ls
aux.model  [0m[01;32mcnn.grammar[0m  [01;32mconfig.json[0m  [01;32mconfig-skip.json[0m  [01;34mdata[0m  [01;32mexample2.py[0m  [01;32mexample.py[0m  [01;34mexperiments_reevaluate_parent[0m  [01;34mfast_denser[0m  [01;32mmain.py[0m  normal.out  [01;32mREADME.md[0m  requirements.txt  skip_parent.out  [01;32mspike_bar.gif[0m  TESTER.py  [01;32mTODO.txt[0m
[01;32mbranquinho@pamela[00m:[01;34m~/snn[00m$ cd fast_denser/
[01;32mbranquinho@pamela[00m:[01;34m~/snn/fast_denser[00m$ nano engine.py 
[?1049h[1;59r(B[m[4l[?7h[?1h=[?1h=[?1h=[39;49m[?25l[39;49m(B[m[H[2J[57;112H(B[0;7m[ Reading File ][3d(B[m[57;111H(B[0;7m[ Read 749 lines ][3d(B[m[?12l[?25h[H[39;49m(B[0;7m  GNU nano 2.5.3                                                                   File: engine.py                                                                                                                                            [3;1H(B[0;1m[36mimport[39m(B[m os[4d(B[0;1m[36mimport[39m(B[m sys, getopt[5d(B[0;1m[36mfrom[39m(B[m fast_denser.grammar (B[0;1m[36mimport[39m(B[m Grammar[6d(B[0;1m[36mfrom[39m(B[m fast_denser.utils (B[0;1m[36mimport[39m(B[m Evaluator, Individual[7d(B[0;1m[36mimport[39m(B[m json[8d(B[0;1m[36mfrom[39m(B[m pathlib (B[0;1m[36mimport[39m(B[m Path[9d(B[0;1m[36mfrom[39m(B[m os (B[0;1m[36mimport[39m(B[m makedirs[10d(B[0;1m[36mimport[39m(B[m random[11d(B[0;1m[36mimport[39m(B[m numpy (B[0;1m[36mas[39m(B[m np[12d(B[0;1m[36mfrom[39m(B[m jsmin (B[0;1m[36mimport[39m(B[m jsmin[13d(B[0;1m[36mfrom[39m(B[m copy (B[0;1m[36mimport[39m(B[m deepcopy[14d(B[0;1m[36mfrom[39m(B[m glob (B[0;1m[36mimport[39m(B[m glob[15d(B[0;1m[36mimport[39m(B[m pickle[16d(B[0;1m[36mfrom[39m(B[m shutil (B[0;1m[36mimport[39m(B[m copyfile[17d(B[0;1m[36mimport[39m(B[m warnings[20dwarnings.filterwarnings((B[0;1m[32m"ignore"[39m(B[m, category=UserWarning)[22dos.environ[(B[0;1m[32m"CUDA_VISIBLE_DEVICES"[39m(B[m] = (B[0;1m[32m"0"[23d[39m(B[mos.environ[(B[0;1m[32m"PYTORCH_CUDA_ALLOC_CONF"[39m(B[m] = (B[0;1m[32m"max_split_size_mb:512"[24d[39m(B[mos.environ[(B[0;1m[32m"CUDA_DEVICE_ORDER"[39m(B[m] = (B[0;1m[32m"PCI_BUS_ID"[26d[36mdef[34m save_pop[39m(B[m(population, save_path, run, gen):[27;5H"""[28d Save the current population statistics (B[0;1m[36min[39m(B[m json.[29;9HFor each individual:[30;13H.id: unique generation identifier[31;13H.phenotype: phenotype of the individual[32;13H.fitness: fitness of the individual[33;13H.metrics: other evaluation metrics (e.g., loss, accuracy)[34;13H.trainable_parameters: number of network trainable parameters[35;13H.num_epochs: number of performed training epochs[36;13H.time: time (sec) the network took to perform num_epochs[37;13H.train_time: maximum time (sec) that the network (B[0;1m[36mis[39m(B[m allowed to train (B[0;1m[36mfor[41;9H[39m(B[mParameters[42;9H----------[43;9Hpopulation : list[44;13Hlist of Individual instances[46;9Hsave_path : str[47;13Hpath to the json file[49;9Hrun : int[50;13Hcurrent evolutionary run[52;9Hgen : int[53;13Hcurrent generation[55;5H"""[58d(B[0;7m^G(B[m Get Help[19G(B[0;7m^O(B[m Write Out[37G(B[0;7m^W(B[m Where Is[55G(B[0;7m^K(B[m Cut Text[73G(B[0;7m^J(B[m Justify[58;91H(B[0;7m^C(B[m Cur Pos[58;109H(B[0;7m^Y(B[m Prev Page[127G(B[0;7mM-\(B[m First Line    (B[0;7mM-W(B[m WhereIs Next  (B[0;7m^^(B[m Mark Text[181G(B[0;7mM-}(B[m Indent Text   (B[0;7mM-U(B[m Undo[58;217H(B[0;7m^B(B[m Back[59d(B[0;7m^X(B[m Exit[59;19H(B[0;7m^R(B[m Read File[37G(B[0;7m^\(B[m Replace[59;55H(B[0;7m^U(B[m Uncut Text     (B[0;7m^T(B[m To Linter[91G(B[0;7m^_(B[m Go To Line     (B[0;7m^V(B[m Next Page[127G(B[0;7mM-/(B[m Last Line     (B[0;7mM-](B[m To Bracket    (B[0;7mM-^(B[m Copy Text     (B[0;7mM-{(B[m Unindent Text (B[0;7mM-E(B[m Redo[59;217H(B[0;7m^F(B[m Forward[3d[4d[5d[6d[7d[8d[10d[13d[14d[15d[16d[17d[18d[19d[21d[22d[23d[22;41H[1;229H(B[0;7mModified[22;38H(B[m"" (B[0;1m[32m"1"[39m(B[m[57d(B[0;7mFile Name to Write: engine.py                                                                                                                                                                                                                 [58;19H(B[m            [37G           (B[0;7mM-D(B[m DOS Format    [73G          [58;91H    (B[0;7mM-A(B[m Append[16X[58;127H[15X[58;142H(B[0;7mM-B(B[m Backup File[K[59;2H(B[0;7mC(B[m Cancel[59;19H            [37G           (B[0;7mM-M(B[m Mac Format[23X[59;91H    (B[0;7mM-P(B[m Prepend[15X[59;127H[15X[59;142H(B[0;7m^T(B[m To Files[K[57;30H[?25l[57;109H[39;49m(B[m[1K (B[0;7m[ Wrote 749 lines ](B[m[K[22;40H[?12l[?25h[1;229H(B[0;7m        [58;19H^O(B[m Write Out[37G(B[0;7m^W(B[m Where Is       (B[0;7m^K(B[m Cut Text[73G(B[0;7m^J(B[m Justify[58;91H(B[0;7m^C(B[m Cur Pos        (B[0;7m^Y(B[m Prev Page[127G(B[0;7mM-\(B[m First Line    (B[0;7mM-W(B[m WhereIs Next  (B[0;7m^^(B[m Mark Text[181G(B[0;7mM-}(B[m Indent Text   (B[0;7mM-U(B[m Undo[58;217H(B[0;7m^B(B[m Back[59;2H(B[0;7mX(B[m Exit  [59;19H(B[0;7m^R(B[m Read File[37G(B[0;7m^\(B[m Replace        (B[0;7m^U(B[m Uncut Text     (B[0;7m^T(B[m To Linter[91G(B[0;7m^_(B[m Go To Line     (B[0;7m^V(B[m Next Page[127G(B[0;7mM-/(B[m Last Line     (B[0;7mM-](B[m To Bracket    (B[0;7mM-^(B[m Copy Text     (B[0;7mM-{(B[m Unindent Text (B[0;7mM-E(B[m Redo[59;217H(B[0;7m^F(B[m Forward[22;40H[57d[J[59;238H[59;1H[?1049l[?1l>[01;32mbranquinho@pamela[00m:[01;34m~/snn/fast_denser[00m$ d ..
d: command not found
[01;32mbranquinho@pamela[00m:[01;34m~/snn/fast_denser[00m$ cd ..
[01;32mbranquinho@pamela[00m:[01;34m~/snn[00m$ python main.py -c config[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[Kls
aux.model  [0m[01;32mcnn.grammar[0m  [01;32mconfig.json[0m  [01;32mconfig-skip.json[0m  [01;34mdata[0m  [01;32mexample2.py[0m  [01;32mexample.py[0m  [01;34mexperiments_reevaluate_parent[0m  [01;34mfast_denser[0m  [01;32mmain.py[0m  normal.out  [01;32mREADME.md[0m  requirements.txt  skip_parent.out  [01;32mspike_bar.gif[0m  TESTER.py  [01;32mTODO.txt[0m
[01;32mbranquinho@pamela[00m:[01;34m~/snn[00m$ python3.7 main.py -c config-skip.json -g cnn.grammar -d x 
Running on Device =  cuda
Evo train dataset has 42000 samples
Evo test dataset has 18000 samples
[0] Creating the initial population
[0] Performing generation: 0
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Epoch 0, Iteration 0/657 
Train Loss: 9.88 Accuracy: 14.06%
Epoch 0, Iteration 1/657 
Train Loss: 51.82 Accuracy: 26.56%
Epoch 0, Iteration 2/657 
Train Loss: 23.84 Accuracy: 12.50%
Epoch 0, Iteration 3/657 
Train Loss: 26.26 Accuracy: 9.38%
Epoch 0, Iteration 4/657 
Train Loss: 19.39 Accuracy: 10.94%
Epoch 0, Iteration 5/657 
Train Loss: 9.73 Accuracy: 15.62%
Epoch 0, Iteration 6/657 
Train Loss: 9.59 Accuracy: 15.62%
Epoch 0, Iteration 7/657 
Train Loss: 9.64 Accuracy: 23.44%
Epoch 0, Iteration 8/657 
Train Loss: 9.66 Accuracy: 18.75%
Epoch 0, Iteration 9/657 
Train Loss: 8.74 Accuracy: 29.69%
Epoch 0, Iteration 10/657 
Train Loss: 9.45 Accuracy: 14.06%
Epoch 0, Iteration 11/657 
Train Loss: 9.02 Accuracy: 23.44%
Epoch 0, Iteration 12/657 
Train Loss: 9.30 Accuracy: 17.19%
Epoch 0, Iteration 13/657 
Train Loss: 8.66 Accuracy: 23.44%
Epoch 0, Iteration 14/657 
Train Loss: 9.42 Accuracy: 12.50%
Epoch 0, Iteration 15/657 
Train Loss: 9.45 Accuracy: 14.06%
Epoch 0, Iteration 16/657 
Train Loss: 9.02 Accuracy: 17.19%
Epoch 0, Iteration 17/657 
Train Loss: 8.70 Accuracy: 21.88%
Epoch 0, Iteration 18/657 
Train Loss: 9.23 Accuracy: 12.50%
Epoch 0, Iteration 19/657 
Train Loss: 9.32 Accuracy: 21.88%
Epoch 0, Iteration 20/657 
Train Loss: 8.81 Accuracy: 31.25%
Epoch 0, Iteration 21/657 
Train Loss: 8.51 Accuracy: 20.31%
Epoch 0, Iteration 22/657 
Train Loss: 9.32 Accuracy: 12.50%
Epoch 0, Iteration 23/657 
Train Loss: 8.93 Accuracy: 25.00%
Epoch 0, Iteration 24/657 
Train Loss: 9.39 Accuracy: 21.88%
	Current speed:3.4524353099696734 iterations per second
Epoch 0, Iteration 25/657 
Train Loss: 8.79 Accuracy: 28.12%
Epoch 0, Iteration 26/657 
Train Loss: 8.96 Accuracy: 15.62%
Epoch 0, Iteration 27/657 
Train Loss: 8.46 Accuracy: 25.00%
Epoch 0, Iteration 28/657 
Train Loss: 9.05 Accuracy: 23.44%
Epoch 0, Iteration 29/657 
Train Loss: 8.88 Accuracy: 17.19%
Epoch 0, Iteration 30/657 
Train Loss: 9.53 Accuracy: 17.19%
Epoch 0, Iteration 31/657 
Train Loss: 8.66 Accuracy: 23.44%
Epoch 0, Iteration 32/657 
Train Loss: 8.03 Accuracy: 31.25%
Epoch 0, Iteration 33/657 
Train Loss: 8.24 Accuracy: 31.25%
Epoch 0, Iteration 34/657 
Train Loss: 8.51 Accuracy: 28.12%
Epoch 0, Iteration 35/657 
Train Loss: 9.10 Accuracy: 20.31%
Epoch 0, Iteration 36/657 
Train Loss: 9.07 Accuracy: 25.00%
Epoch 0, Iteration 37/657 
Train Loss: 9.16 Accuracy: 18.75%
Epoch 0, Iteration 38/657 
Train Loss: 9.06 Accuracy: 20.31%
Epoch 0, Iteration 39/657 
Train Loss: 9.08 Accuracy: 23.44%
Epoch 0, Iteration 40/657 
Train Loss: 8.43 Accuracy: 32.81%
Epoch 0, Iteration 41/657 
Train Loss: 8.83 Accuracy: 34.38%
Epoch 0, Iteration 42/657 
Train Loss: 8.10 Accuracy: 32.81%
Epoch 0, Iteration 43/657 
Train Loss: 9.37 Accuracy: 23.44%
Epoch 0, Iteration 44/657 
Train Loss: 8.73 Accuracy: 25.00%
Epoch 0, Iteration 45/657 
Train Loss: 8.41 Accuracy: 31.25%
Epoch 0, Iteration 46/657 
Train Loss: 8.14 Accuracy: 32.81%
Epoch 0, Iteration 47/657 
Train Loss: 8.73 Accuracy: 23.44%
Epoch 0, Iteration 48/657 
Train Loss: 8.52 Accuracy: 25.00%
Epoch 0, Iteration 49/657 
Train Loss: 7.42 Accuracy: 43.75%
	Current speed:3.6262195716176775 iterations per second
Epoch 0, Iteration 50/657 
Train Loss: 9.59 Accuracy: 12.50%
Epoch 0, Iteration 51/657 
Train Loss: 7.81 Accuracy: 31.25%
Epoch 0, Iteration 52/657 
Train Loss: 8.09 Accuracy: 28.12%
Epoch 0, Iteration 53/657 
Train Loss: 7.62 Accuracy: 35.94%
Epoch 0, Iteration 54/657 
Train Loss: 8.64 Accuracy: 25.00%
Epoch 0, Iteration 55/657 
Train Loss: 7.95 Accuracy: 31.25%
Epoch 0, Iteration 56/657 
Train Loss: 7.54 Accuracy: 35.94%
Epoch 0, Iteration 57/657 
Train Loss: 8.05 Accuracy: 35.94%
Epoch 0, Iteration 58/657 
Train Loss: 7.36 Accuracy: 39.06%
Epoch 0, Iteration 59/657 
Train Loss: 6.71 Accuracy: 42.19%
Epoch 0, Iteration 60/657 
Train Loss: 7.24 Accuracy: 40.62%
Epoch 0, Iteration 61/657 
Train Loss: 7.71 Accuracy: 39.06%
Epoch 0, Iteration 62/657 
Train Loss: 7.45 Accuracy: 39.06%
Epoch 0, Iteration 63/657 
Train Loss: 7.13 Accuracy: 42.19%
Epoch 0, Iteration 64/657 
Train Loss: 7.12 Accuracy: 40.62%
Epoch 0, Iteration 65/657 
Train Loss: 7.58 Accuracy: 39.06%
Epoch 0, Iteration 66/657 
Train Loss: 8.20 Accuracy: 31.25%
Epoch 0, Iteration 67/657 
Train Loss: 8.09 Accuracy: 31.25%
Epoch 0, Iteration 68/657 
Train Loss: 6.39 Accuracy: 51.56%
Epoch 0, Iteration 69/657 
Train Loss: 7.21 Accuracy: 40.62%
Epoch 0, Iteration 70/657 
Train Loss: 7.15 Accuracy: 45.31%
Epoch 0, Iteration 71/657 
Train Loss: 7.77 Accuracy: 31.25%
Epoch 0, Iteration 72/657 
Train Loss: 7.80 Accuracy: 34.38%
Epoch 0, Iteration 73/657 
Train Loss: 7.65 Accuracy: 39.06%
Epoch 0, Iteration 74/657 
Train Loss: 7.96 Accuracy: 37.50%
	Current speed:3.683174675588869 iterations per second
Epoch 0, Iteration 75/657 
Train Loss: 6.67 Accuracy: 51.56%
Epoch 0, Iteration 76/657 
Train Loss: 7.07 Accuracy: 37.50%
Epoch 0, Iteration 77/657 
Train Loss: 6.64 Accuracy: 50.00%
Epoch 0, Iteration 78/657 
Train Loss: 7.86 Accuracy: 35.94%
Epoch 0, Iteration 79/657 
Train Loss: 7.99 Accuracy: 35.94%
Epoch 0, Iteration 80/657 
Train Loss: 6.61 Accuracy: 45.31%
Epoch 0, Iteration 81/657 
Train Loss: 8.19 Accuracy: 31.25%
Epoch 0, Iteration 82/657 
Train Loss: 7.86 Accuracy: 31.25%
Epoch 0, Iteration 83/657 
Train Loss: 7.53 Accuracy: 34.38%
Epoch 0, Iteration 84/657 
Train Loss: 7.49 Accuracy: 35.94%
Epoch 0, Iteration 85/657 
Train Loss: 8.53 Accuracy: 35.94%
Epoch 0, Iteration 86/657 
Train Loss: 7.57 Accuracy: 32.81%
Epoch 0, Iteration 87/657 
Train Loss: 7.17 Accuracy: 37.50%
Epoch 0, Iteration 88/657 
Train Loss: 8.59 Accuracy: 25.00%
Epoch 0, Iteration 89/657 
Train Loss: 8.18 Accuracy: 28.12%
Epoch 0, Iteration 90/657 
Train Loss: 8.03 Accuracy: 31.25%
Epoch 0, Iteration 91/657 
Train Loss: 7.91 Accuracy: 39.06%
Epoch 0, Iteration 92/657 
Train Loss: 7.56 Accuracy: 39.06%
Epoch 0, Iteration 93/657 
Train Loss: 6.72 Accuracy: 43.75%
Epoch 0, Iteration 94/657 
Train Loss: 7.49 Accuracy: 37.50%
Epoch 0, Iteration 95/657 
Train Loss: 7.24 Accuracy: 35.94%
Epoch 0, Iteration 96/657 
Train Loss: 8.00 Accuracy: 26.56%
Epoch 0, Iteration 97/657 
Train Loss: 6.65 Accuracy: 46.88%
Epoch 0, Iteration 98/657 
Train Loss: 7.68 Accuracy: 39.06%
Epoch 0, Iteration 99/657 
Train Loss: 7.45 Accuracy: 32.81%
	Current speed:3.707062693208573 iterations per second
Epoch 0, Iteration 100/657 
Train Loss: 7.67 Accuracy: 34.38%
Epoch 0, Iteration 101/657 
Train Loss: 6.53 Accuracy: 46.88%
Epoch 0, Iteration 102/657 
Train Loss: 6.47 Accuracy: 50.00%
Epoch 0, Iteration 103/657 
Train Loss: 7.94 Accuracy: 35.94%
Epoch 0, Iteration 104/657 
Train Loss: 7.82 Accuracy: 28.12%
Epoch 0, Iteration 105/657 
Train Loss: 6.40 Accuracy: 48.44%
Epoch 0, Iteration 106/657 
Train Loss: 7.70 Accuracy: 32.81%
Epoch 0, Iteration 107/657 
Train Loss: 7.92 Accuracy: 34.38%
Epoch 0, Iteration 108/657 
Train Loss: 7.73 Accuracy: 37.50%
Epoch 0, Iteration 109/657 
Train Loss: 7.66 Accuracy: 34.38%
Epoch 0, Iteration 110/657 
Train Loss: 7.42 Accuracy: 31.25%
Epoch 0, Iteration 111/657 
Train Loss: 8.08 Accuracy: 23.44%
Epoch 0, Iteration 112/657 
Train Loss: 7.44 Accuracy: 35.94%
Epoch 0, Iteration 113/657 
Train Loss: 6.94 Accuracy: 39.06%
Epoch 0, Iteration 114/657 
Train Loss: 8.10 Accuracy: 32.81%
Epoch 0, Iteration 115/657 
Train Loss: 7.45 Accuracy: 32.81%
Epoch 0, Iteration 116/657 
Train Loss: 7.41 Accuracy: 29.69%
Epoch 0, Iteration 117/657 
Train Loss: 7.22 Accuracy: 37.50%
Epoch 0, Iteration 118/657 
Train Loss: 6.86 Accuracy: 42.19%
Epoch 0, Iteration 119/657 
Train Loss: 7.84 Accuracy: 28.12%
Epoch 0, Iteration 120/657 
Train Loss: 7.40 Accuracy: 35.94%
Epoch 0, Iteration 121/657 
Train Loss: 6.56 Accuracy: 46.88%
Epoch 0, Iteration 122/657 
Train Loss: 6.93 Accuracy: 37.50%
Epoch 0, Iteration 123/657 
Train Loss: 6.95 Accuracy: 42.19%
Epoch 0, Iteration 124/657 
Train Loss: 7.75 Accuracy: 35.94%
	Current speed:3.7211514379062662 iterations per second
Epoch 0, Iteration 125/657 
Train Loss: 8.55 Accuracy: 20.31%
Epoch 0, Iteration 126/657 
Train Loss: 6.82 Accuracy: 40.62%
Epoch 0, Iteration 127/657 
Train Loss: 6.97 Accuracy: 40.62%
Epoch 0, Iteration 128/657 
Train Loss: 7.92 Accuracy: 28.12%
Epoch 0, Iteration 129/657 
Train Loss: 7.33 Accuracy: 35.94%
Epoch 0, Iteration 130/657 
Train Loss: 6.82 Accuracy: 40.62%
Epoch 0, Iteration 131/657 
Train Loss: 7.98 Accuracy: 35.94%
Epoch 0, Iteration 132/657 
Train Loss: 8.31 Accuracy: 28.12%
Epoch 0, Iteration 133/657 
Train Loss: 8.42 Accuracy: 26.56%
Epoch 0, Iteration 134/657 
Train Loss: 7.72 Accuracy: 35.94%
Epoch 0, Iteration 135/657 
Train Loss: 6.63 Accuracy: 43.75%
Epoch 0, Iteration 136/657 
Train Loss: 7.22 Accuracy: 34.38%
Epoch 0, Iteration 137/657 
Train Loss: 6.58 Accuracy: 43.75%
Epoch 0, Iteration 138/657 
Train Loss: 7.48 Accuracy: 32.81%
Epoch 0, Iteration 139/657 
Train Loss: 6.85 Accuracy: 43.75%
Epoch 0, Iteration 140/657 
Train Loss: 7.99 Accuracy: 31.25%
Epoch 0, Iteration 141/657 
Train Loss: 7.01 Accuracy: 42.19%
Epoch 0, Iteration 142/657 
Train Loss: 8.36 Accuracy: 32.81%
Epoch 0, Iteration 143/657 
Train Loss: 6.01 Accuracy: 46.88%
Epoch 0, Iteration 144/657 
Train Loss: 7.79 Accuracy: 34.38%
Epoch 0, Iteration 145/657 
Train Loss: 7.08 Accuracy: 43.75%
Epoch 0, Iteration 146/657 
Train Loss: 8.10 Accuracy: 37.50%
Epoch 0, Iteration 147/657 
Train Loss: 7.49 Accuracy: 32.81%
Epoch 0, Iteration 148/657 
Train Loss: 7.61 Accuracy: 34.38%
Epoch 0, Iteration 149/657 
Train Loss: 6.80 Accuracy: 42.19%
	Current speed:3.7296004574360424 iterations per second
Epoch 0, Iteration 150/657 
Train Loss: 7.73 Accuracy: 32.81%
Epoch 0, Iteration 151/657 
Train Loss: 7.78 Accuracy: 43.75%
Epoch 0, Iteration 152/657 
Train Loss: 7.46 Accuracy: 35.94%
Epoch 0, Iteration 153/657 
Train Loss: 6.33 Accuracy: 50.00%
Epoch 0, Iteration 154/657 
Train Loss: 7.17 Accuracy: 46.88%
Epoch 0, Iteration 155/657 
Train Loss: 7.71 Accuracy: 34.38%
Epoch 0, Iteration 156/657 
Train Loss: 7.52 Accuracy: 34.38%
Epoch 0, Iteration 157/657 
Train Loss: 7.85 Accuracy: 31.25%
Epoch 0, Iteration 158/657 
Train Loss: 7.28 Accuracy: 40.62%
Epoch 0, Iteration 159/657 
Train Loss: 8.34 Accuracy: 26.56%
Epoch 0, Iteration 160/657 
Train Loss: 7.20 Accuracy: 39.06%
Epoch 0, Iteration 161/657 
Train Loss: 7.59 Accuracy: 35.94%
Epoch 0, Iteration 162/657 
Train Loss: 7.41 Accuracy: 43.75%
Epoch 0, Iteration 163/657 
Train Loss: 7.59 Accuracy: 39.06%
Epoch 0, Iteration 164/657 
Train Loss: 6.90 Accuracy: 39.06%
Epoch 0, Iteration 165/657 
Train Loss: 8.15 Accuracy: 34.38%
Epoch 0, Iteration 166/657 
Train Loss: 8.00 Accuracy: 21.88%
Epoch 0, Iteration 167/657 
Train Loss: 8.23 Accuracy: 25.00%
Epoch 0, Iteration 168/657 
Train Loss: 7.72 Accuracy: 40.62%
Epoch 0, Iteration 169/657 
Train Loss: 8.72 Accuracy: 20.31%
Epoch 0, Iteration 170/657 
Train Loss: 8.08 Accuracy: 34.38%
Epoch 0, Iteration 171/657 
Train Loss: 7.24 Accuracy: 34.38%
Epoch 0, Iteration 172/657 
Train Loss: 7.74 Accuracy: 34.38%
Epoch 0, Iteration 173/657 
Train Loss: 6.65 Accuracy: 40.62%
Epoch 0, Iteration 174/657 
Train Loss: 6.91 Accuracy: 43.75%
	Current speed:3.735706759657605 iterations per second
Epoch 0, Iteration 175/657 
Train Loss: 7.04 Accuracy: 35.94%
Epoch 0, Iteration 176/657 
Train Loss: 7.34 Accuracy: 39.06%
Epoch 0, Iteration 177/657 
Train Loss: 8.36 Accuracy: 35.94%
Epoch 0, Iteration 178/657 
Train Loss: 6.31 Accuracy: 43.75%
Epoch 0, Iteration 179/657 
Train Loss: 7.15 Accuracy: 43.75%
Epoch 0, Iteration 180/657 
Train Loss: 6.62 Accuracy: 43.75%
Epoch 0, Iteration 181/657 
Train Loss: 6.79 Accuracy: 46.88%
Epoch 0, Iteration 182/657 
Train Loss: 5.63 Accuracy: 56.25%
Epoch 0, Iteration 183/657 
Train Loss: 6.82 Accuracy: 42.19%
Epoch 0, Iteration 184/657 
Train Loss: 7.69 Accuracy: 29.69%
Epoch 0, Iteration 185/657 
Train Loss: 7.14 Accuracy: 32.81%
Epoch 0, Iteration 186/657 
Train Loss: 7.46 Accuracy: 31.25%
Epoch 0, Iteration 187/657 
Train Loss: 7.42 Accuracy: 29.69%
Epoch 0, Iteration 188/657 
Train Loss: 8.43 Accuracy: 23.44%
Epoch 0, Iteration 189/657 
Train Loss: 8.08 Accuracy: 26.56%
Epoch 0, Iteration 190/657 
Train Loss: 7.70 Accuracy: 39.06%
Epoch 0, Iteration 191/657 
Train Loss: 7.55 Accuracy: 37.50%
Epoch 0, Iteration 192/657 
Train Loss: 7.13 Accuracy: 43.75%
Epoch 0, Iteration 193/657 
Train Loss: 8.03 Accuracy: 32.81%
Epoch 0, Iteration 194/657 
Train Loss: 7.80 Accuracy: 39.06%
Epoch 0, Iteration 195/657 
Train Loss: 7.21 Accuracy: 37.50%
Epoch 0, Iteration 196/657 
Train Loss: 7.79 Accuracy: 31.25%
Epoch 0, Iteration 197/657 
Train Loss: 7.19 Accuracy: 37.50%
Epoch 0, Iteration 198/657 
Train Loss: 7.03 Accuracy: 42.19%
Epoch 0, Iteration 199/657 
Train Loss: 7.04 Accuracy: 37.50%
	Current speed:3.7297257767155636 iterations per second
Epoch 0, Iteration 200/657 
Train Loss: 7.70 Accuracy: 32.81%
Epoch 0, Iteration 201/657 
Train Loss: 6.50 Accuracy: 42.19%
Epoch 0, Iteration 202/657 
Train Loss: 6.45 Accuracy: 54.69%
Epoch 0, Iteration 203/657 
Train Loss: 8.05 Accuracy: 26.56%
Epoch 0, Iteration 204/657 
Train Loss: 5.64 Accuracy: 53.12%
Epoch 0, Iteration 205/657 
Train Loss: 7.17 Accuracy: 40.62%
Epoch 0, Iteration 206/657 
Train Loss: 8.00 Accuracy: 43.75%
Epoch 0, Iteration 207/657 
Train Loss: 7.20 Accuracy: 39.06%
Epoch 0, Iteration 208/657 
Train Loss: 6.96 Accuracy: 40.62%
Epoch 0, Iteration 209/657 
Train Loss: 8.31 Accuracy: 25.00%
Epoch 0, Iteration 210/657 
Train Loss: 6.74 Accuracy: 40.62%
Epoch 0, Iteration 211/657 
Train Loss: 7.51 Accuracy: 31.25%
Epoch 0, Iteration 212/657 
Train Loss: 7.60 Accuracy: 26.56%
Epoch 0, Iteration 213/657 
Train Loss: 7.00 Accuracy: 34.38%
Epoch 0, Iteration 214/657 
Train Loss: 7.55 Accuracy: 34.38%
Epoch 0, Iteration 215/657 
Train Loss: 7.29 Accuracy: 40.62%
Epoch 0, Iteration 216/657 
Train Loss: 7.90 Accuracy: 35.94%
Epoch 0, Iteration 217/657 
Train Loss: 7.65 Accuracy: 34.38%
Epoch 0, Iteration 218/657 
Train Loss: 6.52 Accuracy: 45.31%
Epoch 0, Iteration 219/657 
Train Loss: 8.06 Accuracy: 31.25%
Epoch 0, Iteration 220/657 
Train Loss: 8.01 Accuracy: 35.94%
Epoch 0, Iteration 221/657 
Train Loss: 6.53 Accuracy: 43.75%
Epoch 0, Iteration 222/657 
Train Loss: 7.18 Accuracy: 37.50%
Epoch 0, Iteration 223/657 
Train Loss: 7.67 Accuracy: 32.81%
Epoch 0, Iteration 224/657 
Train Loss: 7.94 Accuracy: 32.81%
	Current speed:3.735579872095321 iterations per second
Epoch 0, Iteration 225/657 
Train Loss: 7.20 Accuracy: 42.19%
Epoch 0, Iteration 226/657 
Train Loss: 8.38 Accuracy: 26.56%
Epoch 0, Iteration 227/657 
Train Loss: 8.07 Accuracy: 32.81%
Epoch 0, Iteration 228/657 
Train Loss: 7.78 Accuracy: 35.94%
Epoch 0, Iteration 229/657 
Train Loss: 6.84 Accuracy: 43.75%
Epoch 0, Iteration 230/657 
Train Loss: 7.46 Accuracy: 39.06%
Epoch 0, Iteration 231/657 
Train Loss: 7.35 Accuracy: 35.94%
Epoch 0, Iteration 232/657 
Train Loss: 7.92 Accuracy: 31.25%
Epoch 0, Iteration 233/657 
Train Loss: 7.05 Accuracy: 40.62%
Epoch 0, Iteration 234/657 
Train Loss: 8.02 Accuracy: 34.38%
Epoch 0, Iteration 235/657 
Train Loss: 6.76 Accuracy: 46.88%
Epoch 0, Iteration 236/657 
Train Loss: 7.32 Accuracy: 35.94%
Epoch 0, Iteration 237/657 
Train Loss: 8.01 Accuracy: 39.06%
Epoch 0, Iteration 238/657 
Train Loss: 6.80 Accuracy: 42.19%
Epoch 0, Iteration 239/657 
Train Loss: 6.93 Accuracy: 42.19%
Epoch 0, Iteration 240/657 
Train Loss: 7.53 Accuracy: 37.50%
Epoch 0, Iteration 241/657 
Train Loss: 7.16 Accuracy: 39.06%
Epoch 0, Iteration 242/657 
Train Loss: 6.08 Accuracy: 46.88%
Epoch 0, Iteration 243/657 
Train Loss: 7.91 Accuracy: 29.69%
Epoch 0, Iteration 244/657 
Train Loss: 7.23 Accuracy: 35.94%
Epoch 0, Iteration 245/657 
Train Loss: 6.55 Accuracy: 43.75%
Epoch 0, Iteration 246/657 
Train Loss: 6.86 Accuracy: 42.19%
Epoch 0, Iteration 247/657 
Train Loss: 7.29 Accuracy: 32.81%
Epoch 0, Iteration 248/657 
Train Loss: 6.18 Accuracy: 43.75%
Epoch 0, Iteration 249/657 
Train Loss: 7.42 Accuracy: 42.19%
	Current speed:3.753826809015591 iterations per second
Epoch 0, Iteration 250/657 
Train Loss: 8.18 Accuracy: 29.69%
Epoch 0, Iteration 251/657 
Train Loss: 6.18 Accuracy: 54.69%
Epoch 0, Iteration 252/657 
Train Loss: 7.84 Accuracy: 29.69%
Epoch 0, Iteration 253/657 
Train Loss: 7.06 Accuracy: 37.50%
Epoch 0, Iteration 254/657 
Train Loss: 7.07 Accuracy: 37.50%
Epoch 0, Iteration 255/657 
Train Loss: 6.81 Accuracy: 42.19%
Epoch 0, Iteration 256/657 
Train Loss: 7.73 Accuracy: 39.06%
Epoch 0, Iteration 257/657 
Train Loss: 8.19 Accuracy: 35.94%
Epoch 0, Iteration 258/657 
Train Loss: 6.28 Accuracy: 46.88%
Epoch 0, Iteration 259/657 
Train Loss: 7.88 Accuracy: 34.38%
Epoch 0, Iteration 260/657 
Train Loss: 7.75 Accuracy: 31.25%
Epoch 0, Iteration 261/657 
Train Loss: 7.46 Accuracy: 35.94%
Epoch 0, Iteration 262/657 
Train Loss: 7.56 Accuracy: 40.62%
Epoch 0, Iteration 263/657 
Train Loss: 8.21 Accuracy: 28.12%
Epoch 0, Iteration 264/657 
Train Loss: 6.99 Accuracy: 40.62%
Epoch 0, Iteration 265/657 
Train Loss: 7.89 Accuracy: 35.94%
Epoch 0, Iteration 266/657 
Train Loss: 7.79 Accuracy: 32.81%
Epoch 0, Iteration 267/657 
Train Loss: 7.83 Accuracy: 26.56%
Epoch 0, Iteration 268/657 
Train Loss: 6.89 Accuracy: 42.19%
Epoch 0, Iteration 269/657 
Train Loss: 7.36 Accuracy: 32.81%
Epoch 0, Iteration 270/657 
Train Loss: 8.20 Accuracy: 28.12%
Epoch 0, Iteration 271/657 
Train Loss: 7.51 Accuracy: 29.69%
Epoch 0, Iteration 272/657 
Train Loss: 7.63 Accuracy: 32.81%
Epoch 0, Iteration 273/657 
Train Loss: 7.63 Accuracy: 39.06%
Epoch 0, Iteration 274/657 
Train Loss: 7.06 Accuracy: 37.50%
	Current speed:3.766653563443886 iterations per second
Epoch 0, Iteration 275/657 
Train Loss: 7.71 Accuracy: 34.38%
Epoch 0, Iteration 276/657 
Train Loss: 7.20 Accuracy: 35.94%
Epoch 0, Iteration 277/657 
Train Loss: 7.76 Accuracy: 28.12%
Epoch 0, Iteration 278/657 
Train Loss: 7.29 Accuracy: 35.94%
Epoch 0, Iteration 279/657 
Train Loss: 7.86 Accuracy: 29.69%
Epoch 0, Iteration 280/657 
Train Loss: 7.43 Accuracy: 42.19%
Epoch 0, Iteration 281/657 
Train Loss: 7.84 Accuracy: 35.94%
Epoch 0, Iteration 282/657 
Train Loss: 7.19 Accuracy: 39.06%
Epoch 0, Iteration 283/657 
Train Loss: 7.92 Accuracy: 35.94%
Epoch 0, Iteration 284/657 
Train Loss: 6.57 Accuracy: 46.88%
Epoch 0, Iteration 285/657 
Train Loss: 6.60 Accuracy: 46.88%
Epoch 0, Iteration 286/657 
Train Loss: 7.34 Accuracy: 40.62%
Epoch 0, Iteration 287/657 
Train Loss: 6.55 Accuracy: 45.31%
Epoch 0, Iteration 288/657 
Train Loss: 8.03 Accuracy: 32.81%
Epoch 0, Iteration 289/657 
Train Loss: 7.18 Accuracy: 40.62%
Epoch 0, Iteration 290/657 
Train Loss: 6.28 Accuracy: 50.00%
Epoch 0, Iteration 291/657 
Train Loss: 7.71 Accuracy: 34.38%
Epoch 0, Iteration 292/657 
Train Loss: 6.91 Accuracy: 43.75%
Epoch 0, Iteration 293/657 
Train Loss: 7.12 Accuracy: 37.50%
Epoch 0, Iteration 294/657 
Train Loss: 7.03 Accuracy: 40.62%
Epoch 0, Iteration 295/657 
Train Loss: 8.21 Accuracy: 31.25%
Epoch 0, Iteration 296/657 
Train Loss: 7.49 Accuracy: 32.81%
Epoch 0, Iteration 297/657 
Train Loss: 8.28 Accuracy: 32.81%
Epoch 0, Iteration 298/657 
Train Loss: 6.18 Accuracy: 50.00%
Epoch 0, Iteration 299/657 
Train Loss: 6.74 Accuracy: 43.75%
	Current speed:3.7766824911760213 iterations per second
Epoch 0, Iteration 300/657 
Train Loss: 7.11 Accuracy: 39.06%
Epoch 0, Iteration 301/657 
Train Loss: 7.78 Accuracy: 28.12%
Epoch 0, Iteration 302/657 
Train Loss: 7.95 Accuracy: 34.38%
Epoch 0, Iteration 303/657 
Train Loss: 7.24 Accuracy: 31.25%
Epoch 0, Iteration 304/657 
Train Loss: 7.64 Accuracy: 42.19%
Epoch 0, Iteration 305/657 
Train Loss: 7.76 Accuracy: 32.81%
Epoch 0, Iteration 306/657 
Train Loss: 6.85 Accuracy: 39.06%
Epoch 0, Iteration 307/657 
Train Loss: 7.77 Accuracy: 35.94%
Epoch 0, Iteration 308/657 
Train Loss: 7.80 Accuracy: 31.25%
Epoch 0, Iteration 309/657 
Train Loss: 8.01 Accuracy: 32.81%
Epoch 0, Iteration 310/657 
Train Loss: 6.90 Accuracy: 45.31%
Epoch 0, Iteration 311/657 
Train Loss: 6.65 Accuracy: 53.12%
Epoch 0, Iteration 312/657 
Train Loss: 7.11 Accuracy: 42.19%
Epoch 0, Iteration 313/657 
Train Loss: 6.97 Accuracy: 42.19%
Epoch 0, Iteration 314/657 
Train Loss: 7.64 Accuracy: 35.94%
Epoch 0, Iteration 315/657 
Train Loss: 7.68 Accuracy: 32.81%
Epoch 0, Iteration 316/657 
Train Loss: 6.46 Accuracy: 40.62%
Epoch 0, Iteration 317/657 
Train Loss: 7.41 Accuracy: 40.62%
Epoch 0, Iteration 318/657 
Train Loss: 7.26 Accuracy: 42.19%
Epoch 0, Iteration 319/657 
Train Loss: 7.26 Accuracy: 34.38%
Epoch 0, Iteration 320/657 
Train Loss: 7.53 Accuracy: 35.94%
Epoch 0, Iteration 321/657 
Train Loss: 6.81 Accuracy: 46.88%
Epoch 0, Iteration 322/657 
Train Loss: 8.01 Accuracy: 32.81%
Epoch 0, Iteration 323/657 
Train Loss: 6.57 Accuracy: 42.19%
Epoch 0, Iteration 324/657 
Train Loss: 6.80 Accuracy: 39.06%
	Current speed:3.7853340304955707 iterations per second
Epoch 0, Iteration 325/657 
Train Loss: 7.93 Accuracy: 29.69%
Epoch 0, Iteration 326/657 
Train Loss: 7.67 Accuracy: 29.69%
Epoch 0, Iteration 327/657 
Train Loss: 7.73 Accuracy: 34.38%
Epoch 0, Iteration 328/657 
Train Loss: 7.29 Accuracy: 35.94%
Epoch 0, Iteration 329/657 
Train Loss: 7.25 Accuracy: 39.06%
Epoch 0, Iteration 330/657 
Train Loss: 7.49 Accuracy: 42.19%
Epoch 0, Iteration 331/657 
Train Loss: 6.87 Accuracy: 45.31%
Epoch 0, Iteration 332/657 
Train Loss: 7.12 Accuracy: 42.19%
Epoch 0, Iteration 333/657 
Train Loss: 7.99 Accuracy: 35.94%
Epoch 0, Iteration 334/657 
Train Loss: 6.63 Accuracy: 42.19%
Epoch 0, Iteration 335/657 
Train Loss: 7.06 Accuracy: 39.06%
Epoch 0, Iteration 336/657 
Train Loss: 8.16 Accuracy: 34.38%
Epoch 0, Iteration 337/657 
Train Loss: 7.90 Accuracy: 31.25%
Epoch 0, Iteration 338/657 
Train Loss: 7.21 Accuracy: 42.19%
Epoch 0, Iteration 339/657 
Train Loss: 7.04 Accuracy: 35.94%
Epoch 0, Iteration 340/657 
Train Loss: 7.96 Accuracy: 34.38%
Epoch 0, Iteration 341/657 
Train Loss: 7.87 Accuracy: 34.38%
Epoch 0, Iteration 342/657 
Train Loss: 7.45 Accuracy: 37.50%
Epoch 0, Iteration 343/657 
Train Loss: 8.45 Accuracy: 28.12%
Epoch 0, Iteration 344/657 
Train Loss: 6.59 Accuracy: 48.44%
Epoch 0, Iteration 345/657 
Train Loss: 6.85 Accuracy: 43.75%
Epoch 0, Iteration 346/657 
Train Loss: 7.75 Accuracy: 37.50%
Epoch 0, Iteration 347/657 
Train Loss: 6.19 Accuracy: 43.75%
Epoch 0, Iteration 348/657 
Train Loss: 7.92 Accuracy: 32.81%
Epoch 0, Iteration 349/657 
Train Loss: 6.93 Accuracy: 42.19%
	Current speed:3.792845960487972 iterations per second
Epoch 0, Iteration 350/657 
Train Loss: 7.65 Accuracy: 39.06%
Epoch 0, Iteration 351/657 
Train Loss: 7.64 Accuracy: 28.12%
Epoch 0, Iteration 352/657 
Train Loss: 6.14 Accuracy: 45.31%
Epoch 0, Iteration 353/657 
Train Loss: 7.02 Accuracy: 40.62%
Epoch 0, Iteration 354/657 
Train Loss: 7.65 Accuracy: 35.94%
Epoch 0, Iteration 355/657 
Train Loss: 5.83 Accuracy: 54.69%
Epoch 0, Iteration 356/657 
Train Loss: 8.42 Accuracy: 26.56%
Epoch 0, Iteration 357/657 
Train Loss: 6.81 Accuracy: 40.62%
Epoch 0, Iteration 358/657 
Train Loss: 6.78 Accuracy: 40.62%
Epoch 0, Iteration 359/657 
Train Loss: 7.97 Accuracy: 32.81%
Epoch 0, Iteration 360/657 
Train Loss: 8.44 Accuracy: 28.12%
Epoch 0, Iteration 361/657 
Train Loss: 7.75 Accuracy: 26.56%
Epoch 0, Iteration 362/657 
Train Loss: 7.71 Accuracy: 31.25%
Epoch 0, Iteration 363/657 
Train Loss: 7.17 Accuracy: 37.50%
Epoch 0, Iteration 364/657 
Train Loss: 8.12 Accuracy: 28.12%
Epoch 0, Iteration 365/657 
Train Loss: 6.57 Accuracy: 46.88%
Epoch 0, Iteration 366/657 
Train Loss: 7.15 Accuracy: 39.06%
Epoch 0, Iteration 367/657 
Train Loss: 6.93 Accuracy: 39.06%
Epoch 0, Iteration 368/657 
Train Loss: 7.05 Accuracy: 39.06%
Epoch 0, Iteration 369/657 
Train Loss: 5.77 Accuracy: 51.56%
Epoch 0, Iteration 370/657 
Train Loss: 7.29 Accuracy: 40.62%
Epoch 0, Iteration 371/657 
Train Loss: 6.95 Accuracy: 39.06%
Epoch 0, Iteration 372/657 
Train Loss: 8.37 Accuracy: 28.12%
Epoch 0, Iteration 373/657 
Train Loss: 7.12 Accuracy: 39.06%
Epoch 0, Iteration 374/657 
Train Loss: 7.50 Accuracy: 42.19%
	Current speed:3.800247242800621 iterations per second
Epoch 0, Iteration 375/657 
Train Loss: 6.79 Accuracy: 42.19%
Epoch 0, Iteration 376/657 
Train Loss: 7.29 Accuracy: 39.06%
Epoch 0, Iteration 377/657 
Train Loss: 7.48 Accuracy: 39.06%
Epoch 0, Iteration 378/657 
Train Loss: 7.03 Accuracy: 37.50%
Epoch 0, Iteration 379/657 
Train Loss: 6.97 Accuracy: 39.06%
Epoch 0, Iteration 380/657 
Train Loss: 8.51 Accuracy: 23.44%
Epoch 0, Iteration 381/657 
Train Loss: 7.13 Accuracy: 35.94%
Epoch 0, Iteration 382/657 
Train Loss: 7.33 Accuracy: 31.25%
Epoch 0, Iteration 383/657 
Train Loss: 7.53 Accuracy: 32.81%
Epoch 0, Iteration 384/657 
Train Loss: 7.23 Accuracy: 35.94%
Epoch 0, Iteration 385/657 
Train Loss: 8.12 Accuracy: 29.69%
Epoch 0, Iteration 386/657 
Train Loss: 6.88 Accuracy: 42.19%
Epoch 0, Iteration 387/657 
Train Loss: 8.13 Accuracy: 32.81%
Epoch 0, Iteration 388/657 
Train Loss: 6.20 Accuracy: 48.44%
Epoch 0, Iteration 389/657 
Train Loss: 6.48 Accuracy: 43.75%
Epoch 0, Iteration 390/657 
Train Loss: 7.12 Accuracy: 45.31%
Epoch 0, Iteration 391/657 
Train Loss: 6.85 Accuracy: 42.19%
Epoch 0, Iteration 392/657 
Train Loss: 6.86 Accuracy: 40.62%
Epoch 0, Iteration 393/657 
Train Loss: 6.43 Accuracy: 39.06%
Epoch 0, Iteration 394/657 
Train Loss: 7.67 Accuracy: 35.94%
Epoch 0, Iteration 395/657 
Train Loss: 7.75 Accuracy: 29.69%
Epoch 0, Iteration 396/657 
Train Loss: 7.53 Accuracy: 29.69%
Epoch 0, Iteration 397/657 
Train Loss: 6.74 Accuracy: 48.44%
Epoch 0, Iteration 398/657 
Train Loss: 6.95 Accuracy: 37.50%
Epoch 0, Iteration 399/657 
Train Loss: 7.85 Accuracy: 32.81%
	Current speed:3.8079056814719303 iterations per second
Epoch 0, Iteration 400/657 
Train Loss: 7.08 Accuracy: 42.19%
Epoch 0, Iteration 401/657 
Train Loss: 7.08 Accuracy: 45.31%
Epoch 0, Iteration 402/657 
Train Loss: 7.89 Accuracy: 37.50%
Epoch 0, Iteration 403/657 
Train Loss: 7.73 Accuracy: 35.94%
Epoch 0, Iteration 404/657 
Train Loss: 7.33 Accuracy: 37.50%
Epoch 0, Iteration 405/657 
Train Loss: 7.62 Accuracy: 32.81%
Epoch 0, Iteration 406/657 
Train Loss: 8.28 Accuracy: 25.00%
Epoch 0, Iteration 407/657 
Train Loss: 7.42 Accuracy: 34.38%
Epoch 0, Iteration 408/657 
Train Loss: 7.64 Accuracy: 34.38%
Epoch 0, Iteration 409/657 
Train Loss: 7.21 Accuracy: 40.62%
Epoch 0, Iteration 410/657 
Train Loss: 7.23 Accuracy: 34.38%
Epoch 0, Iteration 411/657 
Train Loss: 7.06 Accuracy: 42.19%
Epoch 0, Iteration 412/657 
Train Loss: 6.48 Accuracy: 45.31%
Epoch 0, Iteration 413/657 
Train Loss: 7.75 Accuracy: 28.12%
Epoch 0, Iteration 414/657 
Train Loss: 6.54 Accuracy: 43.75%
Epoch 0, Iteration 415/657 
Train Loss: 6.96 Accuracy: 42.19%
Epoch 0, Iteration 416/657 
Train Loss: 6.99 Accuracy: 32.81%
Epoch 0, Iteration 417/657 
Train Loss: 7.09 Accuracy: 35.94%
Epoch 0, Iteration 418/657 
Train Loss: 7.80 Accuracy: 35.94%
Epoch 0, Iteration 419/657 
Train Loss: 7.18 Accuracy: 34.38%
Epoch 0, Iteration 420/657 
Train Loss: 6.41 Accuracy: 48.44%
Epoch 0, Iteration 421/657 
Train Loss: 7.57 Accuracy: 39.06%
Epoch 0, Iteration 422/657 
Train Loss: 7.42 Accuracy: 40.62%
Epoch 0, Iteration 423/657 
Train Loss: 7.44 Accuracy: 39.06%
Epoch 0, Iteration 424/657 
Train Loss: 6.93 Accuracy: 35.94%
	Current speed:3.8140969401128357 iterations per second
Epoch 0, Iteration 425/657 
Train Loss: 6.85 Accuracy: 39.06%
Epoch 0, Iteration 426/657 
Train Loss: 7.60 Accuracy: 34.38%
Epoch 0, Iteration 427/657 
Train Loss: 6.74 Accuracy: 39.06%
Epoch 0, Iteration 428/657 
Train Loss: 7.63 Accuracy: 34.38%
Epoch 0, Iteration 429/657 
Train Loss: 6.62 Accuracy: 43.75%
Epoch 0, Iteration 430/657 
Train Loss: 6.88 Accuracy: 45.31%
Epoch 0, Iteration 431/657 
Train Loss: 6.47 Accuracy: 46.88%
Epoch 0, Iteration 432/657 
Train Loss: 7.69 Accuracy: 32.81%
Epoch 0, Iteration 433/657 
Train Loss: 7.65 Accuracy: 40.62%
Epoch 0, Iteration 434/657 
Train Loss: 7.28 Accuracy: 35.94%
Epoch 0, Iteration 435/657 
Train Loss: 8.10 Accuracy: 26.56%
Epoch 0, Iteration 436/657 
Train Loss: 7.36 Accuracy: 37.50%
Epoch 0, Iteration 437/657 
Train Loss: 6.96 Accuracy: 42.19%
Epoch 0, Iteration 438/657 
Train Loss: 6.59 Accuracy: 48.44%
Epoch 0, Iteration 439/657 
Train Loss: 6.67 Accuracy: 42.19%
Epoch 0, Iteration 440/657 
Train Loss: 8.23 Accuracy: 25.00%
Epoch 0, Iteration 441/657 
Train Loss: 6.50 Accuracy: 48.44%
Epoch 0, Iteration 442/657 
Train Loss: 6.66 Accuracy: 45.31%
Epoch 0, Iteration 443/657 
Train Loss: 7.08 Accuracy: 40.62%
Epoch 0, Iteration 444/657 
Train Loss: 8.03 Accuracy: 29.69%
Epoch 0, Iteration 445/657 
Train Loss: 7.24 Accuracy: 45.31%
Epoch 0, Iteration 446/657 
Train Loss: 7.08 Accuracy: 40.62%
Epoch 0, Iteration 447/657 
Train Loss: 6.67 Accuracy: 39.06%
Epoch 0, Iteration 448/657 
Train Loss: 7.00 Accuracy: 39.06%
Epoch 0, Iteration 449/657 
Train Loss: 6.81 Accuracy: 40.62%
	Current speed:3.804848938074848 iterations per second
Epoch 0, Iteration 450/657 
Train Loss: 7.79 Accuracy: 31.25%
Epoch 0, Iteration 451/657 
Train Loss: 7.06 Accuracy: 40.62%
Epoch 0, Iteration 452/657 
Train Loss: 8.09 Accuracy: 39.06%
Epoch 0, Iteration 453/657 
Train Loss: 6.79 Accuracy: 40.62%
Epoch 0, Iteration 454/657 
Train Loss: 7.67 Accuracy: 32.81%
Epoch 0, Iteration 455/657 
Train Loss: 7.68 Accuracy: 39.06%
Epoch 0, Iteration 456/657 
Train Loss: 7.28 Accuracy: 37.50%
Epoch 0, Iteration 457/657 
Train Loss: 8.23 Accuracy: 32.81%
Epoch 0, Iteration 458/657 
Train Loss: 7.85 Accuracy: 28.12%
Epoch 0, Iteration 459/657 
Train Loss: 7.52 Accuracy: 35.94%
Epoch 0, Iteration 460/657 
Train Loss: 7.52 Accuracy: 42.19%
Epoch 0, Iteration 461/657 
Train Loss: 7.65 Accuracy: 37.50%
Epoch 0, Iteration 462/657 
Train Loss: 7.47 Accuracy: 39.06%
Epoch 0, Iteration 463/657 
Train Loss: 7.26 Accuracy: 37.50%
Epoch 0, Iteration 464/657 
Train Loss: 7.72 Accuracy: 31.25%
Epoch 0, Iteration 465/657 
Train Loss: 7.97 Accuracy: 32.81%
Epoch 0, Iteration 466/657 
Train Loss: 5.95 Accuracy: 50.00%
Epoch 0, Iteration 467/657 
Train Loss: 6.75 Accuracy: 40.62%
Epoch 0, Iteration 468/657 
Train Loss: 7.84 Accuracy: 32.81%
Epoch 0, Iteration 469/657 
Train Loss: 7.72 Accuracy: 35.94%
Epoch 0, Iteration 470/657 
Train Loss: 7.50 Accuracy: 45.31%
Epoch 0, Iteration 471/657 
Train Loss: 6.85 Accuracy: 45.31%
Epoch 0, Iteration 472/657 
Train Loss: 7.37 Accuracy: 42.19%
Epoch 0, Iteration 473/657 
Train Loss: 7.17 Accuracy: 43.75%
Epoch 0, Iteration 474/657 
Train Loss: 7.34 Accuracy: 40.62%
	Current speed:3.797347539474747 iterations per second
Epoch 0, Iteration 475/657 
Train Loss: 6.41 Accuracy: 57.81%
Epoch 0, Iteration 476/657 
Train Loss: 6.11 Accuracy: 51.56%
Epoch 0, Iteration 477/657 
Train Loss: 7.82 Accuracy: 29.69%
Epoch 0, Iteration 478/657 
Train Loss: 8.07 Accuracy: 39.06%
Epoch 0, Iteration 479/657 
Train Loss: 7.62 Accuracy: 40.62%
Epoch 0, Iteration 480/657 
Train Loss: 6.09 Accuracy: 46.88%
Epoch 0, Iteration 481/657 
Train Loss: 7.36 Accuracy: 45.31%
Epoch 0, Iteration 482/657 
Train Loss: 6.66 Accuracy: 57.81%
Epoch 0, Iteration 483/657 
Train Loss: 7.56 Accuracy: 50.00%
Epoch 0, Iteration 484/657 
Train Loss: 7.58 Accuracy: 37.50%
Epoch 0, Iteration 485/657 
Train Loss: 6.25 Accuracy: 48.44%
Epoch 0, Iteration 486/657 
Train Loss: 6.16 Accuracy: 51.56%
Epoch 0, Iteration 487/657 
Train Loss: 6.70 Accuracy: 50.00%
Epoch 0, Iteration 488/657 
Train Loss: 6.38 Accuracy: 48.44%
Epoch 0, Iteration 489/657 
Train Loss: 6.87 Accuracy: 46.88%
Epoch 0, Iteration 490/657 
Train Loss: 7.45 Accuracy: 45.31%
Epoch 0, Iteration 491/657 
Train Loss: 6.55 Accuracy: 48.44%
Epoch 0, Iteration 492/657 
Train Loss: 5.65 Accuracy: 54.69%
Epoch 0, Iteration 493/657 
Train Loss: 5.98 Accuracy: 56.25%
Epoch 0, Iteration 494/657 
Train Loss: 7.31 Accuracy: 43.75%
Epoch 0, Iteration 495/657 
Train Loss: 6.43 Accuracy: 50.00%
Epoch 0, Iteration 496/657 
Train Loss: 7.03 Accuracy: 45.31%
Epoch 0, Iteration 497/657 
Train Loss: 6.86 Accuracy: 45.31%
Epoch 0, Iteration 498/657 
Train Loss: 7.08 Accuracy: 46.88%
Epoch 0, Iteration 499/657 
Train Loss: 7.20 Accuracy: 43.75%
	Current speed:3.7874074006276377 iterations per second
Epoch 0, Iteration 500/657 
Train Loss: 7.44 Accuracy: 42.19%
Epoch 0, Iteration 501/657 
Train Loss: 6.28 Accuracy: 50.00%
Epoch 0, Iteration 502/657 
Train Loss: 6.42 Accuracy: 45.31%
Epoch 0, Iteration 503/657 
Train Loss: 6.28 Accuracy: 51.56%
Epoch 0, Iteration 504/657 
Train Loss: 6.67 Accuracy: 48.44%
Epoch 0, Iteration 505/657 
Train Loss: 7.08 Accuracy: 46.88%
Epoch 0, Iteration 506/657 
Train Loss: 5.79 Accuracy: 60.94%
Epoch 0, Iteration 507/657 
Train Loss: 4.85 Accuracy: 59.38%
Epoch 0, Iteration 508/657 
Train Loss: 6.68 Accuracy: 45.31%
Epoch 0, Iteration 509/657 
Train Loss: 6.63 Accuracy: 40.62%
Epoch 0, Iteration 510/657 
Train Loss: 6.49 Accuracy: 43.75%
Epoch 0, Iteration 511/657 
Train Loss: 6.88 Accuracy: 45.31%
Epoch 0, Iteration 512/657 
Train Loss: 6.75 Accuracy: 46.88%
Epoch 0, Iteration 513/657 
Train Loss: 6.32 Accuracy: 51.56%
Epoch 0, Iteration 514/657 
Train Loss: 6.76 Accuracy: 43.75%
Epoch 0, Iteration 515/657 
Train Loss: 6.86 Accuracy: 42.19%
Epoch 0, Iteration 516/657 
Train Loss: 6.90 Accuracy: 39.06%
Epoch 0, Iteration 517/657 
Train Loss: 5.80 Accuracy: 51.56%
Epoch 0, Iteration 518/657 
Train Loss: 7.11 Accuracy: 50.00%
Epoch 0, Iteration 519/657 
Train Loss: 6.96 Accuracy: 51.56%
Epoch 0, Iteration 520/657 
Train Loss: 7.58 Accuracy: 34.38%
Epoch 0, Iteration 521/657 
Train Loss: 5.81 Accuracy: 56.25%
Epoch 0, Iteration 522/657 
Train Loss: 6.50 Accuracy: 51.56%
Epoch 0, Iteration 523/657 
Train Loss: 7.08 Accuracy: 39.06%
Epoch 0, Iteration 524/657 
Train Loss: 6.52 Accuracy: 50.00%
	Current speed:3.7791485901612982 iterations per second
Epoch 0, Iteration 525/657 
Train Loss: 6.64 Accuracy: 48.44%
Epoch 0, Iteration 526/657 
Train Loss: 5.97 Accuracy: 57.81%
Epoch 0, Iteration 527/657 
Train Loss: 6.54 Accuracy: 51.56%
Epoch 0, Iteration 528/657 
Train Loss: 5.23 Accuracy: 64.06%
Epoch 0, Iteration 529/657 
Train Loss: 5.50 Accuracy: 57.81%
Epoch 0, Iteration 530/657 
Train Loss: 6.45 Accuracy: 43.75%
Epoch 0, Iteration 531/657 
Train Loss: 4.83 Accuracy: 57.81%
Epoch 0, Iteration 532/657 
Train Loss: 6.10 Accuracy: 50.00%
Epoch 0, Iteration 533/657 
Train Loss: 5.78 Accuracy: 54.69%
Epoch 0, Iteration 534/657 
Train Loss: 4.87 Accuracy: 57.81%
Epoch 0, Iteration 535/657 
Train Loss: 5.86 Accuracy: 56.25%
Epoch 0, Iteration 536/657 
Train Loss: 5.22 Accuracy: 57.81%
Epoch 0, Iteration 537/657 
Train Loss: 5.92 Accuracy: 54.69%
Epoch 0, Iteration 538/657 
Train Loss: 5.70 Accuracy: 51.56%
Epoch 0, Iteration 539/657 
Train Loss: 5.76 Accuracy: 54.69%
Epoch 0, Iteration 540/657 
Train Loss: 6.72 Accuracy: 56.25%
Epoch 0, Iteration 541/657 
Train Loss: 5.50 Accuracy: 59.38%
Epoch 0, Iteration 542/657 
Train Loss: 5.42 Accuracy: 54.69%
Epoch 0, Iteration 543/657 
Train Loss: 5.52 Accuracy: 60.94%
Epoch 0, Iteration 544/657 
Train Loss: 5.48 Accuracy: 51.56%
Epoch 0, Iteration 545/657 
Train Loss: 5.44 Accuracy: 56.25%
Epoch 0, Iteration 546/657 
Train Loss: 5.97 Accuracy: 46.88%
Epoch 0, Iteration 547/657 
Train Loss: 7.27 Accuracy: 40.62%
Epoch 0, Iteration 548/657 
Train Loss: 5.87 Accuracy: 57.81%
Epoch 0, Iteration 549/657 
Train Loss: 5.37 Accuracy: 54.69%
	Current speed:3.7719535777998527 iterations per second
Epoch 0, Iteration 550/657 
Train Loss: 4.91 Accuracy: 59.38%
Epoch 0, Iteration 551/657 
Train Loss: 5.97 Accuracy: 46.88%
Epoch 0, Iteration 552/657 
Train Loss: 6.24 Accuracy: 54.69%
Epoch 0, Iteration 553/657 
Train Loss: 5.66 Accuracy: 54.69%
Epoch 0, Iteration 554/657 
Train Loss: 5.95 Accuracy: 53.12%
Epoch 0, Iteration 555/657 
Train Loss: 4.94 Accuracy: 62.50%
Epoch 0, Iteration 556/657 
Train Loss: 6.00 Accuracy: 46.88%
Epoch 0, Iteration 557/657 
Train Loss: 4.96 Accuracy: 62.50%
Epoch 0, Iteration 558/657 
Train Loss: 5.29 Accuracy: 57.81%
Epoch 0, Iteration 559/657 
Train Loss: 7.18 Accuracy: 42.19%
Epoch 0, Iteration 560/657 
Train Loss: 6.16 Accuracy: 53.12%
Epoch 0, Iteration 561/657 
Train Loss: 4.25 Accuracy: 67.19%
Epoch 0, Iteration 562/657 
Train Loss: 5.72 Accuracy: 57.81%
Epoch 0, Iteration 563/657 
Train Loss: 6.23 Accuracy: 48.44%
Epoch 0, Iteration 564/657 
Train Loss: 5.07 Accuracy: 64.06%
Epoch 0, Iteration 565/657 
Train Loss: 5.03 Accuracy: 64.06%
Epoch 0, Iteration 566/657 
Train Loss: 5.78 Accuracy: 59.38%
Epoch 0, Iteration 567/657 
Train Loss: 4.82 Accuracy: 64.06%
Epoch 0, Iteration 568/657 
Train Loss: 5.72 Accuracy: 57.81%
Epoch 0, Iteration 569/657 
Train Loss: 5.84 Accuracy: 54.69%
Epoch 0, Iteration 570/657 
Train Loss: 6.80 Accuracy: 42.19%
Epoch 0, Iteration 571/657 
Train Loss: 5.67 Accuracy: 59.38%
Epoch 0, Iteration 572/657 
Train Loss: 5.70 Accuracy: 50.00%
Epoch 0, Iteration 573/657 
Train Loss: 6.59 Accuracy: 48.44%
Epoch 0, Iteration 574/657 
Train Loss: 3.91 Accuracy: 71.88%
	Current speed:3.7620443398562746 iterations per second
Epoch 0, Iteration 575/657 
Train Loss: 4.74 Accuracy: 65.62%
Epoch 0, Iteration 576/657 
Train Loss: 6.27 Accuracy: 51.56%
Epoch 0, Iteration 577/657 
Train Loss: 6.92 Accuracy: 46.88%
Epoch 0, Iteration 578/657 
Train Loss: 5.90 Accuracy: 51.56%
Epoch 0, Iteration 579/657 
Train Loss: 5.78 Accuracy: 54.69%
Epoch 0, Iteration 580/657 
Train Loss: 5.28 Accuracy: 59.38%
Epoch 0, Iteration 581/657 
Train Loss: 6.25 Accuracy: 48.44%
Epoch 0, Iteration 582/657 
Train Loss: 6.48 Accuracy: 45.31%
Epoch 0, Iteration 583/657 
Train Loss: 4.91 Accuracy: 65.62%
Epoch 0, Iteration 584/657 
Train Loss: 5.85 Accuracy: 62.50%
Epoch 0, Iteration 585/657 
Train Loss: 5.75 Accuracy: 51.56%
Epoch 0, Iteration 586/657 
Train Loss: 6.15 Accuracy: 50.00%
Epoch 0, Iteration 587/657 
Train Loss: 4.95 Accuracy: 59.38%
Epoch 0, Iteration 588/657 
Train Loss: 5.41 Accuracy: 62.50%
Epoch 0, Iteration 589/657 
Train Loss: 6.31 Accuracy: 46.88%
Epoch 0, Iteration 590/657 
Train Loss: 4.69 Accuracy: 65.62%
Epoch 0, Iteration 591/657 
Train Loss: 6.02 Accuracy: 50.00%
Epoch 0, Iteration 592/657 
Train Loss: 5.00 Accuracy: 62.50%
Epoch 0, Iteration 593/657 
Train Loss: 5.80 Accuracy: 53.12%
Epoch 0, Iteration 594/657 
Train Loss: 5.30 Accuracy: 56.25%
Epoch 0, Iteration 595/657 
Train Loss: 4.88 Accuracy: 62.50%
Epoch 0, Iteration 596/657 
Train Loss: 5.18 Accuracy: 57.81%
Epoch 0, Iteration 597/657 
Train Loss: 5.87 Accuracy: 51.56%
Epoch 0, Iteration 598/657 
Train Loss: 5.21 Accuracy: 53.12%
Epoch 0, Iteration 599/657 
Train Loss: 5.17 Accuracy: 54.69%
	Current speed:3.7562185415709797 iterations per second
Epoch 0, Iteration 600/657 
Train Loss: 5.63 Accuracy: 53.12%
Epoch 0, Iteration 601/657 
Train Loss: 6.60 Accuracy: 48.44%
Epoch 0, Iteration 602/657 
Train Loss: 5.28 Accuracy: 54.69%
Epoch 0, Iteration 603/657 
Train Loss: 5.14 Accuracy: 57.81%
Epoch 0, Iteration 604/657 
Train Loss: 6.02 Accuracy: 54.69%
Epoch 0, Iteration 605/657 
Train Loss: 6.09 Accuracy: 45.31%
Epoch 0, Iteration 606/657 
Train Loss: 6.33 Accuracy: 54.69%
Epoch 0, Iteration 607/657 
Train Loss: 5.11 Accuracy: 65.62%
Epoch 0, Iteration 608/657 
Train Loss: 4.58 Accuracy: 64.06%
Epoch 0, Iteration 609/657 
Train Loss: 6.12 Accuracy: 50.00%
Epoch 0, Iteration 610/657 
Train Loss: 5.57 Accuracy: 60.94%
Epoch 0, Iteration 611/657 
Train Loss: 6.18 Accuracy: 45.31%
Epoch 0, Iteration 612/657 
Train Loss: 6.29 Accuracy: 50.00%
Epoch 0, Iteration 613/657 
Train Loss: 5.92 Accuracy: 54.69%
Epoch 0, Iteration 614/657 
Train Loss: 5.54 Accuracy: 59.38%
Epoch 0, Iteration 615/657 
Train Loss: 5.96 Accuracy: 51.56%
Epoch 0, Iteration 616/657 
Train Loss: 5.47 Accuracy: 56.25%
Epoch 0, Iteration 617/657 
Train Loss: 5.14 Accuracy: 67.19%
Epoch 0, Iteration 618/657 
Train Loss: 5.18 Accuracy: 67.19%
Epoch 0, Iteration 619/657 
Train Loss: 5.14 Accuracy: 64.06%
Epoch 0, Iteration 620/657 
Train Loss: 4.68 Accuracy: 62.50%
Epoch 0, Iteration 621/657 
Train Loss: 4.27 Accuracy: 68.75%
Epoch 0, Iteration 622/657 
Train Loss: 4.75 Accuracy: 68.75%
Epoch 0, Iteration 623/657 
Train Loss: 5.90 Accuracy: 57.81%
Epoch 0, Iteration 624/657 
Train Loss: 5.51 Accuracy: 62.50%
	Current speed:3.7489120398241362 iterations per second
Epoch 0, Iteration 625/657 
Train Loss: 5.11 Accuracy: 64.06%
Epoch 0, Iteration 626/657 
Train Loss: 5.41 Accuracy: 53.12%
Epoch 0, Iteration 627/657 
Train Loss: 4.19 Accuracy: 65.62%
Epoch 0, Iteration 628/657 
Train Loss: 4.95 Accuracy: 62.50%
Epoch 0, Iteration 629/657 
Train Loss: 4.54 Accuracy: 65.62%
Epoch 0, Iteration 630/657 
Train Loss: 4.15 Accuracy: 65.62%
Epoch 0, Iteration 631/657 
Train Loss: 5.55 Accuracy: 51.56%
Epoch 0, Iteration 632/657 
Train Loss: 6.29 Accuracy: 46.88%
Epoch 0, Iteration 633/657 
Train Loss: 4.97 Accuracy: 56.25%
Epoch 0, Iteration 634/657 
Train Loss: 4.73 Accuracy: 60.94%
Epoch 0, Iteration 635/657 
Train Loss: 6.11 Accuracy: 48.44%
Epoch 0, Iteration 636/657 
Train Loss: 6.23 Accuracy: 48.44%
Epoch 0, Iteration 637/657 
Train Loss: 4.48 Accuracy: 65.62%
Epoch 0, Iteration 638/657 
Train Loss: 5.74 Accuracy: 48.44%
Epoch 0, Iteration 639/657 
Train Loss: 3.84 Accuracy: 75.00%
Epoch 0, Iteration 640/657 
Train Loss: 5.38 Accuracy: 60.94%
Epoch 0, Iteration 641/657 
Train Loss: 5.23 Accuracy: 54.69%
Epoch 0, Iteration 642/657 
Train Loss: 5.11 Accuracy: 56.25%
Epoch 0, Iteration 643/657 
Train Loss: 3.13 Accuracy: 78.12%
Epoch 0, Iteration 644/657 
Train Loss: 5.20 Accuracy: 59.38%
Epoch 0, Iteration 645/657 
Train Loss: 4.61 Accuracy: 60.94%
Epoch 0, Iteration 646/657 
Train Loss: 6.02 Accuracy: 51.56%
Epoch 0, Iteration 647/657 
Train Loss: 6.33 Accuracy: 51.56%
Epoch 0, Iteration 648/657 
Train Loss: 5.24 Accuracy: 54.69%
Epoch 0, Iteration 649/657 
Train Loss: 4.77 Accuracy: 62.50%
	Current speed:3.743454657208673 iterations per second
Epoch 0, Iteration 650/657 
Train Loss: 5.08 Accuracy: 62.50%
Epoch 0, Iteration 651/657 
Train Loss: 5.14 Accuracy: 62.50%
Epoch 0, Iteration 652/657 
Train Loss: 4.74 Accuracy: 73.44%
Epoch 0, Iteration 653/657 
Train Loss: 4.99 Accuracy: 60.94%
Epoch 0, Iteration 654/657 
Train Loss: 5.04 Accuracy: 64.06%
Epoch 0, Iteration 655/657 
Train Loss: 5.71 Accuracy: 53.12%
Epoch 0, Iteration 656/657 
Train Loss: 4.58 Accuracy: 68.75%
Training time (s):  175.39906692504883
Time spent converting dataset (s / %):  46.85016059875488 26.710609936582387
Time spent in forward pass (s / %): 71.40714931488037 40.71124810794685
Time spent in learning (s / %) 55.500027656555176 31.6421453258194
Time spent loading data (s / %): 1.6417293548583984 0.9359966296513647
Total correctly classified test set images: 11771/18000
Test Set Accuracy: 65.39%
[('conv', {'num-filters': ['89'], 'filter-shape': ['4'], 'stride': ['2'], 'padding': ['same'], 'bias': ['True']}), ('pool-max', {'kernel-size': ['4']}), ('act', {'beta': ['0.5424804602129135'], 'beta-trainable': ['False'], 'threshold': ['0.9017362278811754'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['zero']}), ('conv', {'num-filters': ['97'], 'filter-shape': ['3'], 'stride': ['3'], 'padding': ['valid'], 'bias': ['True']}), ('pool-max', {'kernel-size': ['2']}), ('act', {'beta': ['0.7061820603607597'], 'beta-trainable': ['True'], 'threshold': ['1.2820746719491745'], 'threshold-trainable': ['True'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']}), ('dropout', {'rate': ['0.00626363862143231']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.7201063081299326'], 'beta-trainable': ['True'], 'threshold': ['0.8898450339202282'], 'threshold-trainable': ['True'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Conv2d(1, 89, kernel_size=(4, 4), stride=(1, 1), padding=same)
  (1): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
  (2): Leaky()
  (3): Conv2d(89, 97, kernel_size=(3, 3), stride=(3, 3), padding=valid)
  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (5): Leaky()
  (6): Dropout(p=0.00626363862143231, inplace=False)
  (7): Flatten(start_dim=1, end_dim=-1)
  (8): Linear(in_features=97, out_features=10, bias=True)
  (9): Leaky()
)
	Current speed:0.0 iterations per second
Epoch 0, Iteration 0/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 1/657 
Train Loss: 59.88 Accuracy: 23.44%
Epoch 0, Iteration 2/657 
Train Loss: 18.75 Accuracy: 6.25%
Epoch 0, Iteration 3/657 
Train Loss: 12.00 Accuracy: 17.19%
Epoch 0, Iteration 4/657 
Train Loss: 10.00 Accuracy: 14.06%
Epoch 0, Iteration 5/657 
Train Loss: 10.07 Accuracy: 10.94%
Epoch 0, Iteration 6/657 
Train Loss: 12.34 Accuracy: 14.06%
Epoch 0, Iteration 7/657 
Train Loss: 10.00 Accuracy: 15.62%
Epoch 0, Iteration 8/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 9/657 
Train Loss: 10.00 Accuracy: 17.19%
Epoch 0, Iteration 10/657 
Train Loss: 15.33 Accuracy: 20.31%
Epoch 0, Iteration 11/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 12/657 
Train Loss: 11.56 Accuracy: 9.38%
Epoch 0, Iteration 13/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 14/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 15/657 
Train Loss: 10.11 Accuracy: 9.38%
Epoch 0, Iteration 16/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 17/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 18/657 
Train Loss: 10.00 Accuracy: 4.69%
Epoch 0, Iteration 19/657 
Train Loss: 15.71 Accuracy: 15.62%
Epoch 0, Iteration 20/657 
Train Loss: 10.68 Accuracy: 17.19%
Epoch 0, Iteration 21/657 
Train Loss: 10.00 Accuracy: 4.69%
Epoch 0, Iteration 22/657 
Train Loss: 10.00 Accuracy: 4.69%
Epoch 0, Iteration 23/657 
Train Loss: 10.00 Accuracy: 14.06%
Epoch 0, Iteration 24/657 
Train Loss: 9.97 Accuracy: 10.94%
	Current speed:1.954074653845437 iterations per second
Epoch 0, Iteration 25/657 
Train Loss: 11.74 Accuracy: 7.81%
Epoch 0, Iteration 26/657 
Train Loss: 10.00 Accuracy: 4.69%
Epoch 0, Iteration 27/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 28/657 
Train Loss: 11.28 Accuracy: 10.94%
Epoch 0, Iteration 29/657 
Train Loss: 10.00 Accuracy: 4.69%
Epoch 0, Iteration 30/657 
Train Loss: 17.50 Accuracy: 7.81%
Epoch 0, Iteration 31/657 
Train Loss: 12.52 Accuracy: 6.25%
Epoch 0, Iteration 32/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 33/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 34/657 
Train Loss: 25.15 Accuracy: 10.94%
Epoch 0, Iteration 35/657 
Train Loss: 10.97 Accuracy: 10.94%
Epoch 0, Iteration 36/657 
Train Loss: 10.00 Accuracy: 14.06%
Epoch 0, Iteration 37/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 38/657 
Train Loss: 9.95 Accuracy: 12.50%
Epoch 0, Iteration 39/657 
Train Loss: 21.39 Accuracy: 10.94%
Epoch 0, Iteration 40/657 
Train Loss: 11.88 Accuracy: 7.81%
Epoch 0, Iteration 41/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 42/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 43/657 
Train Loss: 10.00 Accuracy: 4.69%
Epoch 0, Iteration 44/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 45/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 46/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 47/657 
Train Loss: 11.58 Accuracy: 9.38%
Epoch 0, Iteration 48/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 49/657 
Train Loss: 10.00 Accuracy: 9.38%
	Current speed:2.017394645641647 iterations per second
Epoch 0, Iteration 50/657 
Train Loss: 11.40 Accuracy: 10.94%
Epoch 0, Iteration 51/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 52/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 53/657 
Train Loss: 11.55 Accuracy: 9.38%
Epoch 0, Iteration 54/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 55/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 56/657 
Train Loss: 22.49 Accuracy: 12.50%
Epoch 0, Iteration 57/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 58/657 
Train Loss: 10.00 Accuracy: 0.00%
Epoch 0, Iteration 59/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 60/657 
Train Loss: 13.05 Accuracy: 6.25%
Epoch 0, Iteration 61/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 62/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 63/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 64/657 
Train Loss: 10.76 Accuracy: 10.94%
Epoch 0, Iteration 65/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 66/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 67/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 68/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 69/657 
Train Loss: 11.24 Accuracy: 12.50%
Epoch 0, Iteration 70/657 
Train Loss: 10.00 Accuracy: 18.75%
Epoch 0, Iteration 71/657 
Train Loss: 10.00 Accuracy: 15.62%
Epoch 0, Iteration 72/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 73/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 74/657 
Train Loss: 9.95 Accuracy: 12.50%
	Current speed:2.0463086379833824 iterations per second
Epoch 0, Iteration 75/657 
Train Loss: 10.00 Accuracy: 15.62%
Epoch 0, Iteration 76/657 
Train Loss: 10.00 Accuracy: 4.69%
Epoch 0, Iteration 77/657 
Train Loss: 10.45 Accuracy: 20.31%
Epoch 0, Iteration 78/657 
Train Loss: 10.00 Accuracy: 14.06%
Epoch 0, Iteration 79/657 
Train Loss: 13.67 Accuracy: 9.38%
Epoch 0, Iteration 80/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 81/657 
Train Loss: 10.16 Accuracy: 10.94%
Epoch 0, Iteration 82/657 
Train Loss: 10.75 Accuracy: 15.62%
Epoch 0, Iteration 83/657 
Train Loss: 12.15 Accuracy: 3.12%
Epoch 0, Iteration 84/657 
Train Loss: 9.92 Accuracy: 7.81%
Epoch 0, Iteration 85/657 
Train Loss: 12.07 Accuracy: 10.94%
Epoch 0, Iteration 86/657 
Train Loss: 11.56 Accuracy: 9.38%
Epoch 0, Iteration 87/657 
Train Loss: 11.09 Accuracy: 14.06%
Epoch 0, Iteration 88/657 
Train Loss: 9.98 Accuracy: 7.81%
Epoch 0, Iteration 89/657 
Train Loss: 17.06 Accuracy: 10.94%
Epoch 0, Iteration 90/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 91/657 
Train Loss: 11.88 Accuracy: 6.25%
Epoch 0, Iteration 92/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 93/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 94/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 95/657 
Train Loss: 10.00 Accuracy: 14.06%
Epoch 0, Iteration 96/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 97/657 
Train Loss: 10.97 Accuracy: 7.81%
Epoch 0, Iteration 98/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 99/657 
Train Loss: 10.00 Accuracy: 7.81%
	Current speed:2.0609362391561534 iterations per second
Epoch 0, Iteration 100/657 
Train Loss: 13.57 Accuracy: 3.12%
Epoch 0, Iteration 101/657 
Train Loss: 9.83 Accuracy: 15.62%
Epoch 0, Iteration 102/657 
Train Loss: 11.77 Accuracy: 15.62%
Epoch 0, Iteration 103/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 104/657 
Train Loss: 11.41 Accuracy: 4.69%
Epoch 0, Iteration 105/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 106/657 
Train Loss: 10.01 Accuracy: 7.81%
Epoch 0, Iteration 107/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 108/657 
Train Loss: 10.00 Accuracy: 14.06%
Epoch 0, Iteration 109/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 110/657 
Train Loss: 10.00 Accuracy: 4.69%
Epoch 0, Iteration 111/657 
Train Loss: 10.13 Accuracy: 15.62%
Epoch 0, Iteration 112/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 113/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 114/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 115/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 116/657 
Train Loss: 10.00 Accuracy: 3.12%
Epoch 0, Iteration 117/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 118/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 119/657 
Train Loss: 10.00 Accuracy: 4.69%
Epoch 0, Iteration 120/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 121/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 122/657 
Train Loss: 10.00 Accuracy: 4.69%
Epoch 0, Iteration 123/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 124/657 
Train Loss: 10.00 Accuracy: 14.06%
	Current speed:2.0673209392339076 iterations per second
Epoch 0, Iteration 125/657 
Train Loss: 10.00 Accuracy: 4.69%
Epoch 0, Iteration 126/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 127/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 128/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 129/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 130/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 131/657 
Train Loss: 10.00 Accuracy: 18.75%
Epoch 0, Iteration 132/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 133/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 134/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 135/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 136/657 
Train Loss: 10.00 Accuracy: 3.12%
Epoch 0, Iteration 137/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 138/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 139/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 140/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 141/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 142/657 
Train Loss: 10.00 Accuracy: 15.62%
Epoch 0, Iteration 143/657 
Train Loss: 10.00 Accuracy: 4.69%
Epoch 0, Iteration 144/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 145/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 146/657 
Train Loss: 10.00 Accuracy: 18.75%
Epoch 0, Iteration 147/657 
Train Loss: 12.19 Accuracy: 3.12%
Epoch 0, Iteration 148/657 
Train Loss: 11.72 Accuracy: 7.81%
Epoch 0, Iteration 149/657 
Train Loss: 11.41 Accuracy: 10.94%
	Current speed:2.0734475254218587 iterations per second
Epoch 0, Iteration 150/657 
Train Loss: 11.72 Accuracy: 7.81%
Epoch 0, Iteration 151/657 
Train Loss: 12.50 Accuracy: 17.19%
Epoch 0, Iteration 152/657 
Train Loss: 11.72 Accuracy: 7.81%
Epoch 0, Iteration 153/657 
Train Loss: 11.41 Accuracy: 10.94%
Epoch 0, Iteration 154/657 
Train Loss: 10.78 Accuracy: 17.19%
Epoch 0, Iteration 155/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 156/657 
Train Loss: 11.41 Accuracy: 10.94%
Epoch 0, Iteration 157/657 
Train Loss: 11.57 Accuracy: 9.38%
Epoch 0, Iteration 158/657 
Train Loss: 17.02 Accuracy: 14.06%
Epoch 0, Iteration 159/657 
Train Loss: 11.42 Accuracy: 10.94%
Epoch 0, Iteration 160/657 
Train Loss: 21.60 Accuracy: 18.75%
Epoch 0, Iteration 161/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 162/657 
Train Loss: 12.40 Accuracy: 14.06%
Epoch 0, Iteration 163/657 
Train Loss: 11.56 Accuracy: 9.38%
Epoch 0, Iteration 164/657 
Train Loss: 11.24 Accuracy: 12.50%
Epoch 0, Iteration 165/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 166/657 
Train Loss: 12.79 Accuracy: 10.94%
Epoch 0, Iteration 167/657 
Train Loss: 11.05 Accuracy: 9.38%
Epoch 0, Iteration 168/657 
Train Loss: 10.87 Accuracy: 14.06%
Epoch 0, Iteration 169/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 170/657 
Train Loss: 10.00 Accuracy: 14.06%
Epoch 0, Iteration 171/657 
Train Loss: 9.87 Accuracy: 10.94%
Epoch 0, Iteration 172/657 
Train Loss: 18.33 Accuracy: 3.12%
Epoch 0, Iteration 173/657 
Train Loss: 14.06 Accuracy: 15.62%
Epoch 0, Iteration 174/657 
Train Loss: 10.97 Accuracy: 9.38%
	Current speed:2.0789517574408625 iterations per second
Epoch 0, Iteration 175/657 
Train Loss: 10.40 Accuracy: 6.25%
Epoch 0, Iteration 176/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 177/657 
Train Loss: 10.00 Accuracy: 18.75%
Epoch 0, Iteration 178/657 
Train Loss: 11.88 Accuracy: 6.25%
Epoch 0, Iteration 179/657 
Train Loss: 11.20 Accuracy: 9.38%
Epoch 0, Iteration 180/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 181/657 
Train Loss: 12.40 Accuracy: 10.94%
Epoch 0, Iteration 182/657 
Train Loss: 11.84 Accuracy: 6.25%
Epoch 0, Iteration 183/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 184/657 
Train Loss: 19.01 Accuracy: 4.69%
Epoch 0, Iteration 185/657 
Train Loss: 9.97 Accuracy: 10.94%
Epoch 0, Iteration 186/657 
Train Loss: 15.65 Accuracy: 10.94%
Epoch 0, Iteration 187/657 
Train Loss: 11.95 Accuracy: 10.94%
Epoch 0, Iteration 188/657 
Train Loss: 10.90 Accuracy: 15.62%
Epoch 0, Iteration 189/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 190/657 
Train Loss: 11.39 Accuracy: 10.94%
Epoch 0, Iteration 191/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 192/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 193/657 
Train Loss: 10.74 Accuracy: 17.19%
Epoch 0, Iteration 194/657 
Train Loss: 10.76 Accuracy: 9.38%
Epoch 0, Iteration 195/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 196/657 
Train Loss: 10.07 Accuracy: 7.81%
Epoch 0, Iteration 197/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 198/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 199/657 
Train Loss: 10.00 Accuracy: 6.25%
	Current speed:2.0830467789269203 iterations per second
Epoch 0, Iteration 200/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 201/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 202/657 
Train Loss: 10.00 Accuracy: 15.62%
Epoch 0, Iteration 203/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 204/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 205/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 206/657 
Train Loss: 10.00 Accuracy: 23.44%
Epoch 0, Iteration 207/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 208/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 209/657 
Train Loss: 10.00 Accuracy: 4.69%
Epoch 0, Iteration 210/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 211/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 212/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 213/657 
Train Loss: 10.00 Accuracy: 3.12%
Epoch 0, Iteration 214/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 215/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 216/657 
Train Loss: 10.00 Accuracy: 15.62%
Epoch 0, Iteration 217/657 
Train Loss: 11.09 Accuracy: 14.06%
Epoch 0, Iteration 218/657 
Train Loss: 10.62 Accuracy: 18.75%
Epoch 0, Iteration 219/657 
Train Loss: 11.41 Accuracy: 10.94%
Epoch 0, Iteration 220/657 
Train Loss: 11.72 Accuracy: 7.81%
Epoch 0, Iteration 221/657 
Train Loss: 13.28 Accuracy: 6.25%
Epoch 0, Iteration 222/657 
Train Loss: 14.06 Accuracy: 9.38%
Epoch 0, Iteration 223/657 
Train Loss: 14.71 Accuracy: 14.06%
Epoch 0, Iteration 224/657 
Train Loss: 12.63 Accuracy: 10.94%
	Current speed:2.086578762897918 iterations per second
Epoch 0, Iteration 225/657 
Train Loss: 11.97 Accuracy: 3.12%
Epoch 0, Iteration 226/657 
Train Loss: 12.56 Accuracy: 14.06%
Epoch 0, Iteration 227/657 
Train Loss: 12.68 Accuracy: 10.94%
Epoch 0, Iteration 228/657 
Train Loss: 13.52 Accuracy: 9.38%
Epoch 0, Iteration 229/657 
Train Loss: 9.98 Accuracy: 9.38%
Epoch 0, Iteration 230/657 
Train Loss: 13.20 Accuracy: 12.50%
Epoch 0, Iteration 231/657 
Train Loss: 10.01 Accuracy: 4.69%
Epoch 0, Iteration 232/657 
Train Loss: 11.70 Accuracy: 6.25%
Epoch 0, Iteration 233/657 
Train Loss: 9.97 Accuracy: 18.75%
Epoch 0, Iteration 234/657 
Train Loss: 12.39 Accuracy: 10.94%
Epoch 0, Iteration 235/657 
Train Loss: 14.17 Accuracy: 15.62%
Epoch 0, Iteration 236/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 237/657 
Train Loss: 10.07 Accuracy: 18.75%
Epoch 0, Iteration 238/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 239/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 240/657 
Train Loss: 9.90 Accuracy: 12.50%
Epoch 0, Iteration 241/657 
Train Loss: 12.19 Accuracy: 3.12%
Epoch 0, Iteration 242/657 
Train Loss: 11.88 Accuracy: 6.25%
Epoch 0, Iteration 243/657 
Train Loss: 11.21 Accuracy: 7.81%
Epoch 0, Iteration 244/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 245/657 
Train Loss: 14.73 Accuracy: 14.06%
Epoch 0, Iteration 246/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 247/657 
Train Loss: 11.03 Accuracy: 7.81%
Epoch 0, Iteration 248/657 
Train Loss: 10.00 Accuracy: 4.69%
Epoch 0, Iteration 249/657 
Train Loss: 10.00 Accuracy: 12.50%
	Current speed:2.088804048665818 iterations per second
Epoch 0, Iteration 250/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 251/657 
Train Loss: 14.04 Accuracy: 4.69%
Epoch 0, Iteration 252/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 253/657 
Train Loss: 11.69 Accuracy: 7.81%
Epoch 0, Iteration 254/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 255/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 256/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 257/657 
Train Loss: 10.00 Accuracy: 14.06%
Epoch 0, Iteration 258/657 
Train Loss: 9.84 Accuracy: 17.19%
Epoch 0, Iteration 259/657 
Train Loss: 11.98 Accuracy: 4.69%
Epoch 0, Iteration 260/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 261/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 262/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 263/657 
Train Loss: 14.35 Accuracy: 7.81%
Epoch 0, Iteration 264/657 
Train Loss: 14.02 Accuracy: 4.69%
Epoch 0, Iteration 265/657 
Train Loss: 12.71 Accuracy: 10.94%
Epoch 0, Iteration 266/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 267/657 
Train Loss: 11.37 Accuracy: 10.94%
Epoch 0, Iteration 268/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 269/657 
Train Loss: 11.08 Accuracy: 14.06%
Epoch 0, Iteration 270/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 271/657 
Train Loss: 10.25 Accuracy: 7.81%
Epoch 0, Iteration 272/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 273/657 
Train Loss: 10.00 Accuracy: 14.06%
Epoch 0, Iteration 274/657 
Train Loss: 10.00 Accuracy: 12.50%
	Current speed:2.0907940132504588 iterations per second
Epoch 0, Iteration 275/657 
Train Loss: 13.41 Accuracy: 6.25%
Epoch 0, Iteration 276/657 
Train Loss: 10.01 Accuracy: 4.69%
Epoch 0, Iteration 277/657 
Train Loss: 9.95 Accuracy: 18.75%
Epoch 0, Iteration 278/657 
Train Loss: 10.02 Accuracy: 7.81%
Epoch 0, Iteration 279/657 
Train Loss: 10.00 Accuracy: 4.69%
Epoch 0, Iteration 280/657 
Train Loss: 11.54 Accuracy: 4.69%
Epoch 0, Iteration 281/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 282/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 283/657 
Train Loss: 10.00 Accuracy: 18.75%
Epoch 0, Iteration 284/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 285/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 286/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 287/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 288/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 289/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 290/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 291/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 292/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 293/657 
Train Loss: 10.00 Accuracy: 4.69%
Epoch 0, Iteration 294/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 295/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 296/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 297/657 
Train Loss: 10.00 Accuracy: 14.06%
Epoch 0, Iteration 298/657 
Train Loss: 10.12 Accuracy: 14.06%
Epoch 0, Iteration 299/657 
Train Loss: 10.55 Accuracy: 14.06%
	Current speed:2.0931811794843536 iterations per second
Epoch 0, Iteration 300/657 
Train Loss: 10.68 Accuracy: 6.25%
Epoch 0, Iteration 301/657 
Train Loss: 10.16 Accuracy: 9.38%
Epoch 0, Iteration 302/657 
Train Loss: 10.08 Accuracy: 10.94%
Epoch 0, Iteration 303/657 
Train Loss: 10.76 Accuracy: 9.38%
Epoch 0, Iteration 304/657 
Train Loss: 9.97 Accuracy: 17.19%
Epoch 0, Iteration 305/657 
Train Loss: 11.54 Accuracy: 9.38%
Epoch 0, Iteration 306/657 
Train Loss: 10.40 Accuracy: 4.69%
Epoch 0, Iteration 307/657 
Train Loss: 10.06 Accuracy: 4.69%
Epoch 0, Iteration 308/657 
Train Loss: 9.91 Accuracy: 12.50%
Epoch 0, Iteration 309/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 310/657 
Train Loss: 10.19 Accuracy: 12.50%
Epoch 0, Iteration 311/657 
Train Loss: 9.80 Accuracy: 6.25%
Epoch 0, Iteration 312/657 
Train Loss: 10.31 Accuracy: 6.25%
Epoch 0, Iteration 313/657 
Train Loss: 9.96 Accuracy: 9.38%
Epoch 0, Iteration 314/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 315/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 316/657 
Train Loss: 10.00 Accuracy: 4.69%
Epoch 0, Iteration 317/657 
Train Loss: 10.02 Accuracy: 9.38%
Epoch 0, Iteration 318/657 
Train Loss: 9.95 Accuracy: 12.50%
Epoch 0, Iteration 319/657 
Train Loss: 10.26 Accuracy: 10.94%
Epoch 0, Iteration 320/657 
Train Loss: 11.47 Accuracy: 7.81%
Epoch 0, Iteration 321/657 
Train Loss: 11.05 Accuracy: 9.38%
Epoch 0, Iteration 322/657 
Train Loss: 11.17 Accuracy: 4.69%
Epoch 0, Iteration 323/657 
Train Loss: 9.85 Accuracy: 12.50%
Epoch 0, Iteration 324/657 
Train Loss: 9.88 Accuracy: 10.94%
	Current speed:2.0940313166741467 iterations per second
Epoch 0, Iteration 325/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 326/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 327/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 328/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 329/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 330/657 
Train Loss: 9.99 Accuracy: 12.50%
Epoch 0, Iteration 331/657 
Train Loss: 9.43 Accuracy: 14.06%
Epoch 0, Iteration 332/657 
Train Loss: 10.43 Accuracy: 4.69%
Epoch 0, Iteration 333/657 
Train Loss: 10.17 Accuracy: 9.38%
Epoch 0, Iteration 334/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 335/657 
Train Loss: 10.23 Accuracy: 6.25%
Epoch 0, Iteration 336/657 
Train Loss: 16.37 Accuracy: 14.06%
Epoch 0, Iteration 337/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 338/657 
Train Loss: 11.88 Accuracy: 6.25%
Epoch 0, Iteration 339/657 
Train Loss: 10.00 Accuracy: 3.12%
Epoch 0, Iteration 340/657 
Train Loss: 10.00 Accuracy: 15.62%
Epoch 0, Iteration 341/657 
Train Loss: 10.32 Accuracy: 7.81%
Epoch 0, Iteration 342/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 343/657 
Train Loss: 9.99 Accuracy: 7.81%
Epoch 0, Iteration 344/657 
Train Loss: 9.98 Accuracy: 15.62%
Epoch 0, Iteration 345/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 346/657 
Train Loss: 13.32 Accuracy: 14.06%
Epoch 0, Iteration 347/657 
Train Loss: 10.77 Accuracy: 9.38%
Epoch 0, Iteration 348/657 
Train Loss: 11.56 Accuracy: 9.38%
Epoch 0, Iteration 349/657 
Train Loss: 10.00 Accuracy: 14.06%
	Current speed:2.095608608209866 iterations per second
Epoch 0, Iteration 350/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 351/657 
Train Loss: 13.89 Accuracy: 7.81%
Epoch 0, Iteration 352/657 
Train Loss: 9.99 Accuracy: 9.38%
Epoch 0, Iteration 353/657 
Train Loss: 15.78 Accuracy: 12.50%
Epoch 0, Iteration 354/657 
Train Loss: 14.53 Accuracy: 9.38%
Epoch 0, Iteration 355/657 
Train Loss: 13.90 Accuracy: 26.56%
Epoch 0, Iteration 356/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 357/657 
Train Loss: 10.38 Accuracy: 9.38%
Epoch 0, Iteration 358/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 359/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 360/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 361/657 
Train Loss: 9.98 Accuracy: 4.69%
Epoch 0, Iteration 362/657 
Train Loss: 11.33 Accuracy: 17.19%
Epoch 0, Iteration 363/657 
Train Loss: 11.88 Accuracy: 6.25%
Epoch 0, Iteration 364/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 365/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 366/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 367/657 
Train Loss: 11.16 Accuracy: 6.25%
Epoch 0, Iteration 368/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 369/657 
Train Loss: 10.00 Accuracy: 4.69%
Epoch 0, Iteration 370/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 371/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 372/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 373/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 374/657 
Train Loss: 10.00 Accuracy: 17.19%
	Current speed:2.0969857146247923 iterations per second
Epoch 0, Iteration 375/657 
Train Loss: 17.55 Accuracy: 7.81%
Epoch 0, Iteration 376/657 
Train Loss: 11.48 Accuracy: 9.38%
Epoch 0, Iteration 377/657 
Train Loss: 10.00 Accuracy: 14.06%
Epoch 0, Iteration 378/657 
Train Loss: 10.43 Accuracy: 7.81%
Epoch 0, Iteration 379/657 
Train Loss: 12.18 Accuracy: 4.69%
Epoch 0, Iteration 380/657 
Train Loss: 11.36 Accuracy: 10.94%
Epoch 0, Iteration 381/657 
Train Loss: 13.12 Accuracy: 9.38%
Epoch 0, Iteration 382/657 
Train Loss: 11.87 Accuracy: 4.69%
Epoch 0, Iteration 383/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 384/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 385/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 386/657 
Train Loss: 9.99 Accuracy: 10.94%
Epoch 0, Iteration 387/657 
Train Loss: 10.99 Accuracy: 14.06%
Epoch 0, Iteration 388/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 389/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 390/657 
Train Loss: 10.00 Accuracy: 14.06%
Epoch 0, Iteration 391/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 392/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 393/657 
Train Loss: 10.00 Accuracy: 1.56%
Epoch 0, Iteration 394/657 
Train Loss: 10.00 Accuracy: 15.62%
Epoch 0, Iteration 395/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 396/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 397/657 
Train Loss: 10.00 Accuracy: 15.62%
Epoch 0, Iteration 398/657 
Train Loss: 10.00 Accuracy: 4.69%
Epoch 0, Iteration 399/657 
Train Loss: 10.00 Accuracy: 7.81%
	Current speed:2.1059246952539192 iterations per second
Epoch 0, Iteration 400/657 
Train Loss: 10.95 Accuracy: 14.06%
Epoch 0, Iteration 401/657 
Train Loss: 10.00 Accuracy: 18.75%
Epoch 0, Iteration 402/657 
Train Loss: 10.00 Accuracy: 17.19%
Epoch 0, Iteration 403/657 
Train Loss: 13.33 Accuracy: 10.94%
Epoch 0, Iteration 404/657 
Train Loss: 15.29 Accuracy: 10.94%
Epoch 0, Iteration 405/657 
Train Loss: 12.35 Accuracy: 17.19%
Epoch 0, Iteration 406/657 
Train Loss: 16.18 Accuracy: 6.25%
Epoch 0, Iteration 407/657 
Train Loss: 13.40 Accuracy: 9.38%
Epoch 0, Iteration 408/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 409/657 
Train Loss: 11.92 Accuracy: 4.69%
Epoch 0, Iteration 410/657 
Train Loss: 11.25 Accuracy: 12.50%
Epoch 0, Iteration 411/657 
Train Loss: 10.11 Accuracy: 10.94%
Epoch 0, Iteration 412/657 
Train Loss: 12.41 Accuracy: 7.81%
Epoch 0, Iteration 413/657 
Train Loss: 12.09 Accuracy: 4.69%
Epoch 0, Iteration 414/657 
Train Loss: 9.97 Accuracy: 14.06%
Epoch 0, Iteration 415/657 
Train Loss: 11.21 Accuracy: 12.50%
Epoch 0, Iteration 416/657 
Train Loss: 10.00 Accuracy: 1.56%
Epoch 0, Iteration 417/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 418/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 419/657 
Train Loss: 10.00 Accuracy: 4.69%
Epoch 0, Iteration 420/657 
Train Loss: 10.17 Accuracy: 14.06%
Epoch 0, Iteration 421/657 
Train Loss: 10.00 Accuracy: 14.06%
Epoch 0, Iteration 422/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 423/657 
Train Loss: 11.13 Accuracy: 10.94%
Epoch 0, Iteration 424/657 
Train Loss: 10.00 Accuracy: 6.25%
	Current speed:2.1181180545078484 iterations per second
Epoch 0, Iteration 425/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 426/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 427/657 
Train Loss: 10.00 Accuracy: 4.69%
Epoch 0, Iteration 428/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 429/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 430/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 431/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 432/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 433/657 
Train Loss: 10.00 Accuracy: 18.75%
Epoch 0, Iteration 434/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 435/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 436/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 437/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 438/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 439/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 440/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 441/657 
Train Loss: 10.00 Accuracy: 15.62%
Epoch 0, Iteration 442/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 443/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 444/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 445/657 
Train Loss: 10.00 Accuracy: 15.62%
Epoch 0, Iteration 446/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 447/657 
Train Loss: 10.00 Accuracy: 4.69%
Epoch 0, Iteration 448/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 449/657 
Train Loss: 10.00 Accuracy: 9.38%
	Current speed:2.1283266840226815 iterations per second
Epoch 0, Iteration 450/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 451/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 452/657 
Train Loss: 10.00 Accuracy: 17.19%
Epoch 0, Iteration 453/657 
Train Loss: 10.00 Accuracy: 4.69%
Epoch 0, Iteration 454/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 455/657 
Train Loss: 10.00 Accuracy: 15.62%
Epoch 0, Iteration 456/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 457/657 
Train Loss: 10.00 Accuracy: 18.75%
Epoch 0, Iteration 458/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 459/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 460/657 
Train Loss: 10.00 Accuracy: 15.62%
Epoch 0, Iteration 461/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 462/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 463/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 464/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 465/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 466/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 467/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 468/657 
Train Loss: 11.72 Accuracy: 7.81%
Epoch 0, Iteration 469/657 
Train Loss: 12.80 Accuracy: 9.38%
Epoch 0, Iteration 470/657 
Train Loss: 21.34 Accuracy: 6.25%
Epoch 0, Iteration 471/657 
Train Loss: 11.56 Accuracy: 9.38%
Epoch 0, Iteration 472/657 
Train Loss: 12.50 Accuracy: 15.62%
Epoch 0, Iteration 473/657 
Train Loss: 17.47 Accuracy: 7.81%
Epoch 0, Iteration 474/657 
Train Loss: 11.25 Accuracy: 12.50%
	Current speed:2.1374221492512473 iterations per second
Epoch 0, Iteration 475/657 
Train Loss: 11.56 Accuracy: 9.38%
Epoch 0, Iteration 476/657 
Train Loss: 11.44 Accuracy: 10.94%
Epoch 0, Iteration 477/657 
Train Loss: 11.72 Accuracy: 7.81%
Epoch 0, Iteration 478/657 
Train Loss: 11.25 Accuracy: 12.50%
Epoch 0, Iteration 479/657 
Train Loss: 16.10 Accuracy: 9.38%
Epoch 0, Iteration 480/657 
Train Loss: 12.73 Accuracy: 9.38%
Epoch 0, Iteration 481/657 
Train Loss: 10.41 Accuracy: 9.38%
Epoch 0, Iteration 482/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 483/657 
Train Loss: 11.24 Accuracy: 10.94%
Epoch 0, Iteration 484/657 
Train Loss: 12.78 Accuracy: 6.25%
Epoch 0, Iteration 485/657 
Train Loss: 9.99 Accuracy: 6.25%
Epoch 0, Iteration 486/657 
Train Loss: 11.56 Accuracy: 9.38%
Epoch 0, Iteration 487/657 
Train Loss: 11.72 Accuracy: 7.81%
Epoch 0, Iteration 488/657 
Train Loss: 11.51 Accuracy: 9.38%
Epoch 0, Iteration 489/657 
Train Loss: 11.10 Accuracy: 12.50%
Epoch 0, Iteration 490/657 
Train Loss: 13.11 Accuracy: 14.06%
Epoch 0, Iteration 491/657 
Train Loss: 9.87 Accuracy: 18.75%
Epoch 0, Iteration 492/657 
Train Loss: 16.67 Accuracy: 15.62%
Epoch 0, Iteration 493/657 
Train Loss: 10.75 Accuracy: 17.19%
Epoch 0, Iteration 494/657 
Train Loss: 10.00 Accuracy: 14.06%
Epoch 0, Iteration 495/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 496/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 497/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 498/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 499/657 
Train Loss: 10.00 Accuracy: 10.94%
	Current speed:2.1461530479444844 iterations per second
Epoch 0, Iteration 500/657 
Train Loss: 10.00 Accuracy: 4.69%
Epoch 0, Iteration 501/657 
Train Loss: 10.02 Accuracy: 9.38%
Epoch 0, Iteration 502/657 
Train Loss: 10.00 Accuracy: 3.12%
Epoch 0, Iteration 503/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 504/657 
Train Loss: 11.72 Accuracy: 7.81%
Epoch 0, Iteration 505/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 506/657 
Train Loss: 10.00 Accuracy: 17.19%
Epoch 0, Iteration 507/657 
Train Loss: 14.89 Accuracy: 4.69%
Epoch 0, Iteration 508/657 
Train Loss: 10.05 Accuracy: 7.81%
Epoch 0, Iteration 509/657 
Train Loss: 10.00 Accuracy: 3.12%
Epoch 0, Iteration 510/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 511/657 
Train Loss: 14.68 Accuracy: 12.50%
Epoch 0, Iteration 512/657 
Train Loss: 10.05 Accuracy: 10.94%
Epoch 0, Iteration 513/657 
Train Loss: 11.28 Accuracy: 12.50%
Epoch 0, Iteration 514/657 
Train Loss: 9.99 Accuracy: 9.38%
Epoch 0, Iteration 515/657 
Train Loss: 10.59 Accuracy: 14.06%
Epoch 0, Iteration 516/657 
Train Loss: 10.13 Accuracy: 12.50%
Epoch 0, Iteration 517/657 
Train Loss: 9.92 Accuracy: 17.19%
Epoch 0, Iteration 518/657 
Train Loss: 10.00 Accuracy: 17.19%
Epoch 0, Iteration 519/657 
Train Loss: 10.00 Accuracy: 15.62%
Epoch 0, Iteration 520/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 521/657 
Train Loss: 9.77 Accuracy: 10.94%
Epoch 0, Iteration 522/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 523/657 
Train Loss: 10.00 Accuracy: 3.12%
Epoch 0, Iteration 524/657 
Train Loss: 10.00 Accuracy: 10.94%
	Current speed:2.1537183415347196 iterations per second
Epoch 0, Iteration 525/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 526/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 527/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 528/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 529/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 530/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 531/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 532/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 533/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 534/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 535/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 536/657 
Train Loss: 10.00 Accuracy: 4.69%
Epoch 0, Iteration 537/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 538/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 539/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 540/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 541/657 
Train Loss: 11.25 Accuracy: 12.50%
Epoch 0, Iteration 542/657 
Train Loss: 11.09 Accuracy: 14.06%
Epoch 0, Iteration 543/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 544/657 
Train Loss: 13.28 Accuracy: 10.94%
Epoch 0, Iteration 545/657 
Train Loss: 11.56 Accuracy: 9.38%
Epoch 0, Iteration 546/657 
Train Loss: 13.44 Accuracy: 10.94%
Epoch 0, Iteration 547/657 
Train Loss: 16.88 Accuracy: 3.12%
Epoch 0, Iteration 548/657 
Train Loss: 15.31 Accuracy: 6.25%
Epoch 0, Iteration 549/657 
Train Loss: 18.28 Accuracy: 12.50%
	Current speed:2.1602030138383483 iterations per second
Epoch 0, Iteration 550/657 
Train Loss: 16.55 Accuracy: 7.81%
Epoch 0, Iteration 551/657 
Train Loss: 12.87 Accuracy: 6.25%
Epoch 0, Iteration 552/657 
Train Loss: 18.22 Accuracy: 12.50%
Epoch 0, Iteration 553/657 
Train Loss: 10.01 Accuracy: 10.94%
Epoch 0, Iteration 554/657 
Train Loss: 11.32 Accuracy: 10.94%
Epoch 0, Iteration 555/657 
Train Loss: 11.56 Accuracy: 7.81%
Epoch 0, Iteration 556/657 
Train Loss: 10.00 Accuracy: 4.69%
Epoch 0, Iteration 557/657 
Train Loss: 9.99 Accuracy: 9.38%
Epoch 0, Iteration 558/657 
Train Loss: 13.30 Accuracy: 6.25%
Epoch 0, Iteration 559/657 
Train Loss: 14.67 Accuracy: 6.25%
Epoch 0, Iteration 560/657 
Train Loss: 9.97 Accuracy: 15.62%
Epoch 0, Iteration 561/657 
Train Loss: 11.47 Accuracy: 9.38%
Epoch 0, Iteration 562/657 
Train Loss: 9.81 Accuracy: 10.94%
Epoch 0, Iteration 563/657 
Train Loss: 10.08 Accuracy: 17.19%
Epoch 0, Iteration 564/657 
Train Loss: 9.96 Accuracy: 6.25%
Epoch 0, Iteration 565/657 
Train Loss: 9.99 Accuracy: 12.50%
Epoch 0, Iteration 566/657 
Train Loss: 11.48 Accuracy: 4.69%
Epoch 0, Iteration 567/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 568/657 
Train Loss: 9.90 Accuracy: 10.94%
Epoch 0, Iteration 569/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 570/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 571/657 
Train Loss: 10.00 Accuracy: 15.62%
Epoch 0, Iteration 572/657 
Train Loss: 10.89 Accuracy: 14.06%
Epoch 0, Iteration 573/657 
Train Loss: 11.69 Accuracy: 10.94%
Epoch 0, Iteration 574/657 
Train Loss: 10.00 Accuracy: 4.69%
	Current speed:2.1660101443099364 iterations per second
Epoch 0, Iteration 575/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 576/657 
Train Loss: 10.00 Accuracy: 14.06%
Epoch 0, Iteration 577/657 
Train Loss: 10.00 Accuracy: 15.62%
Epoch 0, Iteration 578/657 
Train Loss: 15.96 Accuracy: 10.94%
Epoch 0, Iteration 579/657 
Train Loss: 13.32 Accuracy: 9.38%
Epoch 0, Iteration 580/657 
Train Loss: 11.69 Accuracy: 14.06%
Epoch 0, Iteration 581/657 
Train Loss: 10.00 Accuracy: 4.69%
Epoch 0, Iteration 582/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 583/657 
Train Loss: 13.85 Accuracy: 7.81%
Epoch 0, Iteration 584/657 
Train Loss: 10.00 Accuracy: 18.75%
Epoch 0, Iteration 585/657 
Train Loss: 11.37 Accuracy: 7.81%
Epoch 0, Iteration 586/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 587/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 588/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 589/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 590/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 591/657 
Train Loss: 10.00 Accuracy: 14.06%
Epoch 0, Iteration 592/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 593/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 594/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 595/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 596/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 597/657 
Train Loss: 10.00 Accuracy: 17.19%
Epoch 0, Iteration 598/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 599/657 
Train Loss: 10.62 Accuracy: 18.75%
	Current speed:2.1652449814418038 iterations per second
Epoch 0, Iteration 600/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 601/657 
Train Loss: 10.00 Accuracy: 14.06%
Epoch 0, Iteration 602/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 603/657 
Train Loss: 11.25 Accuracy: 12.50%
Epoch 0, Iteration 604/657 
Train Loss: 11.09 Accuracy: 14.06%
Epoch 0, Iteration 605/657 
Train Loss: 11.56 Accuracy: 9.38%
Epoch 0, Iteration 606/657 
Train Loss: 10.00 Accuracy: 15.62%
Epoch 0, Iteration 607/657 
Train Loss: 11.56 Accuracy: 9.38%
Epoch 0, Iteration 608/657 
Train Loss: 13.28 Accuracy: 7.81%
Epoch 0, Iteration 609/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 610/657 
Train Loss: 10.00 Accuracy: 14.06%
Epoch 0, Iteration 611/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 612/657 
Train Loss: 10.00 Accuracy: 10.94%
Epoch 0, Iteration 613/657 
Train Loss: 12.66 Accuracy: 12.50%
Epoch 0, Iteration 614/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 615/657 
Train Loss: 14.53 Accuracy: 7.81%
Epoch 0, Iteration 616/657 
Train Loss: 12.66 Accuracy: 9.38%
Epoch 0, Iteration 617/657 
Train Loss: 14.69 Accuracy: 9.38%
Epoch 0, Iteration 618/657 
Train Loss: 10.00 Accuracy: 14.06%
Epoch 0, Iteration 619/657 
Train Loss: 14.53 Accuracy: 7.81%
Epoch 0, Iteration 620/657 
Train Loss: 14.22 Accuracy: 14.06%
Epoch 0, Iteration 621/657 
Train Loss: 10.82 Accuracy: 10.94%
Epoch 0, Iteration 622/657 
Train Loss: 18.24 Accuracy: 6.25%
Epoch 0, Iteration 623/657 
Train Loss: 14.35 Accuracy: 9.38%
Epoch 0, Iteration 624/657 
Train Loss: 11.25 Accuracy: 12.50%
	Current speed:2.164367794144144 iterations per second
Epoch 0, Iteration 625/657 
Train Loss: 12.50 Accuracy: 17.19%
Epoch 0, Iteration 626/657 
Train Loss: 15.74 Accuracy: 10.94%
Epoch 0, Iteration 627/657 
Train Loss: 13.40 Accuracy: 9.38%
Epoch 0, Iteration 628/657 
Train Loss: 13.52 Accuracy: 9.38%
Epoch 0, Iteration 629/657 
Train Loss: 11.75 Accuracy: 12.50%
Epoch 0, Iteration 630/657 
Train Loss: 13.55 Accuracy: 4.69%
Epoch 0, Iteration 631/657 
Train Loss: 15.14 Accuracy: 4.69%
Epoch 0, Iteration 632/657 
Train Loss: 10.76 Accuracy: 12.50%
Epoch 0, Iteration 633/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 634/657 
Train Loss: 11.07 Accuracy: 14.06%
Epoch 0, Iteration 635/657 
Train Loss: 13.22 Accuracy: 6.25%
Epoch 0, Iteration 636/657 
Train Loss: 14.47 Accuracy: 9.38%
Epoch 0, Iteration 637/657 
Train Loss: 9.99 Accuracy: 10.94%
Epoch 0, Iteration 638/657 
Train Loss: 10.59 Accuracy: 17.19%
Epoch 0, Iteration 639/657 
Train Loss: 12.67 Accuracy: 0.00%
Epoch 0, Iteration 640/657 
Train Loss: 11.25 Accuracy: 12.50%
Epoch 0, Iteration 641/657 
Train Loss: 11.56 Accuracy: 9.38%
Epoch 0, Iteration 642/657 
Train Loss: 11.97 Accuracy: 4.69%
Epoch 0, Iteration 643/657 
Train Loss: 13.59 Accuracy: 3.12%
Epoch 0, Iteration 644/657 
Train Loss: 17.84 Accuracy: 12.50%
Epoch 0, Iteration 645/657 
Train Loss: 14.16 Accuracy: 9.38%
Epoch 0, Iteration 646/657 
Train Loss: 11.34 Accuracy: 9.38%
Epoch 0, Iteration 647/657 
Train Loss: 10.06 Accuracy: 17.19%
Epoch 0, Iteration 648/657 
Train Loss: 10.00 Accuracy: 4.69%
Epoch 0, Iteration 649/657 
Train Loss: 10.00 Accuracy: 12.50%
	Current speed:2.165459912108303 iterations per second
Epoch 0, Iteration 650/657 
Train Loss: 11.91 Accuracy: 9.38%
Epoch 0, Iteration 651/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 652/657 
Train Loss: 10.00 Accuracy: 12.50%
Epoch 0, Iteration 653/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 654/657 
Train Loss: 10.00 Accuracy: 9.38%
Epoch 0, Iteration 655/657 
Train Loss: 10.00 Accuracy: 7.81%
Epoch 0, Iteration 656/657 
Train Loss: 10.00 Accuracy: 6.25%
Training time (s):  303.31154108047485
Time spent converting dataset (s / %):  47.428741455078125 15.63697223195813
Time spent in forward pass (s / %): 153.78842091560364 50.70312206643016
Time spent in learning (s / %) 100.0406928062439 32.98281774899591
Time spent loading data (s / %): 2.0536859035491943 0.6770879526157921
Total correctly classified test set images: 1777/18000
Test Set Accuracy: 9.87%
[('conv', {'num-filters': ['44'], 'filter-shape': ['2'], 'stride': ['1'], 'padding': ['same'], 'bias': ['True']}), ('pool-max', {'kernel-size': ['2']}), ('act', {'beta': ['0.5405288817459849'], 'beta-trainable': ['False'], 'threshold': ['0.843665232475586'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']}), ('conv', {'num-filters': ['58'], 'filter-shape': ['3'], 'stride': ['1'], 'padding': ['valid'], 'bias': ['False']}), ('no-op', {}), ('act', {'beta': ['0.22765025495040303'], 'beta-trainable': ['True'], 'threshold': ['1.4543883671716387'], 'threshold-trainable': ['True'], 'surr-grad': ['fast_sigmoid'], 'reset': ['zero']}), ('fc', {'num-units': ['91'], 'bias': ['False']}), ('act', {'beta': ['0.2196699105052644'], 'beta-trainable': ['True'], 'threshold': ['1.3210515572515622'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['zero']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.6930072726133314'], 'beta-trainable': ['False'], 'threshold': ['0.6589417598464633'], 'threshold-trainable': ['True'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Conv2d(1, 44, kernel_size=(2, 2), stride=(1, 1), padding=same)
  (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (2): Leaky()
  (3): Conv2d(44, 58, kernel_size=(3, 3), stride=(1, 1), padding=valid, bias=False)
  (4): Leaky()
  (5): Flatten(start_dim=1, end_dim=-1)
  (6): Linear(in_features=8352, out_features=91, bias=False)
  (7): Leaky()
  (8): Linear(in_features=91, out_features=10, bias=True)
  (9): Leaky()
)
	Current speed:0.0 iterations per second
Epoch 0, Iteration 0/657 
Train Loss: 10.00 Accuracy: 6.25%
Epoch 0, Iteration 1/657 
Train Loss: 10.00 Accuracy: 23.44%
Epoch 0, Iteration 2/657 
Train Loss: 9.82 Accuracy: 14.06%
Epoch 0, Iteration 3/657 
Train Loss: 10.16 Accuracy: 6.25%
Epoch 0, Iteration 4/657 
Train Loss: 9.79 Accuracy: 12.50%
Epoch 0, Iteration 5/657 
Train Loss: 9.70 Accuracy: 12.50%
Epoch 0, Iteration 6/657 
Train Loss: 9.78 Accuracy: 12.50%
Epoch 0, Iteration 7/657 
Train Loss: 9.73 Accuracy: 12.50%
Epoch 0, Iteration 8/657 
Train Loss: 9.85 Accuracy: 1.56%
Epoch 0, Iteration 9/657 
Train Loss: 9.44 Accuracy: 9.38%
Epoch 0, Iteration 10/657 
Train Loss: 9.45 Accuracy: 10.94%
Epoch 0, Iteration 11/657 
Train Loss: 9.30 Accuracy: 10.94%
Epoch 0, Iteration 12/657 
Train Loss: 9.29 Accuracy: 7.81%
Epoch 0, Iteration 13/657 
Train Loss: 9.28 Accuracy: 6.25%
Epoch 0, Iteration 14/657 
Train Loss: 9.28 Accuracy: 14.06%
Epoch 0, Iteration 15/657 
Train Loss: 9.38 Accuracy: 9.38%
Epoch 0, Iteration 16/657 
Train Loss: 9.18 Accuracy: 18.75%
Epoch 0, Iteration 17/657 
Train Loss: 9.80 Accuracy: 10.94%
Epoch 0, Iteration 18/657 
Train Loss: 9.29 Accuracy: 6.25%
Epoch 0, Iteration 19/657 
Train Loss: 9.18 Accuracy: 10.94%
Epoch 0, Iteration 20/657 
Train Loss: 9.40 Accuracy: 10.94%
Epoch 0, Iteration 21/657 
Train Loss: 9.34 Accuracy: 15.62%
Epoch 0, Iteration 22/657 
Train Loss: 9.30 Accuracy: 7.81%
Epoch 0, Iteration 23/657 
Train Loss: 9.21 Accuracy: 10.94%
Epoch 0, Iteration 24/657 
Train Loss: 9.07 Accuracy: 9.38%
	Current speed:1.7516898865274557 iterations per second
Epoch 0, Iteration 25/657 
Train Loss: 9.13 Accuracy: 15.62%
Epoch 0, Iteration 26/657 
Train Loss: 9.27 Accuracy: 4.69%
Epoch 0, Iteration 27/657 
Train Loss: 9.13 Accuracy: 9.38%
Epoch 0, Iteration 28/657 
Train Loss: 9.01 Accuracy: 12.50%
Epoch 0, Iteration 29/657 
Train Loss: 9.05 Accuracy: 14.06%
Epoch 0, Iteration 30/657 
Train Loss: 9.27 Accuracy: 4.69%
Epoch 0, Iteration 31/657 
Train Loss: 9.24 Accuracy: 9.38%
Epoch 0, Iteration 32/657 
Train Loss: 9.16 Accuracy: 10.94%
Epoch 0, Iteration 33/657 
Train Loss: 9.06 Accuracy: 12.50%
Epoch 0, Iteration 34/657 
Train Loss: 9.01 Accuracy: 12.50%
Epoch 0, Iteration 35/657 
Train Loss: 9.30 Accuracy: 10.94%
Epoch 0, Iteration 36/657 
Train Loss: 9.08 Accuracy: 9.38%
Epoch 0, Iteration 37/657 
Train Loss: 9.11 Accuracy: 10.94%
Epoch 0, Iteration 38/657 
Train Loss: 9.08 Accuracy: 10.94%
Epoch 0, Iteration 39/657 
Train Loss: 9.09 Accuracy: 9.38%
Epoch 0, Iteration 40/657 
Train Loss: 9.18 Accuracy: 10.94%
Epoch 0, Iteration 41/657 
Train Loss: 9.17 Accuracy: 12.50%
Epoch 0, Iteration 42/657 
Train Loss: 9.05 Accuracy: 17.19%
Epoch 0, Iteration 43/657 
Train Loss: 9.17 Accuracy: 14.06%
Epoch 0, Iteration 44/657 
Train Loss: 9.40 Accuracy: 12.50%
Epoch 0, Iteration 45/657 
Train Loss: 9.37 Accuracy: 12.50%
Epoch 0, Iteration 46/657 
Train Loss: 9.42 Accuracy: 6.25%
Epoch 0, Iteration 47/657 
Train Loss: 9.25 Accuracy: 10.94%
Epoch 0, Iteration 48/657 
Train Loss: 9.30 Accuracy: 10.94%
Epoch 0, Iteration 49/657 
Train Loss: 9.23 Accuracy: 10.94%
	Current speed:1.7563671987585017 iterations per second
Epoch 0, Iteration 50/657 
Train Loss: 9.61 Accuracy: 0.00%
Epoch 0, Iteration 51/657 
Train Loss: 9.18 Accuracy: 4.69%
Epoch 0, Iteration 52/657 
Train Loss: 9.26 Accuracy: 14.06%
Epoch 0, Iteration 53/657 
Train Loss: 9.16 Accuracy: 6.25%
Epoch 0, Iteration 54/657 
Train Loss: 9.34 Accuracy: 12.50%
Epoch 0, Iteration 55/657 
Train Loss: 9.40 Accuracy: 0.00%
Epoch 0, Iteration 56/657 
Train Loss: 9.27 Accuracy: 7.81%
Epoch 0, Iteration 57/657 
Train Loss: 9.16 Accuracy: 12.50%
Epoch 0, Iteration 58/657 
Train Loss: 9.03 Accuracy: 10.94%
Epoch 0, Iteration 59/657 
Train Loss: 9.24 Accuracy: 18.75%
Epoch 0, Iteration 60/657 
Train Loss: 9.04 Accuracy: 15.62%
Epoch 0, Iteration 61/657 
Train Loss: 9.07 Accuracy: 12.50%
Epoch 0, Iteration 62/657 
Train Loss: 9.08 Accuracy: 6.25%
Epoch 0, Iteration 63/657 
Train Loss: 9.24 Accuracy: 10.94%
Epoch 0, Iteration 64/657 
Train Loss: 9.05 Accuracy: 12.50%
Epoch 0, Iteration 65/657 
Train Loss: 9.08 Accuracy: 14.06%
Epoch 0, Iteration 66/657 
Train Loss: 9.05 Accuracy: 12.50%
Epoch 0, Iteration 67/657 
Train Loss: 9.17 Accuracy: 12.50%
Epoch 0, Iteration 68/657 
Train Loss: 9.13 Accuracy: 4.69%
Epoch 0, Iteration 69/657 
Train Loss: 9.16 Accuracy: 9.38%
Epoch 0, Iteration 70/657 
Train Loss: 8.96 Accuracy: 12.50%
Epoch 0, Iteration 71/657 
Train Loss: 9.18 Accuracy: 15.62%
Epoch 0, Iteration 72/657 
Train Loss: 9.19 Accuracy: 6.25%
Epoch 0, Iteration 73/657 
Train Loss: 9.25 Accuracy: 6.25%
Epoch 0, Iteration 74/657 
Train Loss: 9.15 Accuracy: 4.69%
	Current speed:1.7698690336141425 iterations per second
Epoch 0, Iteration 75/657 
Train Loss: 9.14 Accuracy: 6.25%
Epoch 0, Iteration 76/657 
Train Loss: 9.08 Accuracy: 17.19%
Epoch 0, Iteration 77/657 
Train Loss: 9.05 Accuracy: 12.50%
Epoch 0, Iteration 78/657 
Train Loss: 9.08 Accuracy: 7.81%
Epoch 0, Iteration 79/657 
Train Loss: 9.33 Accuracy: 7.81%
Epoch 0, Iteration 80/657 
Train Loss: 9.09 Accuracy: 9.38%
Epoch 0, Iteration 81/657 
Train Loss: 9.13 Accuracy: 10.94%
Epoch 0, Iteration 82/657 
Train Loss: 9.06 Accuracy: 14.06%
Epoch 0, Iteration 83/657 
Train Loss: 9.27 Accuracy: 9.38%
Epoch 0, Iteration 84/657 
Train Loss: 8.94 Accuracy: 20.31%
Epoch 0, Iteration 85/657 
Train Loss: 9.09 Accuracy: 7.81%
Epoch 0, Iteration 86/657 
Train Loss: 9.29 Accuracy: 10.94%
Epoch 0, Iteration 87/657 
Train Loss: 9.14 Accuracy: 9.38%
Epoch 0, Iteration 88/657 
Train Loss: 9.24 Accuracy: 10.94%
Epoch 0, Iteration 89/657 
Train Loss: 9.10 Accuracy: 10.94%
Epoch 0, Iteration 90/657 
Train Loss: 9.33 Accuracy: 7.81%
Epoch 0, Iteration 91/657 
Train Loss: 9.18 Accuracy: 7.81%
Epoch 0, Iteration 92/657 
Train Loss: 9.18 Accuracy: 12.50%
Epoch 0, Iteration 93/657 
Train Loss: 9.23 Accuracy: 9.38%
Epoch 0, Iteration 94/657 
Train Loss: 9.06 Accuracy: 9.38%
Epoch 0, Iteration 95/657 
Train Loss: 9.21 Accuracy: 6.25%
Epoch 0, Iteration 96/657 
Train Loss: 9.09 Accuracy: 14.06%
Epoch 0, Iteration 97/657 
Train Loss: 9.15 Accuracy: 9.38%
Epoch 0, Iteration 98/657 
Train Loss: 9.29 Accuracy: 3.12%
Epoch 0, Iteration 99/657 
Train Loss: 8.97 Accuracy: 15.62%
	Current speed:1.7788909040792682 iterations per second
Epoch 0, Iteration 100/657 
Train Loss: 9.03 Accuracy: 6.25%
Epoch 0, Iteration 101/657 
Train Loss: 9.47 Accuracy: 9.38%
Epoch 0, Iteration 102/657 
Train Loss: 9.19 Accuracy: 10.94%
Epoch 0, Iteration 103/657 
Train Loss: 9.34 Accuracy: 6.25%
Epoch 0, Iteration 104/657 
Train Loss: 9.29 Accuracy: 12.50%
Epoch 0, Iteration 105/657 
Train Loss: 9.26 Accuracy: 7.81%
Epoch 0, Iteration 106/657 
Train Loss: 9.14 Accuracy: 14.06%
Epoch 0, Iteration 107/657 
Train Loss: 9.01 Accuracy: 14.06%
Epoch 0, Iteration 108/657 
Train Loss: 9.22 Accuracy: 12.50%
Epoch 0, Iteration 109/657 
Train Loss: 9.09 Accuracy: 15.62%
Epoch 0, Iteration 110/657 
Train Loss: 9.11 Accuracy: 14.06%
Epoch 0, Iteration 111/657 
Train Loss: 9.08 Accuracy: 10.94%
Epoch 0, Iteration 112/657 
Train Loss: 9.23 Accuracy: 15.62%
Epoch 0, Iteration 113/657 
Train Loss: 9.13 Accuracy: 7.81%
Epoch 0, Iteration 114/657 
Train Loss: 9.08 Accuracy: 9.38%
Epoch 0, Iteration 115/657 
Train Loss: 9.34 Accuracy: 6.25%
Epoch 0, Iteration 116/657 
Train Loss: 8.95 Accuracy: 20.31%
Epoch 0, Iteration 117/657 
Train Loss: 9.15 Accuracy: 9.38%
Epoch 0, Iteration 118/657 
Train Loss: 9.06 Accuracy: 9.38%
Epoch 0, Iteration 119/657 
Train Loss: 9.04 Accuracy: 6.25%
Epoch 0, Iteration 120/657 
Train Loss: 9.05 Accuracy: 4.69%
Epoch 0, Iteration 121/657 
Train Loss: 9.02 Accuracy: 6.25%
Epoch 0, Iteration 122/657 
Train Loss: 9.11 Accuracy: 4.69%
Epoch 0, Iteration 123/657 
Train Loss: 9.12 Accuracy: 7.81%
Epoch 0, Iteration 124/657 
Train Loss: 9.07 Accuracy: 7.81%
	Current speed:1.7827008786050094 iterations per second
Epoch 0, Iteration 125/657 
Train Loss: 9.08 Accuracy: 4.69%
Epoch 0, Iteration 126/657 
Train Loss: 9.01 Accuracy: 10.94%
Epoch 0, Iteration 127/657 
Train Loss: 9.07 Accuracy: 3.12%
Epoch 0, Iteration 128/657 
Train Loss: 9.03 Accuracy: 17.19%
Epoch 0, Iteration 129/657 
Train Loss: 9.09 Accuracy: 9.38%
Epoch 0, Iteration 130/657 
Train Loss: 9.08 Accuracy: 6.25%
Epoch 0, Iteration 131/657 
Train Loss: 9.04 Accuracy: 18.75%
Epoch 0, Iteration 132/657 
Train Loss: 9.03 Accuracy: 6.25%
Epoch 0, Iteration 133/657 
Train Loss: 9.17 Accuracy: 7.81%
Epoch 0, Iteration 134/657 
Train Loss: 9.12 Accuracy: 10.94%
Epoch 0, Iteration 135/657 
Train Loss: 9.09 Accuracy: 6.25%
Epoch 0, Iteration 136/657 
Train Loss: 9.04 Accuracy: 18.75%
Epoch 0, Iteration 137/657 
Train Loss: 9.18 Accuracy: 6.25%
Epoch 0, Iteration 138/657 
Train Loss: 9.10 Accuracy: 10.94%
Epoch 0, Iteration 139/657 
Train Loss: 9.04 Accuracy: 7.81%
Epoch 0, Iteration 140/657 
Train Loss: 9.05 Accuracy: 6.25%
Epoch 0, Iteration 141/657 
Train Loss: 9.08 Accuracy: 14.06%
Epoch 0, Iteration 142/657 
Train Loss: 8.98 Accuracy: 6.25%
Epoch 0, Iteration 143/657 
Train Loss: 9.05 Accuracy: 4.69%
Epoch 0, Iteration 144/657 
Train Loss: 9.01 Accuracy: 7.81%
Epoch 0, Iteration 145/657 
Train Loss: 9.00 Accuracy: 10.94%
Epoch 0, Iteration 146/657 
Train Loss: 8.96 Accuracy: 14.06%
Epoch 0, Iteration 147/657 
Train Loss: 9.14 Accuracy: 3.12%
Epoch 0, Iteration 148/657 
Train Loss: 9.26 Accuracy: 12.50%
Epoch 0, Iteration 149/657 
Train Loss: 9.03 Accuracy: 10.94%
	Current speed:1.7859028458594228 iterations per second
Epoch 0, Iteration 150/657 
Train Loss: 8.98 Accuracy: 21.88%
Epoch 0, Iteration 151/657 
Train Loss: 9.21 Accuracy: 3.12%
Epoch 0, Iteration 152/657 
Train Loss: 9.02 Accuracy: 10.94%
Epoch 0, Iteration 153/657 
Train Loss: 9.01 Accuracy: 7.81%
Epoch 0, Iteration 154/657 
Train Loss: 9.35 Accuracy: 20.31%
Epoch 0, Iteration 155/657 
Train Loss: 9.11 Accuracy: 9.38%
Epoch 0, Iteration 156/657 
Train Loss: 9.17 Accuracy: 9.38%
Epoch 0, Iteration 157/657 
Train Loss: 9.25 Accuracy: 12.50%
Epoch 0, Iteration 158/657 
Train Loss: 9.25 Accuracy: 6.25%
Epoch 0, Iteration 159/657 
Train Loss: 9.11 Accuracy: 12.50%
Epoch 0, Iteration 160/657 
Train Loss: 9.11 Accuracy: 9.38%
Epoch 0, Iteration 161/657 
Train Loss: 9.10 Accuracy: 12.50%
Epoch 0, Iteration 162/657 
Train Loss: 9.12 Accuracy: 12.50%
Epoch 0, Iteration 163/657 
Train Loss: 9.10 Accuracy: 6.25%
Epoch 0, Iteration 164/657 
Train Loss: 9.11 Accuracy: 9.38%
Epoch 0, Iteration 165/657 
Train Loss: 9.33 Accuracy: 6.25%
Epoch 0, Iteration 166/657 
Train Loss: 9.01 Accuracy: 10.94%
Epoch 0, Iteration 167/657 
Train Loss: 9.14 Accuracy: 9.38%
Epoch 0, Iteration 168/657 
Train Loss: 9.06 Accuracy: 9.38%
Epoch 0, Iteration 169/657 
Train Loss: 8.91 Accuracy: 12.50%
Epoch 0, Iteration 170/657 
Train Loss: 9.16 Accuracy: 9.38%
Epoch 0, Iteration 171/657 
Train Loss: 9.13 Accuracy: 4.69%
Epoch 0, Iteration 172/657 
Train Loss: 9.24 Accuracy: 9.38%
Epoch 0, Iteration 173/657 
Train Loss: 9.25 Accuracy: 10.94%
Epoch 0, Iteration 174/657 
Train Loss: 9.06 Accuracy: 12.50%
	Current speed:1.787290985692087 iterations per second
Epoch 0, Iteration 175/657 
Train Loss: 9.04 Accuracy: 10.94%
Epoch 0, Iteration 176/657 
Train Loss: 9.05 Accuracy: 10.94%
Epoch 0, Iteration 177/657 
Train Loss: 9.10 Accuracy: 7.81%
Epoch 0, Iteration 178/657 
Train Loss: 9.14 Accuracy: 4.69%
Epoch 0, Iteration 179/657 
Train Loss: 9.06 Accuracy: 10.94%
Epoch 0, Iteration 180/657 
Train Loss: 9.01 Accuracy: 9.38%
Epoch 0, Iteration 181/657 
Train Loss: 9.02 Accuracy: 10.94%
Epoch 0, Iteration 182/657 
Train Loss: 8.90 Accuracy: 17.19%
Epoch 0, Iteration 183/657 
Train Loss: 9.23 Accuracy: 9.38%
Epoch 0, Iteration 184/657 
Train Loss: 9.12 Accuracy: 4.69%
Epoch 0, Iteration 185/657 
Train Loss: 9.03 Accuracy: 14.06%
Epoch 0, Iteration 186/657 
Train Loss: 9.29 Accuracy: 10.94%
Epoch 0, Iteration 187/657 
Train Loss: 9.08 Accuracy: 7.81%
Epoch 0, Iteration 188/657 
Train Loss: 9.08 Accuracy: 7.81%
Epoch 0, Iteration 189/657 
Train Loss: 9.22 Accuracy: 6.25%
Epoch 0, Iteration 190/657 
Train Loss: 9.07 Accuracy: 12.50%
Epoch 0, Iteration 191/657 
Train Loss: 9.10 Accuracy: 9.38%
Epoch 0, Iteration 192/657 
Train Loss: 9.17 Accuracy: 12.50%
Epoch 0, Iteration 193/657 
Train Loss: 9.26 Accuracy: 6.25%
Epoch 0, Iteration 194/657 
Train Loss: 9.08 Accuracy: 12.50%
Epoch 0, Iteration 195/657 
Train Loss: 8.99 Accuracy: 12.50%
Epoch 0, Iteration 196/657 
Train Loss: 9.19 Accuracy: 9.38%
Epoch 0, Iteration 197/657 
Train Loss: 9.02 Accuracy: 12.50%
Epoch 0, Iteration 198/657 
Train Loss: 9.12 Accuracy: 10.94%
Epoch 0, Iteration 199/657 
Train Loss: 9.08 Accuracy: 6.25%
	Current speed:1.7895107816556484 iterations per second
Epoch 0, Iteration 200/657 
Train Loss: 9.15 Accuracy: 4.69%
Epoch 0, Iteration 201/657 
Train Loss: 8.97 Accuracy: 12.50%
Epoch 0, Iteration 202/657 
Train Loss: 9.01 Accuracy: 12.50%
Epoch 0, Iteration 203/657 
Train Loss: 9.01 Accuracy: 9.38%
Epoch 0, Iteration 204/657 
Train Loss: 9.00 Accuracy: 12.50%
Epoch 0, Iteration 205/657 
Train Loss: 8.99 Accuracy: 7.81%
Epoch 0, Iteration 206/657 
Train Loss: 9.10 Accuracy: 9.38%
Epoch 0, Iteration 207/657 
Train Loss: 9.00 Accuracy: 12.50%
Epoch 0, Iteration 208/657 
Train Loss: 9.07 Accuracy: 7.81%
Epoch 0, Iteration 209/657 
Train Loss: 9.13 Accuracy: 4.69%
Epoch 0, Iteration 210/657 
Train Loss: 9.00 Accuracy: 14.06%
Epoch 0, Iteration 211/657 
Train Loss: 9.00 Accuracy: 9.38%
Epoch 0, Iteration 212/657 
Train Loss: 8.96 Accuracy: 10.94%
Epoch 0, Iteration 213/657 
Train Loss: 8.97 Accuracy: 12.50%
Epoch 0, Iteration 214/657 
Train Loss: 9.06 Accuracy: 9.38%
Epoch 0, Iteration 215/657 
Train Loss: 9.04 Accuracy: 7.81%
Epoch 0, Iteration 216/657 
Train Loss: 9.04 Accuracy: 9.38%
Epoch 0, Iteration 217/657 
Train Loss: 9.01 Accuracy: 12.50%
Epoch 0, Iteration 218/657 
Train Loss: 9.02 Accuracy: 14.06%
Epoch 0, Iteration 219/657 
Train Loss: 9.00 Accuracy: 10.94%
Epoch 0, Iteration 220/657 
Train Loss: 9.04 Accuracy: 7.81%
Epoch 0, Iteration 221/657 
Train Loss: 9.04 Accuracy: 12.50%
Epoch 0, Iteration 222/657 
Train Loss: 9.03 Accuracy: 7.81%
Epoch 0, Iteration 223/657 
Train Loss: 9.05 Accuracy: 9.38%
Epoch 0, Iteration 224/657 
Train Loss: 9.05 Accuracy: 10.94%
	Current speed:1.7894161038245513 iterations per second
Epoch 0, Iteration 225/657 
Train Loss: 9.12 Accuracy: 9.38%
Epoch 0, Iteration 226/657 
Train Loss: 9.01 Accuracy: 10.94%
Epoch 0, Iteration 227/657 
Train Loss: 9.01 Accuracy: 9.38%
Epoch 0, Iteration 228/657 
Train Loss: 9.05 Accuracy: 10.94%
Epoch 0, Iteration 229/657 
Train Loss: 8.98 Accuracy: 21.88%
Epoch 0, Iteration 230/657 
Train Loss: 9.01 Accuracy: 14.06%
Epoch 0, Iteration 231/657 
Train Loss: 9.06 Accuracy: 7.81%
Epoch 0, Iteration 232/657 
Train Loss: 9.08 Accuracy: 7.81%
Epoch 0, Iteration 233/657 
Train Loss: 8.98 Accuracy: 12.50%
Epoch 0, Iteration 234/657 
Train Loss: 9.05 Accuracy: 9.38%
Epoch 0, Iteration 235/657 
Train Loss: 9.06 Accuracy: 4.69%
Epoch 0, Iteration 236/657 
Train Loss: 9.04 Accuracy: 7.81%
Epoch 0, Iteration 237/657 
Train Loss: 9.05 Accuracy: 4.69%
Epoch 0, Iteration 238/657 
Train Loss: 8.98 Accuracy: 4.69%
Epoch 0, Iteration 239/657 
Train Loss: 9.00 Accuracy: 15.62%
Epoch 0, Iteration 240/657 
Train Loss: 9.11 Accuracy: 7.81%
Epoch 0, Iteration 241/657 
Train Loss: 9.07 Accuracy: 14.06%
Epoch 0, Iteration 242/657 
Train Loss: 8.93 Accuracy: 23.44%
Epoch 0, Iteration 243/657 
Train Loss: 8.98 Accuracy: 10.94%
Epoch 0, Iteration 244/657 
Train Loss: 9.05 Accuracy: 15.62%
Epoch 0, Iteration 245/657 
Train Loss: 9.02 Accuracy: 17.19%
Epoch 0, Iteration 246/657 
Train Loss: 9.09 Accuracy: 6.25%
Epoch 0, Iteration 247/657 
Train Loss: 9.03 Accuracy: 9.38%
Epoch 0, Iteration 248/657 
Train Loss: 8.98 Accuracy: 14.06%
Epoch 0, Iteration 249/657 
Train Loss: 9.11 Accuracy: 10.94%
	Current speed:1.789947651965442 iterations per second
Epoch 0, Iteration 250/657 
Train Loss: 9.07 Accuracy: 3.12%
Epoch 0, Iteration 251/657 
Train Loss: 9.03 Accuracy: 6.25%
Epoch 0, Iteration 252/657 
Train Loss: 9.11 Accuracy: 7.81%
Epoch 0, Iteration 253/657 
Train Loss: 9.04 Accuracy: 4.69%
Epoch 0, Iteration 254/657 
Train Loss: 9.04 Accuracy: 14.06%
Epoch 0, Iteration 255/657 
Train Loss: 9.08 Accuracy: 4.69%
Epoch 0, Iteration 256/657 
Train Loss: 9.08 Accuracy: 7.81%
Epoch 0, Iteration 257/657 
Train Loss: 9.12 Accuracy: 4.69%
Epoch 0, Iteration 258/657 
Train Loss: 9.09 Accuracy: 10.94%
Epoch 0, Iteration 259/657 
Train Loss: 9.07 Accuracy: 9.38%
Epoch 0, Iteration 260/657 
Train Loss: 8.97 Accuracy: 4.69%
Epoch 0, Iteration 261/657 
Train Loss: 8.98 Accuracy: 9.38%
Epoch 0, Iteration 262/657 
Train Loss: 9.19 Accuracy: 6.25%
Epoch 0, Iteration 263/657 
Train Loss: 9.07 Accuracy: 7.81%
Epoch 0, Iteration 264/657 
Train Loss: 9.03 Accuracy: 9.38%
Epoch 0, Iteration 265/657 
Train Loss: 9.10 Accuracy: 6.25%
Epoch 0, Iteration 266/657 
Train Loss: 9.04 Accuracy: 9.38%
Epoch 0, Iteration 267/657 
Train Loss: 9.08 Accuracy: 10.94%
Epoch 0, Iteration 268/657 
Train Loss: 8.94 Accuracy: 18.75%
Epoch 0, Iteration 269/657 
Train Loss: 9.10 Accuracy: 14.06%
Epoch 0, Iteration 270/657 
Train Loss: 9.02 Accuracy: 10.94%
Epoch 0, Iteration 271/657 
Train Loss: 9.06 Accuracy: 3.12%
Epoch 0, Iteration 272/657 
Train Loss: 9.06 Accuracy: 10.94%
Epoch 0, Iteration 273/657 
Train Loss: 9.06 Accuracy: 9.38%
Epoch 0, Iteration 274/657 
Train Loss: 9.05 Accuracy: 4.69%
	Current speed:1.7907094539470239 iterations per second
Epoch 0, Iteration 275/657 
Train Loss: 8.99 Accuracy: 10.94%
Epoch 0, Iteration 276/657 
Train Loss: 9.01 Accuracy: 10.94%
Epoch 0, Iteration 277/657 
Train Loss: 9.04 Accuracy: 10.94%
Epoch 0, Iteration 278/657 
Train Loss: 9.03 Accuracy: 12.50%
Epoch 0, Iteration 279/657 
Train Loss: 9.00 Accuracy: 9.38%
Epoch 0, Iteration 280/657 
Train Loss: 9.05 Accuracy: 12.50%
Epoch 0, Iteration 281/657 
Train Loss: 9.01 Accuracy: 12.50%
Epoch 0, Iteration 282/657 
Train Loss: 9.01 Accuracy: 3.12%
Epoch 0, Iteration 283/657 
Train Loss: 9.00 Accuracy: 10.94%
Epoch 0, Iteration 284/657 
Train Loss: 9.06 Accuracy: 4.69%
Epoch 0, Iteration 285/657 
Train Loss: 9.05 Accuracy: 7.81%
Epoch 0, Iteration 286/657 
Train Loss: 9.09 Accuracy: 3.12%
Epoch 0, Iteration 287/657 
Train Loss: 9.00 Accuracy: 10.94%
Epoch 0, Iteration 288/657 
Train Loss: 9.14 Accuracy: 7.81%
Epoch 0, Iteration 289/657 
Train Loss: 8.98 Accuracy: 10.94%
Epoch 0, Iteration 290/657 
Train Loss: 9.00 Accuracy: 17.19%
Epoch 0, Iteration 291/657 
Train Loss: 9.10 Accuracy: 4.69%
Epoch 0, Iteration 292/657 
Train Loss: 9.06 Accuracy: 17.19%
Epoch 0, Iteration 293/657 
Train Loss: 9.02 Accuracy: 10.94%
Epoch 0, Iteration 294/657 
Train Loss: 8.98 Accuracy: 10.94%
Epoch 0, Iteration 295/657 
Train Loss: 8.99 Accuracy: 14.06%
Epoch 0, Iteration 296/657 
Train Loss: 9.22 Accuracy: 6.25%
Epoch 0, Iteration 297/657 
Train Loss: 9.03 Accuracy: 9.38%
Epoch 0, Iteration 298/657 
Train Loss: 9.13 Accuracy: 9.38%
Epoch 0, Iteration 299/657 
Train Loss: 9.08 Accuracy: 9.38%
	Current speed:1.7908699196173026 iterations per second
Epoch 0, Iteration 300/657 
Train Loss: 9.05 Accuracy: 3.12%
Epoch 0, Iteration 301/657 
Train Loss: 9.22 Accuracy: 12.50%
Epoch 0, Iteration 302/657 
Train Loss: 9.08 Accuracy: 15.62%
Epoch 0, Iteration 303/657 
Train Loss: 9.06 Accuracy: 4.69%
Epoch 0, Iteration 304/657 
Train Loss: 9.11 Accuracy: 10.94%
Epoch 0, Iteration 305/657 
Train Loss: 9.25 Accuracy: 7.81%
Epoch 0, Iteration 306/657 
Train Loss: 9.12 Accuracy: 10.94%
Epoch 0, Iteration 307/657 
Train Loss: 9.06 Accuracy: 7.81%
Epoch 0, Iteration 308/657 
Train Loss: 8.98 Accuracy: 10.94%
Epoch 0, Iteration 309/657 
Train Loss: 9.13 Accuracy: 7.81%
Epoch 0, Iteration 310/657 
Train Loss: 9.10 Accuracy: 10.94%
Epoch 0, Iteration 311/657 
Train Loss: 9.07 Accuracy: 7.81%
Epoch 0, Iteration 312/657 
Train Loss: 9.07 Accuracy: 10.94%
Epoch 0, Iteration 313/657 
Train Loss: 9.11 Accuracy: 4.69%
Epoch 0, Iteration 314/657 
Train Loss: 9.13 Accuracy: 9.38%
Epoch 0, Iteration 315/657 
Train Loss: 9.12 Accuracy: 9.38%
Epoch 0, Iteration 316/657 
Train Loss: 8.96 Accuracy: 14.06%
Epoch 0, Iteration 317/657 
Train Loss: 9.13 Accuracy: 9.38%
Epoch 0, Iteration 318/657 
Train Loss: 9.04 Accuracy: 12.50%
Epoch 0, Iteration 319/657 
Train Loss: 9.02 Accuracy: 10.94%
Epoch 0, Iteration 320/657 
Train Loss: 8.99 Accuracy: 7.81%
Epoch 0, Iteration 321/657 
Train Loss: 9.02 Accuracy: 10.94%
Epoch 0, Iteration 322/657 
Train Loss: 9.05 Accuracy: 12.50%
Epoch 0, Iteration 323/657 
Train Loss: 9.07 Accuracy: 7.81%
Epoch 0, Iteration 324/657 
Train Loss: 9.04 Accuracy: 6.25%
	Current speed:1.7912293690444019 iterations per second
Epoch 0, Iteration 325/657 
Train Loss: 9.07 Accuracy: 9.38%
Epoch 0, Iteration 326/657 
Train Loss: 8.98 Accuracy: 4.69%
Epoch 0, Iteration 327/657 
Train Loss: 8.99 Accuracy: 6.25%
Epoch 0, Iteration 328/657 
Train Loss: 9.02 Accuracy: 10.94%
Epoch 0, Iteration 329/657 
Train Loss: 9.06 Accuracy: 7.81%
Epoch 0, Iteration 330/657 
Train Loss: 9.04 Accuracy: 10.94%
Epoch 0, Iteration 331/657 
Train Loss: 9.01 Accuracy: 1.56%
Epoch 0, Iteration 332/657 
Train Loss: 9.04 Accuracy: 12.50%
Epoch 0, Iteration 333/657 
Train Loss: 8.98 Accuracy: 10.94%
Epoch 0, Iteration 334/657 
Train Loss: 8.98 Accuracy: 15.62%
Epoch 0, Iteration 335/657 
Train Loss: 9.05 Accuracy: 18.75%
Epoch 0, Iteration 336/657 
Train Loss: 8.99 Accuracy: 9.38%
Epoch 0, Iteration 337/657 
Train Loss: 9.09 Accuracy: 6.25%
Epoch 0, Iteration 338/657 
Train Loss: 8.97 Accuracy: 15.62%
Epoch 0, Iteration 339/657 
Train Loss: 9.08 Accuracy: 15.62%
Epoch 0, Iteration 340/657 
Train Loss: 9.15 Accuracy: 6.25%
Epoch 0, Iteration 341/657 
Train Loss: 9.06 Accuracy: 10.94%
Epoch 0, Iteration 342/657 
Train Loss: 9.04 Accuracy: 14.06%
Epoch 0, Iteration 343/657 
Train Loss: 9.02 Accuracy: 12.50%
Epoch 0, Iteration 344/657 
Train Loss: 9.25 Accuracy: 12.50%
Epoch 0, Iteration 345/657 
Train Loss: 9.05 Accuracy: 15.62%
Epoch 0, Iteration 346/657 
Train Loss: 9.17 Accuracy: 7.81%
Epoch 0, Iteration 347/657 
Train Loss: 8.97 Accuracy: 18.75%
Epoch 0, Iteration 348/657 
Train Loss: 9.27 Accuracy: 6.25%
Epoch 0, Iteration 349/657 
Train Loss: 8.98 Accuracy: 10.94%
	Current speed:1.7917799754557728 iterations per second
Epoch 0, Iteration 350/657 
Train Loss: 9.20 Accuracy: 7.81%
Epoch 0, Iteration 351/657 
Train Loss: 9.07 Accuracy: 7.81%
Epoch 0, Iteration 352/657 
Train Loss: 8.99 Accuracy: 20.31%
Epoch 0, Iteration 353/657 
Train Loss: 9.09 Accuracy: 12.50%
Epoch 0, Iteration 354/657 
Train Loss: 9.03 Accuracy: 9.38%
Epoch 0, Iteration 355/657 
Train Loss: 9.03 Accuracy: 26.56%
Epoch 0, Iteration 356/657 
Train Loss: 9.08 Accuracy: 7.81%
Epoch 0, Iteration 357/657 
Train Loss: 9.06 Accuracy: 9.38%
Epoch 0, Iteration 358/657 
Train Loss: 9.03 Accuracy: 14.06%
Epoch 0, Iteration 359/657 
Train Loss: 9.08 Accuracy: 6.25%
Epoch 0, Iteration 360/657 
Train Loss: 9.00 Accuracy: 4.69%
Epoch 0, Iteration 361/657 
Train Loss: 8.97 Accuracy: 17.19%
Epoch 0, Iteration 362/657 
Train Loss: 8.97 Accuracy: 14.06%
Epoch 0, Iteration 363/657 
Train Loss: 9.27 Accuracy: 10.94%
Epoch 0, Iteration 364/657 
Train Loss: 9.03 Accuracy: 6.25%
Epoch 0, Iteration 365/657 
Train Loss: 9.01 Accuracy: 15.62%
Epoch 0, Iteration 366/657 
Train Loss: 8.99 Accuracy: 17.19%
Epoch 0, Iteration 367/657 
Train Loss: 9.09 Accuracy: 10.94%
Epoch 0, Iteration 368/657 
Train Loss: 9.14 Accuracy: 10.94%
Epoch 0, Iteration 369/657 
Train Loss: 9.01 Accuracy: 12.50%
Epoch 0, Iteration 370/657 
Train Loss: 9.06 Accuracy: 6.25%
Epoch 0, Iteration 371/657 
Train Loss: 9.03 Accuracy: 7.81%
Epoch 0, Iteration 372/657 
Train Loss: 9.27 Accuracy: 7.81%
Epoch 0, Iteration 373/657 
Train Loss: 9.00 Accuracy: 18.75%
Epoch 0, Iteration 374/657 
Train Loss: 9.13 Accuracy: 14.06%
	Current speed:1.792461635015627 iterations per second
Epoch 0, Iteration 375/657 
Train Loss: 9.06 Accuracy: 7.81%
Epoch 0, Iteration 376/657 
Train Loss: 9.03 Accuracy: 9.38%
Epoch 0, Iteration 377/657 
Train Loss: 9.06 Accuracy: 3.12%
Epoch 0, Iteration 378/657 
Train Loss: 9.14 Accuracy: 7.81%
Epoch 0, Iteration 379/657 
Train Loss: 9.02 Accuracy: 10.94%
Epoch 0, Iteration 380/657 
Train Loss: 9.04 Accuracy: 12.50%
Epoch 0, Iteration 381/657 
Train Loss: 9.03 Accuracy: 10.94%
Epoch 0, Iteration 382/657 
Train Loss: 9.02 Accuracy: 7.81%
Epoch 0, Iteration 383/657 
Train Loss: 9.03 Accuracy: 7.81%
Epoch 0, Iteration 384/657 
Train Loss: 9.04 Accuracy: 15.62%
Epoch 0, Iteration 385/657 
Train Loss: 8.99 Accuracy: 15.62%
Epoch 0, Iteration 386/657 
Train Loss: 9.05 Accuracy: 10.94%
Epoch 0, Iteration 387/657 
Train Loss: 9.06 Accuracy: 9.38%
Epoch 0, Iteration 388/657 
Train Loss: 8.99 Accuracy: 9.38%
Epoch 0, Iteration 389/657 
Train Loss: 9.01 Accuracy: 9.38%
Epoch 0, Iteration 390/657 
Train Loss: 9.05 Accuracy: 14.06%
Epoch 0, Iteration 391/657 
Train Loss: 9.05 Accuracy: 9.38%
Epoch 0, Iteration 392/657 
Train Loss: 9.08 Accuracy: 4.69%
Epoch 0, Iteration 393/657 
Train Loss: 9.06 Accuracy: 6.25%
Epoch 0, Iteration 394/657 
Train Loss: 9.05 Accuracy: 10.94%
Epoch 0, Iteration 395/657 
Train Loss: 9.07 Accuracy: 9.38%
Epoch 0, Iteration 396/657 
Train Loss: 8.98 Accuracy: 7.81%
Epoch 0, Iteration 397/657 
Train Loss: 9.06 Accuracy: 6.25%
Epoch 0, Iteration 398/657 
Train Loss: 9.06 Accuracy: 9.38%
Epoch 0, Iteration 399/657 
Train Loss: 9.06 Accuracy: 9.38%
	Current speed:1.792897850994816 iterations per second
Epoch 0, Iteration 400/657 
Train Loss: 9.04 Accuracy: 6.25%
Epoch 0, Iteration 401/657 
Train Loss: 9.00 Accuracy: 10.94%
Epoch 0, Iteration 402/657 
Train Loss: 9.05 Accuracy: 3.12%
Epoch 0, Iteration 403/657 
Train Loss: 9.04 Accuracy: 10.94%
Epoch 0, Iteration 404/657 
Train Loss: 9.03 Accuracy: 10.94%
Epoch 0, Iteration 405/657 
Train Loss: 9.07 Accuracy: 9.38%
Epoch 0, Iteration 406/657 
Train Loss: 8.96 Accuracy: 9.38%
Epoch 0, Iteration 407/657 
Train Loss: 9.05 Accuracy: 9.38%
Epoch 0, Iteration 408/657 
Train Loss: 9.07 Accuracy: 7.81%
Epoch 0, Iteration 409/657 
Train Loss: 8.99 Accuracy: 15.62%
Epoch 0, Iteration 410/657 
Train Loss: 9.01 Accuracy: 12.50%
Epoch 0, Iteration 411/657 
Train Loss: 9.07 Accuracy: 7.81%
Epoch 0, Iteration 412/657 
Train Loss: 9.06 Accuracy: 6.25%
Epoch 0, Iteration 413/657 
Train Loss: 9.01 Accuracy: 10.94%
Epoch 0, Iteration 414/657 
Train Loss: 9.00 Accuracy: 15.62%
Epoch 0, Iteration 415/657 
Train Loss: 9.13 Accuracy: 7.81%
Epoch 0, Iteration 416/657 
Train Loss: 8.98 Accuracy: 12.50%
Epoch 0, Iteration 417/657 
Train Loss: 9.02 Accuracy: 9.38%
Epoch 0, Iteration 418/657 
Train Loss: 9.07 Accuracy: 10.94%
Epoch 0, Iteration 419/657 
Train Loss: 9.00 Accuracy: 7.81%
Epoch 0, Iteration 420/657 
Train Loss: 9.00 Accuracy: 10.94%
Epoch 0, Iteration 421/657 
Train Loss: 9.04 Accuracy: 7.81%
Epoch 0, Iteration 422/657 
Train Loss: 9.06 Accuracy: 6.25%
Epoch 0, Iteration 423/657 
Train Loss: 9.01 Accuracy: 9.38%
Epoch 0, Iteration 424/657 
Train Loss: 9.05 Accuracy: 12.50%
	Current speed:1.794339511093429 iterations per second
Epoch 0, Iteration 425/657 
Train Loss: 9.04 Accuracy: 9.38%
Epoch 0, Iteration 426/657 
Train Loss: 9.02 Accuracy: 10.94%
Epoch 0, Iteration 427/657 
Train Loss: 9.02 Accuracy: 7.81%
Epoch 0, Iteration 428/657 
Train Loss: 9.06 Accuracy: 6.25%
Epoch 0, Iteration 429/657 
Train Loss: 9.03 Accuracy: 14.06%
Epoch 0, Iteration 430/657 
Train Loss: 9.01 Accuracy: 9.38%
Epoch 0, Iteration 431/657 
Train Loss: 9.01 Accuracy: 6.25%
Epoch 0, Iteration 432/657 
Train Loss: 9.02 Accuracy: 6.25%
Epoch 0, Iteration 433/657 
Train Loss: 9.05 Accuracy: 9.38%
Epoch 0, Iteration 434/657 
Train Loss: 9.05 Accuracy: 9.38%
Epoch 0, Iteration 435/657 
Train Loss: 9.06 Accuracy: 6.25%
Epoch 0, Iteration 436/657 
Train Loss: 8.99 Accuracy: 14.06%
Epoch 0, Iteration 437/657 
Train Loss: 9.01 Accuracy: 10.94%
Epoch 0, Iteration 438/657 
Train Loss: 9.05 Accuracy: 7.81%
Epoch 0, Iteration 439/657 
Train Loss: 9.09 Accuracy: 9.38%
Epoch 0, Iteration 440/657 
Train Loss: 9.09 Accuracy: 6.25%
Epoch 0, Iteration 441/657 
Train Loss: 9.03 Accuracy: 7.81%
Epoch 0, Iteration 442/657 
Train Loss: 9.02 Accuracy: 9.38%
Epoch 0, Iteration 443/657 
Train Loss: 9.06 Accuracy: 7.81%
Epoch 0, Iteration 444/657 
Train Loss: 9.03 Accuracy: 9.38%
Epoch 0, Iteration 445/657 
Train Loss: 8.99 Accuracy: 9.38%
Epoch 0, Iteration 446/657 
Train Loss: 9.08 Accuracy: 4.69%
Epoch 0, Iteration 447/657 
Train Loss: 9.02 Accuracy: 7.81%
Epoch 0, Iteration 448/657 
Train Loss: 9.06 Accuracy: 6.25%
Epoch 0, Iteration 449/657 
Train Loss: 9.01 Accuracy: 10.94%
	Current speed:1.8043020752888341 iterations per second
Epoch 0, Iteration 450/657 
Train Loss: 8.97 Accuracy: 10.94%
Epoch 0, Iteration 451/657 
Train Loss: 8.97 Accuracy: 12.50%
Epoch 0, Iteration 452/657 
Train Loss: 9.06 Accuracy: 7.81%
Epoch 0, Iteration 453/657 
Train Loss: 9.13 Accuracy: 14.06%
Epoch 0, Iteration 454/657 
Train Loss: 9.03 Accuracy: 9.38%
Epoch 0, Iteration 455/657 
Train Loss: 9.00 Accuracy: 14.06%
Epoch 0, Iteration 456/657 
Train Loss: 9.05 Accuracy: 7.81%
Epoch 0, Iteration 457/657 
Train Loss: 8.97 Accuracy: 10.94%
Epoch 0, Iteration 458/657 
Train Loss: 8.93 Accuracy: 14.06%
Epoch 0, Iteration 459/657 
Train Loss: 9.01 Accuracy: 14.06%
Epoch 0, Iteration 460/657 
Train Loss: 9.05 Accuracy: 10.94%
Epoch 0, Iteration 461/657 
Train Loss: 9.10 Accuracy: 9.38%
Epoch 0, Iteration 462/657 
Train Loss: 9.06 Accuracy: 12.50%
Epoch 0, Iteration 463/657 
Train Loss: 8.98 Accuracy: 9.38%
Epoch 0, Iteration 464/657 
Train Loss: 9.16 Accuracy: 14.06%
Epoch 0, Iteration 465/657 
Train Loss: 9.05 Accuracy: 9.38%
Epoch 0, Iteration 466/657 
Train Loss: 8.97 Accuracy: 20.31%
Epoch 0, Iteration 467/657 
Train Loss: 9.03 Accuracy: 15.62%
Epoch 0, Iteration 468/657 
Train Loss: 9.05 Accuracy: 9.38%
Epoch 0, Iteration 469/657 
Train Loss: 9.05 Accuracy: 9.38%
Epoch 0, Iteration 470/657 
Train Loss: 9.17 Accuracy: 6.25%
Epoch 0, Iteration 471/657 
Train Loss: 9.04 Accuracy: 12.50%
Epoch 0, Iteration 472/657 
Train Loss: 9.00 Accuracy: 9.38%
Epoch 0, Iteration 473/657 
Train Loss: 8.99 Accuracy: 7.81%
Epoch 0, Iteration 474/657 
Train Loss: 9.07 Accuracy: 10.94%
	Current speed:1.813142820228023 iterations per second
Epoch 0, Iteration 475/657 
Train Loss: 8.97 Accuracy: 15.62%
Epoch 0, Iteration 476/657 
Train Loss: 9.04 Accuracy: 10.94%
Epoch 0, Iteration 477/657 
Train Loss: 9.06 Accuracy: 7.81%
Epoch 0, Iteration 478/657 
Train Loss: 9.03 Accuracy: 12.50%
Epoch 0, Iteration 479/657 
Train Loss: 9.01 Accuracy: 9.38%
Epoch 0, Iteration 480/657 
Train Loss: 9.25 Accuracy: 12.50%
Epoch 0, Iteration 481/657 
Train Loss: 9.05 Accuracy: 9.38%
Epoch 0, Iteration 482/657 
Train Loss: 9.07 Accuracy: 9.38%
Epoch 0, Iteration 483/657 
Train Loss: 9.10 Accuracy: 4.69%
Epoch 0, Iteration 484/657 
Train Loss: 9.05 Accuracy: 9.38%
Epoch 0, Iteration 485/657 
Train Loss: 9.00 Accuracy: 12.50%
Epoch 0, Iteration 486/657 
Train Loss: 9.07 Accuracy: 7.81%
Epoch 0, Iteration 487/657 
Train Loss: 9.09 Accuracy: 3.12%
Epoch 0, Iteration 488/657 
Train Loss: 9.03 Accuracy: 12.50%
Epoch 0, Iteration 489/657 
Train Loss: 9.02 Accuracy: 10.94%
Epoch 0, Iteration 490/657 
Train Loss: 9.06 Accuracy: 6.25%
Epoch 0, Iteration 491/657 
Train Loss: 9.01 Accuracy: 12.50%
Epoch 0, Iteration 492/657 
Train Loss: 9.01 Accuracy: 7.81%
Epoch 0, Iteration 493/657 
Train Loss: 8.98 Accuracy: 14.06%
Epoch 0, Iteration 494/657 
Train Loss: 9.04 Accuracy: 7.81%
Epoch 0, Iteration 495/657 
Train Loss: 9.00 Accuracy: 12.50%
Epoch 0, Iteration 496/657 
Train Loss: 9.05 Accuracy: 6.25%
Epoch 0, Iteration 497/657 
Train Loss: 9.03 Accuracy: 6.25%
Epoch 0, Iteration 498/657 
Train Loss: 9.01 Accuracy: 15.62%
Epoch 0, Iteration 499/657 
Train Loss: 9.01 Accuracy: 12.50%
	Current speed:1.821417009978671 iterations per second
Epoch 0, Iteration 500/657 
Train Loss: 9.01 Accuracy: 6.25%
Epoch 0, Iteration 501/657 
Train Loss: 9.06 Accuracy: 10.94%
Epoch 0, Iteration 502/657 
Train Loss: 9.00 Accuracy: 10.94%
Epoch 0, Iteration 503/657 
Train Loss: 9.02 Accuracy: 6.25%
Epoch 0, Iteration 504/657 
Train Loss: 9.06 Accuracy: 7.81%
Epoch 0, Iteration 505/657 
Train Loss: 9.04 Accuracy: 9.38%
Epoch 0, Iteration 506/657 
Train Loss: 8.98 Accuracy: 17.19%
Epoch 0, Iteration 507/657 
Train Loss: 9.02 Accuracy: 6.25%
Epoch 0, Iteration 508/657 
Train Loss: 9.04 Accuracy: 12.50%
Epoch 0, Iteration 509/657 
Train Loss: 9.11 Accuracy: 3.12%
Epoch 0, Iteration 510/657 
Train Loss: 9.21 Accuracy: 6.25%
Epoch 0, Iteration 511/657 
Train Loss: 9.05 Accuracy: 7.81%
Epoch 0, Iteration 512/657 
Train Loss: 9.08 Accuracy: 6.25%
Epoch 0, Iteration 513/657 
Train Loss: 9.09 Accuracy: 10.94%
Epoch 0, Iteration 514/657 
Train Loss: 8.99 Accuracy: 7.81%
Epoch 0, Iteration 515/657 
Train Loss: 9.35 Accuracy: 9.38%
Epoch 0, Iteration 516/657 
Train Loss: 9.04 Accuracy: 4.69%
Epoch 0, Iteration 517/657 
Train Loss: 9.13 Accuracy: 4.69%
Epoch 0, Iteration 518/657 
Train Loss: 9.05 Accuracy: 15.62%
Epoch 0, Iteration 519/657 
Train Loss: 9.07 Accuracy: 9.38%
Epoch 0, Iteration 520/657 
Train Loss: 8.96 Accuracy: 20.31%
Epoch 0, Iteration 521/657 
Train Loss: 9.19 Accuracy: 6.25%
Epoch 0, Iteration 522/657 
Train Loss: 9.00 Accuracy: 12.50%
Epoch 0, Iteration 523/657 
Train Loss: 9.09 Accuracy: 6.25%
Epoch 0, Iteration 524/657 
Train Loss: 9.08 Accuracy: 9.38%
	Current speed:1.828854208872135 iterations per second
Epoch 0, Iteration 525/657 
Train Loss: 9.07 Accuracy: 14.06%
Epoch 0, Iteration 526/657 
Train Loss: 8.99 Accuracy: 12.50%
Epoch 0, Iteration 527/657 
Train Loss: 9.03 Accuracy: 9.38%
Epoch 0, Iteration 528/657 
Train Loss: 8.97 Accuracy: 12.50%
Epoch 0, Iteration 529/657 
Train Loss: 9.00 Accuracy: 10.94%
Epoch 0, Iteration 530/657 
Train Loss: 9.00 Accuracy: 7.81%
Epoch 0, Iteration 531/657 
Train Loss: 9.05 Accuracy: 14.06%
Epoch 0, Iteration 532/657 
Train Loss: 9.09 Accuracy: 4.69%
Epoch 0, Iteration 533/657 
Train Loss: 9.07 Accuracy: 20.31%
Epoch 0, Iteration 534/657 
Train Loss: 8.97 Accuracy: 18.75%
Epoch 0, Iteration 535/657 
Train Loss: 9.06 Accuracy: 7.81%
Epoch 0, Iteration 536/657 
Train Loss: 9.00 Accuracy: 12.50%
Epoch 0, Iteration 537/657 
Train Loss: 9.01 Accuracy: 9.38%
Epoch 0, Iteration 538/657 
Train Loss: 9.12 Accuracy: 15.62%
Epoch 0, Iteration 539/657 
Train Loss: 9.00 Accuracy: 12.50%
Epoch 0, Iteration 540/657 
Train Loss: 9.05 Accuracy: 12.50%
Epoch 0, Iteration 541/657 
Train Loss: 9.09 Accuracy: 6.25%
Epoch 0, Iteration 542/657 
Train Loss: 9.09 Accuracy: 6.25%
Epoch 0, Iteration 543/657 
Train Loss: 9.06 Accuracy: 7.81%
Epoch 0, Iteration 544/657 
Train Loss: 9.14 Accuracy: 4.69%
Epoch 0, Iteration 545/657 
Train Loss: 9.05 Accuracy: 4.69%
Epoch 0, Iteration 546/657 
Train Loss: 9.04 Accuracy: 9.38%
Epoch 0, Iteration 547/657 
Train Loss: 9.00 Accuracy: 3.12%
Epoch 0, Iteration 548/657 
Train Loss: 9.00 Accuracy: 15.62%
Epoch 0, Iteration 549/657 
Train Loss: 9.10 Accuracy: 15.62%
	Current speed:1.8352264301095509 iterations per second
Epoch 0, Iteration 550/657 
Train Loss: 9.00 Accuracy: 7.81%
Epoch 0, Iteration 551/657 
Train Loss: 9.06 Accuracy: 7.81%
Epoch 0, Iteration 552/657 
Train Loss: 9.13 Accuracy: 3.12%
Epoch 0, Iteration 553/657 
Train Loss: 9.00 Accuracy: 10.94%
Epoch 0, Iteration 554/657 
Train Loss: 9.05 Accuracy: 10.94%
Epoch 0, Iteration 555/657 
Train Loss: 9.13 Accuracy: 7.81%
Epoch 0, Iteration 556/657 
Train Loss: 8.98 Accuracy: 9.38%
Epoch 0, Iteration 557/657 
Train Loss: 9.02 Accuracy: 7.81%
Epoch 0, Iteration 558/657 
Train Loss: 9.15 Accuracy: 14.06%
Epoch 0, Iteration 559/657 
Train Loss: 9.12 Accuracy: 1.56%
Epoch 0, Iteration 560/657 
Train Loss: 9.17 Accuracy: 6.25%
Epoch 0, Iteration 561/657 
Train Loss: 9.16 Accuracy: 6.25%
Epoch 0, Iteration 562/657 
Train Loss: 9.02 Accuracy: 15.62%
Epoch 0, Iteration 563/657 
Train Loss: 9.11 Accuracy: 9.38%
Epoch 0, Iteration 564/657 
Train Loss: 8.97 Accuracy: 14.06%
Epoch 0, Iteration 565/657 
Train Loss: 8.98 Accuracy: 12.50%
Epoch 0, Iteration 566/657 
Train Loss: 8.98 Accuracy: 18.75%
Epoch 0, Iteration 567/657 
Train Loss: 9.06 Accuracy: 14.06%
Epoch 0, Iteration 568/657 
Train Loss: 9.07 Accuracy: 6.25%
Epoch 0, Iteration 569/657 
Train Loss: 9.01 Accuracy: 10.94%
Epoch 0, Iteration 570/657 
Train Loss: 9.00 Accuracy: 14.06%
Epoch 0, Iteration 571/657 
Train Loss: 9.02 Accuracy: 7.81%
Epoch 0, Iteration 572/657 
Train Loss: 9.10 Accuracy: 6.25%
Epoch 0, Iteration 573/657 
Train Loss: 9.00 Accuracy: 12.50%
Epoch 0, Iteration 574/657 
Train Loss: 9.09 Accuracy: 7.81%
	Current speed:1.8415388367334349 iterations per second
Epoch 0, Iteration 575/657 
Train Loss: 9.04 Accuracy: 10.94%
Epoch 0, Iteration 576/657 
Train Loss: 9.01 Accuracy: 20.31%
Epoch 0, Iteration 577/657 
Train Loss: 9.00 Accuracy: 15.62%
Epoch 0, Iteration 578/657 
Train Loss: 9.03 Accuracy: 14.06%
Epoch 0, Iteration 579/657 
Train Loss: 9.04 Accuracy: 12.50%
Epoch 0, Iteration 580/657 
Train Loss: 9.04 Accuracy: 9.38%
Epoch 0, Iteration 581/657 
Train Loss: 9.05 Accuracy: 10.94%
Epoch 0, Iteration 582/657 
Train Loss: 8.97 Accuracy: 20.31%
Epoch 0, Iteration 583/657 
Train Loss: 8.94 Accuracy: 17.19%
Epoch 0, Iteration 584/657 
Train Loss: 8.99 Accuracy: 12.50%
Epoch 0, Iteration 585/657 
Train Loss: 9.10 Accuracy: 12.50%
Epoch 0, Iteration 586/657 
Train Loss: 8.95 Accuracy: 18.75%
Epoch 0, Iteration 587/657 
Train Loss: 9.00 Accuracy: 9.38%
Epoch 0, Iteration 588/657 
Train Loss: 9.06 Accuracy: 9.38%
Epoch 0, Iteration 589/657 
Train Loss: 9.11 Accuracy: 9.38%
Epoch 0, Iteration 590/657 
Train Loss: 8.99 Accuracy: 10.94%
Epoch 0, Iteration 591/657 
Train Loss: 9.03 Accuracy: 14.06%
Epoch 0, Iteration 592/657 
Train Loss: 9.06 Accuracy: 6.25%
Epoch 0, Iteration 593/657 
Train Loss: 8.98 Accuracy: 9.38%
Epoch 0, Iteration 594/657 
Train Loss: 9.04 Accuracy: 7.81%
Epoch 0, Iteration 595/657 
Train Loss: 8.97 Accuracy: 12.50%
Epoch 0, Iteration 596/657 
Train Loss: 9.07 Accuracy: 10.94%
Epoch 0, Iteration 597/657 
Train Loss: 9.01 Accuracy: 7.81%
Epoch 0, Iteration 598/657 
Train Loss: 9.04 Accuracy: 10.94%
Epoch 0, Iteration 599/657 
Train Loss: 9.05 Accuracy: 4.69%
	Current speed:1.8471435522722894 iterations per second
Epoch 0, Iteration 600/657 
Train Loss: 9.02 Accuracy: 4.69%
Epoch 0, Iteration 601/657 
Train Loss: 9.06 Accuracy: 10.94%
Epoch 0, Iteration 602/657 
Train Loss: 8.99 Accuracy: 12.50%
Epoch 0, Iteration 603/657 
Train Loss: 9.17 Accuracy: 4.69%
Epoch 0, Iteration 604/657 
Train Loss: 8.99 Accuracy: 18.75%
Epoch 0, Iteration 605/657 
Train Loss: 9.00 Accuracy: 9.38%
Epoch 0, Iteration 606/657 
Train Loss: 9.29 Accuracy: 0.00%
Epoch 0, Iteration 607/657 
Train Loss: 9.01 Accuracy: 12.50%
Epoch 0, Iteration 608/657 
Train Loss: 9.00 Accuracy: 18.75%
Epoch 0, Iteration 609/657 
Train Loss: 8.96 Accuracy: 14.06%
Epoch 0, Iteration 610/657 
Train Loss: 8.85 Accuracy: 20.31%
Epoch 0, Iteration 611/657 
Train Loss: 9.03 Accuracy: 9.38%
Epoch 0, Iteration 612/657 
Train Loss: 9.12 Accuracy: 10.94%
Epoch 0, Iteration 613/657 
Train Loss: 9.01 Accuracy: 12.50%
Epoch 0, Iteration 614/657 
Train Loss: 9.13 Accuracy: 10.94%
Epoch 0, Iteration 615/657 
Train Loss: 9.00 Accuracy: 14.06%
Epoch 0, Iteration 616/657 
Train Loss: 8.94 Accuracy: 18.75%
Epoch 0, Iteration 617/657 
Train Loss: 9.14 Accuracy: 10.94%
Epoch 0, Iteration 618/657 
Train Loss: 9.03 Accuracy: 9.38%
Epoch 0, Iteration 619/657 
Train Loss: 9.02 Accuracy: 7.81%
Epoch 0, Iteration 620/657 
Train Loss: 9.05 Accuracy: 7.81%
Epoch 0, Iteration 621/657 
Train Loss: 9.01 Accuracy: 9.38%
Epoch 0, Iteration 622/657 
Train Loss: 9.07 Accuracy: 6.25%
Epoch 0, Iteration 623/657 
Train Loss: 9.04 Accuracy: 14.06%
Epoch 0, Iteration 624/657 
Train Loss: 9.01 Accuracy: 12.50%
	Current speed:1.85280069295922 iterations per second
Epoch 0, Iteration 625/657 
Train Loss: 8.99 Accuracy: 9.38%
Epoch 0, Iteration 626/657 
Train Loss: 9.04 Accuracy: 7.81%
Epoch 0, Iteration 627/657 
Train Loss: 9.00 Accuracy: 9.38%
Epoch 0, Iteration 628/657 
Train Loss: 9.01 Accuracy: 12.50%
Epoch 0, Iteration 629/657 
Train Loss: 8.97 Accuracy: 9.38%
Epoch 0, Iteration 630/657 
Train Loss: 9.00 Accuracy: 7.81%
Epoch 0, Iteration 631/657 
Train Loss: 9.04 Accuracy: 9.38%
Epoch 0, Iteration 632/657 
Train Loss: 9.08 Accuracy: 3.12%
Epoch 0, Iteration 633/657 
Train Loss: 8.99 Accuracy: 7.81%
Epoch 0, Iteration 634/657 
Train Loss: 9.05 Accuracy: 7.81%
Epoch 0, Iteration 635/657 
Train Loss: 8.98 Accuracy: 7.81%
Epoch 0, Iteration 636/657 
Train Loss: 9.04 Accuracy: 7.81%
Epoch 0, Iteration 637/657 
Train Loss: 8.99 Accuracy: 15.62%
Epoch 0, Iteration 638/657 
Train Loss: 9.01 Accuracy: 14.06%
Epoch 0, Iteration 639/657 
Train Loss: 9.01 Accuracy: 10.94%
Epoch 0, Iteration 640/657 
Train Loss: 9.08 Accuracy: 7.81%
Epoch 0, Iteration 641/657 
Train Loss: 8.96 Accuracy: 14.06%
Epoch 0, Iteration 642/657 
Train Loss: 8.94 Accuracy: 14.06%
Epoch 0, Iteration 643/657 
Train Loss: 9.21 Accuracy: 15.62%
Epoch 0, Iteration 644/657 
Train Loss: 9.06 Accuracy: 7.81%
Epoch 0, Iteration 645/657 
Train Loss: 9.04 Accuracy: 10.94%
Epoch 0, Iteration 646/657 
Train Loss: 9.08 Accuracy: 6.25%
Epoch 0, Iteration 647/657 
Train Loss: 9.05 Accuracy: 6.25%
Epoch 0, Iteration 648/657 
Train Loss: 9.03 Accuracy: 9.38%
Epoch 0, Iteration 649/657 
Train Loss: 9.00 Accuracy: 9.38%
	Current speed:1.8576077885312094 iterations per second
Epoch 0, Iteration 650/657 
Train Loss: 8.98 Accuracy: 10.94%
Epoch 0, Iteration 651/657 
Train Loss: 9.03 Accuracy: 7.81%
Epoch 0, Iteration 652/657 
Train Loss: 9.05 Accuracy: 10.94%
Epoch 0, Iteration 653/657 
Train Loss: 9.02 Accuracy: 10.94%
Epoch 0, Iteration 654/657 
Train Loss: 9.05 Accuracy: 7.81%
Epoch 0, Iteration 655/657 
Train Loss: 9.01 Accuracy: 10.94%
Epoch 0, Iteration 656/657 
Train Loss: 8.98 Accuracy: 12.50%
Training time (s):  353.4715485572815
Time spent converting dataset (s / %):  47.817665576934814 13.52800975696797
Time spent in forward pass (s / %): 193.32737493515015 54.69389989780766
Time spent in learning (s / %) 110.4495120048523 31.24707277167274
Time spent loading data (s / %): 1.8769960403442383 0.5310175735516273
Total correctly classified test set images: 1775/18000
Test Set Accuracy: 9.86%
[('conv', {'num-filters': ['113'], 'filter-shape': ['4'], 'stride': ['1'], 'padding': ['valid'], 'bias': ['True']}), ('no-op', {}), ('act', {'beta': ['0.5790415377626313'], 'beta-trainable': ['True'], 'threshold': ['0.8935262397202577'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['zero']}), ('conv', {'num-filters': ['88'], 'filter-shape': ['3'], 'stride': ['1'], 'padding': ['same'], 'bias': ['False']}), ('pool-avg', {'kernel-size': ['3']}), ('act', {'beta': ['0.14046790424207745'], 'beta-trainable': ['True'], 'threshold': ['1.438674866779509'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['zero']}), ('dropout', {'rate': ['0.05800195289188159']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.22888226833214942'], 'beta-trainable': ['True'], 'threshold': ['1.006609589703333'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['zero']})]
Sequential(
  (0): Conv2d(1, 113, kernel_size=(4, 4), stride=(1, 1), padding=valid)
  (1): Leaky()
  (2): Conv2d(113, 88, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)
  (3): AvgPool2d(kernel_size=3, stride=3, padding=0)
  (4): Leaky()
  (5): Dropout(p=0.05800195289188159, inplace=False)
  (6): Flatten(start_dim=1, end_dim=-1)
  (7): Linear(in_features=5632, out_features=10, bias=True)
  (8): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/snntorch/_neurons/leaky.py", line 186, in forward
    self.reset = self.mem_reset(self.mem)
  File "/home/branquinho/.local/lib/python3.7/site-packages/snntorch/_neurons/neurons.py", line 102, in mem_reset
    reset = self.spike_grad(mem_shift).clone().detach()
  File "/home/branquinho/.local/lib/python3.7/site-packages/snntorch/surrogate.py", line 150, in inner
    return FastSigmoid.apply(x, slope)
  File "/home/branquinho/.local/lib/python3.7/site-packages/snntorch/surrogate.py", line 134, in forward
    out = (input_ > 0).float()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 5.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 0: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 1
[('dropout', {'rate': ['0.3872643558615498']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.3872643558615498, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('conv', {'num-filters': ['51'], 'filter-shape': ['4'], 'stride': ['1'], 'padding': ['valid'], 'bias': ['True']}), ('pool-avg', {'kernel-size': ['3']}), ('act', {'beta': ['0.9750454451924563'], 'beta-trainable': ['True'], 'threshold': ['0.9971738536711056'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']}), ('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Conv2d(1, 51, kernel_size=(4, 4), stride=(1, 1), padding=valid)
  (1): AvgPool2d(kernel_size=3, stride=3, padding=0)
  (2): Leaky()
  (3): Dropout(p=0.4758588514133684, inplace=False)
  (4): Dropout(p=0.21675721744770188, inplace=False)
  (5): Flatten(start_dim=1, end_dim=-1)
  (6): Linear(in_features=3264, out_features=220, bias=False)
  (7): Leaky()
  (8): Linear(in_features=220, out_features=10, bias=True)
  (9): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 460, in _conv_forward
    self.padding, self.dilation, self.groups)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('dropout', {'rate': ['0.14404333913153555']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Dropout(p=0.14404333913153555, inplace=False)
  (6): Linear(in_features=220, out_features=10, bias=True)
  (7): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('conv', {'num-filters': ['112'], 'filter-shape': ['3'], 'stride': ['2'], 'padding': ['valid'], 'bias': ['True']}), ('no-op', {}), ('act', {'beta': ['0.08629978515776715'], 'beta-trainable': ['False'], 'threshold': ['1.0296605906285945'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Conv2d(1, 112, kernel_size=(3, 3), stride=(2, 2), padding=valid)
  (2): Leaky()
  (3): Dropout(p=0.21675721744770188, inplace=False)
  (4): Flatten(start_dim=1, end_dim=-1)
  (5): Linear(in_features=18928, out_features=220, bias=False)
  (6): Leaky()
  (7): Linear(in_features=220, out_features=10, bias=True)
  (8): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.70 GiB already allocated; 7.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 1: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 2
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/dropout.py", line 59, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/functional.py", line 1252, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/dropout.py", line 59, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/functional.py", line 1252, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.0510677311138899']}), ('conv', {'num-filters': ['34'], 'filter-shape': ['4'], 'stride': ['2'], 'padding': ['valid'], 'bias': ['False']}), ('pool-avg', {'kernel-size': ['2']}), ('act', {'beta': ['0.6700913636449005'], 'beta-trainable': ['False'], 'threshold': ['1.019107026912912'], 'threshold-trainable': ['True'], 'surr-grad': ['fast_sigmoid'], 'reset': ['zero']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.0510677311138899, inplace=False)
  (2): Conv2d(1, 34, kernel_size=(4, 4), stride=(2, 2), padding=valid, bias=False)
  (3): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (4): Leaky()
  (5): Flatten(start_dim=1, end_dim=-1)
  (6): Linear(in_features=1224, out_features=220, bias=False)
  (7): Leaky()
  (8): Linear(in_features=220, out_features=10, bias=True)
  (9): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/snntorch/_neurons/leaky.py", line 160, in forward
    self.mem = _SpikeTorchConv(self.mem, input_=input_)
  File "/home/branquinho/.local/lib/python3.7/site-packages/snntorch/_neurons/neurons.py", line 465, in _SpikeTorchConv
    arg = torch.zeros_like(input_, requires_grad=True)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.33090036795032624']}), ('dropout', {'rate': ['0.45145370075721225']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.33090036795032624, inplace=False)
  (2): Dropout(p=0.45145370075721225, inplace=False)
  (3): Dropout(p=0.21675721744770188, inplace=False)
  (4): Flatten(start_dim=1, end_dim=-1)
  (5): Linear(in_features=784, out_features=220, bias=False)
  (6): Leaky()
  (7): Linear(in_features=220, out_features=10, bias=True)
  (8): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/dropout.py", line 59, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/functional.py", line 1252, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 2: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 3
[('dropout', {'rate': ['0.4758588514133684']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Flatten(start_dim=1, end_dim=-1)
  (2): Linear(in_features=784, out_features=220, bias=False)
  (3): Leaky()
  (4): Linear(in_features=220, out_features=10, bias=True)
  (5): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/snntorch/_neurons/leaky.py", line 186, in forward
    self.reset = self.mem_reset(self.mem)
  File "/home/branquinho/.local/lib/python3.7/site-packages/snntorch/_neurons/neurons.py", line 102, in mem_reset
    reset = self.spike_grad(mem_shift).clone().detach()
  File "/home/branquinho/.local/lib/python3.7/site-packages/snntorch/surrogate.py", line 210, in inner
    return ATan.apply(x, alpha)
  File "/home/branquinho/.local/lib/python3.7/site-packages/snntorch/surrogate.py", line 189, in forward
    out = (input_ > 0).float()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/dropout.py", line 59, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/functional.py", line 1252, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.025650098407434596']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('dropout', {'rate': ['0.3542721816849086']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.025650098407434596, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Dropout(p=0.3542721816849086, inplace=False)
  (6): Linear(in_features=220, out_features=10, bias=True)
  (7): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/dropout.py", line 59, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/functional.py", line 1252, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.014784613348348435']}), ('fc', {'num-units': ['188'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.014784613348348435, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=188, bias=False)
  (4): Leaky()
  (5): Linear(in_features=188, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/dropout.py", line 59, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/functional.py", line 1252, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 3: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 4
[('dropout', {'rate': ['0.21675721744770188']}), ('conv', {'num-filters': ['44'], 'filter-shape': ['4'], 'stride': ['3'], 'padding': ['valid'], 'bias': ['True']}), ('no-op', {}), ('act', {'beta': ['0.6365597762899954'], 'beta-trainable': ['False'], 'threshold': ['1.0976538070046085'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['False'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.21675721744770188, inplace=False)
  (1): Conv2d(1, 44, kernel_size=(4, 4), stride=(3, 3), padding=valid)
  (2): Leaky()
  (3): Dropout(p=0.21675721744770188, inplace=False)
  (4): Flatten(start_dim=1, end_dim=-1)
  (5): Linear(in_features=3564, out_features=220, bias=False)
  (6): Leaky()
  (7): Linear(in_features=220, out_features=10, bias=True)
  (8): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 460, in _conv_forward
    self.padding, self.dilation, self.groups)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.3742484304870725']}), ('conv', {'num-filters': ['106'], 'filter-shape': ['3'], 'stride': ['3'], 'padding': ['same'], 'bias': ['False']}), ('pool-max', {'kernel-size': ['4']}), ('act', {'beta': ['0.26835771940961284'], 'beta-trainable': ['False'], 'threshold': ['0.6798645726912963'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['zero']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('dropout', {'rate': ['0.37497295193406394']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.3742484304870725, inplace=False)
  (1): Conv2d(1, 106, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)
  (2): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
  (3): Leaky()
  (4): Flatten(start_dim=1, end_dim=-1)
  (5): Linear(in_features=5194, out_features=220, bias=False)
  (6): Leaky()
  (7): Dropout(p=0.37497295193406394, inplace=False)
  (8): Linear(in_features=220, out_features=10, bias=True)
  (9): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 460, in _conv_forward
    self.padding, self.dilation, self.groups)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.13655768348879227']}), ('dropout', {'rate': ['0.13655768348879227']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.13655768348879227, inplace=False)
  (2): Dropout(p=0.13655768348879227, inplace=False)
  (3): Flatten(start_dim=1, end_dim=-1)
  (4): Linear(in_features=784, out_features=220, bias=False)
  (5): Leaky()
  (6): Linear(in_features=220, out_features=10, bias=True)
  (7): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/dropout.py", line 59, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/functional.py", line 1252, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('conv', {'num-filters': ['94'], 'filter-shape': ['4'], 'stride': ['1'], 'padding': ['same'], 'bias': ['True']}), ('pool-avg', {'kernel-size': ['2']}), ('act', {'beta': ['0.10388942745490037'], 'beta-trainable': ['False'], 'threshold': ['1.246129524753048'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['zero']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Conv2d(1, 94, kernel_size=(4, 4), stride=(1, 1), padding=same)
  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (3): Leaky()
  (4): Flatten(start_dim=1, end_dim=-1)
  (5): Linear(in_features=18424, out_features=220, bias=False)
  (6): Leaky()
  (7): Linear(in_features=220, out_features=10, bias=True)
  (8): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.70 GiB already allocated; 7.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 4: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 5
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['197'], 'bias': ['False']}), ('act', {'beta': ['0.8382056272165036'], 'beta-trainable': ['False'], 'threshold': ['0.6705318266117056'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=197, bias=False)
  (6): Leaky()
  (7): Linear(in_features=197, out_features=10, bias=True)
  (8): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/dropout.py", line 59, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/functional.py", line 1252, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('conv', {'num-filters': ['72'], 'filter-shape': ['2'], 'stride': ['2'], 'padding': ['valid'], 'bias': ['False']}), ('pool-avg', {'kernel-size': ['2']}), ('act', {'beta': ['0.5966331938624061'], 'beta-trainable': ['True'], 'threshold': ['0.6328569915549097'], 'threshold-trainable': ['False'], 'surr-grad': ['atan'], 'reset': ['zero']}), ('dropout', {'rate': ['0.4873135448830495']}), ('fc', {'num-units': ['202'], 'bias': ['False']}), ('act', {'beta': ['0.35817828918341676'], 'beta-trainable': ['False'], 'threshold': ['1.2941415760920418'], 'threshold-trainable': ['False'], 'surr-grad': ['atan'], 'reset': ['zero']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Conv2d(1, 72, kernel_size=(2, 2), stride=(2, 2), padding=valid, bias=False)
  (1): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (2): Leaky()
  (3): Dropout(p=0.4873135448830495, inplace=False)
  (4): Flatten(start_dim=1, end_dim=-1)
  (5): Linear(in_features=3528, out_features=202, bias=False)
  (6): Leaky()
  (7): Linear(in_features=202, out_features=10, bias=True)
  (8): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/pooling.py", line 628, in forward
    self.padding, self.ceil_mode, self.count_include_pad, self.divisor_override)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/dropout.py", line 59, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/functional.py", line 1252, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['199'], 'bias': ['False']}), ('act', {'beta': ['0.4823559226377848'], 'beta-trainable': ['False'], 'threshold': ['0.8415278345209873'], 'threshold-trainable': ['True'], 'surr-grad': ['fast_sigmoid'], 'reset': ['zero']}), ('dropout', {'rate': ['0.38508370288683597']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=199, bias=False)
  (4): Leaky()
  (5): Dropout(p=0.38508370288683597, inplace=False)
  (6): Linear(in_features=199, out_features=10, bias=True)
  (7): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/dropout.py", line 59, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/functional.py", line 1252, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 5: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 6
[('conv', {'num-filters': ['108'], 'filter-shape': ['2'], 'stride': ['3'], 'padding': ['valid'], 'bias': ['True']}), ('no-op', {}), ('act', {'beta': ['0.7368402737025752'], 'beta-trainable': ['True'], 'threshold': ['1.4548728405678761'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']}), ('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Conv2d(1, 108, kernel_size=(2, 2), stride=(3, 3), padding=valid)
  (1): Leaky()
  (2): Dropout(p=0.4758588514133684, inplace=False)
  (3): Dropout(p=0.21675721744770188, inplace=False)
  (4): Flatten(start_dim=1, end_dim=-1)
  (5): Linear(in_features=8748, out_features=220, bias=False)
  (6): Leaky()
  (7): Linear(in_features=220, out_features=10, bias=True)
  (8): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/dropout.py", line 59, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/functional.py", line 1252, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.585832583949178'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/dropout.py", line 59, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/functional.py", line 1252, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.5']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.5, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/dropout.py", line 59, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/functional.py", line 1252, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 6: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 7
[('dropout', {'rate': ['0.4758588514133684']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('dropout', {'rate': ['0.4671742396515868']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Flatten(start_dim=1, end_dim=-1)
  (2): Linear(in_features=784, out_features=220, bias=False)
  (3): Leaky()
  (4): Dropout(p=0.4671742396515868, inplace=False)
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/snntorch/_neurons/leaky.py", line 186, in forward
    self.reset = self.mem_reset(self.mem)
  File "/home/branquinho/.local/lib/python3.7/site-packages/snntorch/_neurons/neurons.py", line 102, in mem_reset
    reset = self.spike_grad(mem_shift).clone().detach()
  File "/home/branquinho/.local/lib/python3.7/site-packages/snntorch/surrogate.py", line 210, in inner
    return ATan.apply(x, alpha)
  File "/home/branquinho/.local/lib/python3.7/site-packages/snntorch/surrogate.py", line 189, in forward
    out = (input_ > 0).float()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/dropout.py", line 59, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/functional.py", line 1252, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('conv', {'num-filters': ['68'], 'filter-shape': ['3'], 'stride': ['1'], 'padding': ['valid'], 'bias': ['True']}), ('no-op', {}), ('act', {'beta': ['0.9006855906344551'], 'beta-trainable': ['True'], 'threshold': ['1.4102817506400587'], 'threshold-trainable': ['True'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']}), ('conv', {'num-filters': ['40'], 'filter-shape': ['2'], 'stride': ['3'], 'padding': ['valid'], 'bias': ['True']}), ('pool-max', {'kernel-size': ['4']}), ('act', {'beta': ['0.6513601634089935'], 'beta-trainable': ['True'], 'threshold': ['1.4755799743329567'], 'threshold-trainable': ['True'], 'surr-grad': ['fast_sigmoid'], 'reset': ['zero']}), ('dropout', {'rate': ['0.428167877895171']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Conv2d(1, 68, kernel_size=(3, 3), stride=(1, 1), padding=valid)
  (1): Leaky()
  (2): Conv2d(68, 40, kernel_size=(2, 2), stride=(3, 3), padding=valid)
  (3): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
  (4): Leaky()
  (5): Dropout(p=0.428167877895171, inplace=False)
  (6): Flatten(start_dim=1, end_dim=-1)
  (7): Linear(in_features=160, out_features=220, bias=False)
  (8): Leaky()
  (9): Linear(in_features=220, out_features=10, bias=True)
  (10): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 460, in _conv_forward
    self.padding, self.dilation, self.groups)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/dropout.py", line 59, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/functional.py", line 1252, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 7: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 8
[('dropout', {'rate': ['0.4036833372629019']}), ('dropout', {'rate': ['0.2578793627483952']}), ('dropout', {'rate': ['0.2578793627483952']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4036833372629019, inplace=False)
  (1): Dropout(p=0.2578793627483952, inplace=False)
  (2): Dropout(p=0.2578793627483952, inplace=False)
  (3): Flatten(start_dim=1, end_dim=-1)
  (4): Linear(in_features=784, out_features=10, bias=True)
  (5): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('conv', {'num-filters': ['62'], 'filter-shape': ['4'], 'stride': ['3'], 'padding': ['valid'], 'bias': ['False']}), ('no-op', {}), ('act', {'beta': ['0.4327501778733278'], 'beta-trainable': ['False'], 'threshold': ['0.8617655742155721'], 'threshold-trainable': ['True'], 'surr-grad': ['fast_sigmoid'], 'reset': ['zero']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Conv2d(1, 62, kernel_size=(4, 4), stride=(3, 3), padding=valid, bias=False)
  (2): Leaky()
  (3): Flatten(start_dim=1, end_dim=-1)
  (4): Linear(in_features=5022, out_features=220, bias=False)
  (5): Leaky()
  (6): Linear(in_features=220, out_features=10, bias=True)
  (7): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/snntorch/_neurons/leaky.py", line 187, in forward
    self.mem = self._build_state_function_hidden(input_)
  File "/home/branquinho/.local/lib/python3.7/site-packages/snntorch/_neurons/leaky.py", line 231, in _build_state_function_hidden
    state_fn = self._base_state_function_hidden(input_)
  File "/home/branquinho/.local/lib/python3.7/site-packages/snntorch/_neurons/leaky.py", line 220, in _base_state_function_hidden
    base_fn = self.beta.clamp(0, 1) * self.mem + input_
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.72 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Flatten(start_dim=1, end_dim=-1)
  (2): Linear(in_features=784, out_features=220, bias=False)
  (3): Leaky()
  (4): Linear(in_features=220, out_features=10, bias=True)
  (5): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/snntorch/_neurons/leaky.py", line 186, in forward
    self.reset = self.mem_reset(self.mem)
  File "/home/branquinho/.local/lib/python3.7/site-packages/snntorch/_neurons/neurons.py", line 102, in mem_reset
    reset = self.spike_grad(mem_shift).clone().detach()
  File "/home/branquinho/.local/lib/python3.7/site-packages/snntorch/surrogate.py", line 210, in inner
    return ATan.apply(x, alpha)
  File "/home/branquinho/.local/lib/python3.7/site-packages/snntorch/surrogate.py", line 189, in forward
    out = (input_ > 0).float()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.21675721744770188']}), ('dropout', {'rate': ['0.06378797508596062']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.21675721744770188, inplace=False)
  (1): Dropout(p=0.06378797508596062, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=10, bias=True)
  (4): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 8: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 9
[('dropout', {'rate': ['0.4758588514133684']}), ('conv', {'num-filters': ['71'], 'filter-shape': ['4'], 'stride': ['2'], 'padding': ['same'], 'bias': ['False']}), ('pool-avg', {'kernel-size': ['4']}), ('act', {'beta': ['0.11982539921548285'], 'beta-trainable': ['True'], 'threshold': ['0.5833709615827922'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['zero']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Conv2d(1, 71, kernel_size=(4, 4), stride=(1, 1), padding=same, bias=False)
  (2): AvgPool2d(kernel_size=4, stride=4, padding=0)
  (3): Leaky()
  (4): Flatten(start_dim=1, end_dim=-1)
  (5): Linear(in_features=3479, out_features=220, bias=False)
  (6): Leaky()
  (7): Linear(in_features=220, out_features=10, bias=True)
  (8): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 460, in _conv_forward
    self.padding, self.dilation, self.groups)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('conv', {'num-filters': ['64'], 'filter-shape': ['3'], 'stride': ['2'], 'padding': ['same'], 'bias': ['False']}), ('pool-avg', {'kernel-size': ['4']}), ('act', {'beta': ['0.7995005100691247'], 'beta-trainable': ['False'], 'threshold': ['0.8859966442142415'], 'threshold-trainable': ['False'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('dropout', {'rate': ['0.4758588514133684']}), ('conv', {'num-filters': ['45'], 'filter-shape': ['4'], 'stride': ['3'], 'padding': ['same'], 'bias': ['True']}), ('no-op', {}), ('act', {'beta': ['0.30241743778973973'], 'beta-trainable': ['False'], 'threshold': ['0.9990779603436644'], 'threshold-trainable': ['True'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['False'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)
  (1): AvgPool2d(kernel_size=4, stride=4, padding=0)
  (2): Leaky()
  (3): Dropout(p=0.4758588514133684, inplace=False)
  (4): Conv2d(64, 45, kernel_size=(4, 4), stride=(1, 1), padding=same)
  (5): Leaky()
  (6): Flatten(start_dim=1, end_dim=-1)
  (7): Linear(in_features=2205, out_features=220, bias=False)
  (8): Leaky()
  (9): Linear(in_features=220, out_features=10, bias=True)
  (10): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 460, in _conv_forward
    self.padding, self.dilation, self.groups)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['107'], 'bias': ['False']}), ('act', {'beta': ['0.6660724139553392'], 'beta-trainable': ['False'], 'threshold': ['0.784229342760786'], 'threshold-trainable': ['True'], 'surr-grad': ['fast_sigmoid'], 'reset': ['zero']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=107, bias=False)
  (4): Leaky()
  (5): Linear(in_features=107, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('dropout', {'rate': ['0.3811842976869946']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['False'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Dropout(p=0.3811842976869946, inplace=False)
  (3): Flatten(start_dim=1, end_dim=-1)
  (4): Linear(in_features=784, out_features=220, bias=False)
  (5): Leaky()
  (6): Linear(in_features=220, out_features=10, bias=True)
  (7): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 9: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 10
[('dropout', {'rate': ['0.4758588514133684']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Flatten(start_dim=1, end_dim=-1)
  (2): Linear(in_features=784, out_features=220, bias=False)
  (3): Leaky()
  (4): Linear(in_features=220, out_features=10, bias=True)
  (5): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('conv', {'num-filters': ['59'], 'filter-shape': ['2'], 'stride': ['2'], 'padding': ['valid'], 'bias': ['False']}), ('no-op', {}), ('act', {'beta': ['0.6769359871291822'], 'beta-trainable': ['True'], 'threshold': ['0.634200607090894'], 'threshold-trainable': ['True'], 'surr-grad': ['fast_sigmoid'], 'reset': ['zero']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('dropout', {'rate': ['0.3882423902576095']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Conv2d(1, 59, kernel_size=(2, 2), stride=(2, 2), padding=valid, bias=False)
  (3): Leaky()
  (4): Flatten(start_dim=1, end_dim=-1)
  (5): Linear(in_features=11564, out_features=220, bias=False)
  (6): Leaky()
  (7): Dropout(p=0.3882423902576095, inplace=False)
  (8): Linear(in_features=220, out_features=10, bias=True)
  (9): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.70 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Flatten(start_dim=1, end_dim=-1)
  (2): Linear(in_features=784, out_features=220, bias=False)
  (3): Leaky()
  (4): Linear(in_features=220, out_features=10, bias=True)
  (5): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('conv', {'num-filters': ['124'], 'filter-shape': ['3'], 'stride': ['1'], 'padding': ['valid'], 'bias': ['False']}), ('no-op', {}), ('act', {'beta': ['0.9933945693862599'], 'beta-trainable': ['True'], 'threshold': ['1.0194072704283532'], 'threshold-trainable': ['True'], 'surr-grad': ['fast_sigmoid'], 'reset': ['zero']}), ('dropout', {'rate': ['0.21675721744770188']}), ('dropout', {'rate': ['0.31493602103257845']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Conv2d(1, 124, kernel_size=(3, 3), stride=(1, 1), padding=valid, bias=False)
  (1): Leaky()
  (2): Dropout(p=0.21675721744770188, inplace=False)
  (3): Dropout(p=0.31493602103257845, inplace=False)
  (4): Flatten(start_dim=1, end_dim=-1)
  (5): Linear(in_features=83824, out_features=220, bias=False)
  (6): Leaky()
  (7): Linear(in_features=220, out_features=10, bias=True)
  (8): Leaky()
)
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 617, in evaluate
    return scnn_eval.evaluate(phenotype, weights_save_path, parent_weights_path, num_epochs)
  File "/home/branquinho/snn/fast_denser/utils.py", line 376, in evaluate
    model.to(device)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 23.75 MiB free; 2.70 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 10: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 11
[('dropout', {'rate': ['0.4758588514133684']}), ('conv', {'num-filters': ['90'], 'filter-shape': ['3'], 'stride': ['1'], 'padding': ['same'], 'bias': ['True']}), ('pool-avg', {'kernel-size': ['3']}), ('act', {'beta': ['0.7424401204338553'], 'beta-trainable': ['False'], 'threshold': ['1.1503482287870415'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['zero']}), ('dropout', {'rate': ['0.0']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Conv2d(1, 90, kernel_size=(3, 3), stride=(1, 1), padding=same)
  (2): AvgPool2d(kernel_size=3, stride=3, padding=0)
  (3): Leaky()
  (4): Dropout(p=0.0, inplace=False)
  (5): Flatten(start_dim=1, end_dim=-1)
  (6): Linear(in_features=7290, out_features=220, bias=False)
  (7): Leaky()
  (8): Linear(in_features=220, out_features=10, bias=True)
  (9): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('dropout', {'rate': ['0.14143161207311677']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Dropout(p=0.14143161207311677, inplace=False)
  (3): Flatten(start_dim=1, end_dim=-1)
  (4): Linear(in_features=784, out_features=10, bias=True)
  (5): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.11686960648703078']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['86'], 'bias': ['True']}), ('act', {'beta': ['0.6003349610680997'], 'beta-trainable': ['False'], 'threshold': ['0.5995178258083306'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['zero']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.11686960648703078, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=86, bias=True)
  (6): Leaky()
  (7): Linear(in_features=86, out_features=10, bias=True)
  (8): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.08016155489705451']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['False'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.08016155489705451, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 11: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 12
[('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.21675721744770188, inplace=False)
  (1): Flatten(start_dim=1, end_dim=-1)
  (2): Linear(in_features=784, out_features=220, bias=False)
  (3): Leaky()
  (4): Linear(in_features=220, out_features=10, bias=True)
  (5): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('conv', {'num-filters': ['93'], 'filter-shape': ['4'], 'stride': ['3'], 'padding': ['same'], 'bias': ['True']}), ('pool-max', {'kernel-size': ['2']}), ('act', {'beta': ['0.17462951192396858'], 'beta-trainable': ['True'], 'threshold': ['1.1515552943553158'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['zero']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Conv2d(1, 93, kernel_size=(4, 4), stride=(1, 1), padding=same)
  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (4): Leaky()
  (5): Flatten(start_dim=1, end_dim=-1)
  (6): Linear(in_features=18228, out_features=220, bias=False)
  (7): Leaky()
  (8): Linear(in_features=220, out_features=10, bias=True)
  (9): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.70 GiB already allocated; 7.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4407816081884335']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4407816081884335, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.21675721744770188, inplace=False)
  (1): Flatten(start_dim=1, end_dim=-1)
  (2): Linear(in_features=784, out_features=220, bias=False)
  (3): Leaky()
  (4): Linear(in_features=220, out_features=10, bias=True)
  (5): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 12: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 13
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Dropout(p=0.21675721744770188, inplace=False)
  (3): Flatten(start_dim=1, end_dim=-1)
  (4): Linear(in_features=784, out_features=220, bias=False)
  (5): Leaky()
  (6): Linear(in_features=220, out_features=10, bias=True)
  (7): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Flatten(start_dim=1, end_dim=-1)
  (2): Linear(in_features=784, out_features=220, bias=False)
  (3): Leaky()
  (4): Linear(in_features=220, out_features=10, bias=True)
  (5): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.21675721744770188, inplace=False)
  (1): Flatten(start_dim=1, end_dim=-1)
  (2): Linear(in_features=784, out_features=220, bias=False)
  (3): Leaky()
  (4): Linear(in_features=220, out_features=10, bias=True)
  (5): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 13: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 14
[('dropout', {'rate': ['0.4758588514133684']}), ('conv', {'num-filters': ['55'], 'filter-shape': ['3'], 'stride': ['3'], 'padding': ['valid'], 'bias': ['False']}), ('pool-max', {'kernel-size': ['3']}), ('act', {'beta': ['0.1072651120587198'], 'beta-trainable': ['False'], 'threshold': ['1.3170217823233283'], 'threshold-trainable': ['False'], 'surr-grad': ['atan'], 'reset': ['zero']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Conv2d(1, 55, kernel_size=(3, 3), stride=(3, 3), padding=valid, bias=False)
  (2): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
  (3): Leaky()
  (4): Flatten(start_dim=1, end_dim=-1)
  (5): Linear(in_features=495, out_features=220, bias=False)
  (6): Leaky()
  (7): Linear(in_features=220, out_features=10, bias=True)
  (8): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.3699595037985137']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.3699595037985137, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['False'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Flatten(start_dim=1, end_dim=-1)
  (2): Linear(in_features=784, out_features=220, bias=False)
  (3): Leaky()
  (4): Linear(in_features=220, out_features=10, bias=True)
  (5): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.03755111185582721']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.03755111185582721, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 14: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 15
[('dropout', {'rate': ['0.4758588514133684']}), ('conv', {'num-filters': ['87'], 'filter-shape': ['2'], 'stride': ['3'], 'padding': ['same'], 'bias': ['True']}), ('no-op', {}), ('act', {'beta': ['0.3276312560673197'], 'beta-trainable': ['True'], 'threshold': ['1.0604580560214267'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Conv2d(1, 87, kernel_size=(2, 2), stride=(1, 1), padding=same)
  (2): Leaky()
  (3): Dropout(p=0.21675721744770188, inplace=False)
  (4): Flatten(start_dim=1, end_dim=-1)
  (5): Linear(in_features=68208, out_features=220, bias=False)
  (6): Leaky()
  (7): Linear(in_features=220, out_features=10, bias=True)
  (8): Leaky()
)
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 617, in evaluate
    return scnn_eval.evaluate(phenotype, weights_save_path, parent_weights_path, num_epochs)
  File "/home/branquinho/snn/fast_denser/utils.py", line 376, in evaluate
    model.to(device)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 58.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 23.75 MiB free; 2.70 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('conv', {'num-filters': ['54'], 'filter-shape': ['2'], 'stride': ['3'], 'padding': ['valid'], 'bias': ['False']}), ('no-op', {}), ('act', {'beta': ['0.3422305258828783'], 'beta-trainable': ['True'], 'threshold': ['0.6249996298436726'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['zero']}), ('dropout', {'rate': ['0.4758588514133684']}), ('conv', {'num-filters': ['39'], 'filter-shape': ['3'], 'stride': ['2'], 'padding': ['valid'], 'bias': ['False']}), ('no-op', {}), ('act', {'beta': ['0.9169328186774347'], 'beta-trainable': ['True'], 'threshold': ['1.3376902488897708'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['zero']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Conv2d(1, 54, kernel_size=(2, 2), stride=(3, 3), padding=valid, bias=False)
  (1): Leaky()
  (2): Dropout(p=0.4758588514133684, inplace=False)
  (3): Conv2d(54, 39, kernel_size=(3, 3), stride=(2, 2), padding=valid, bias=False)
  (4): Leaky()
  (5): Flatten(start_dim=1, end_dim=-1)
  (6): Linear(in_features=624, out_features=220, bias=False)
  (7): Leaky()
  (8): Linear(in_features=220, out_features=10, bias=True)
  (9): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('conv', {'num-filters': ['46'], 'filter-shape': ['3'], 'stride': ['2'], 'padding': ['valid'], 'bias': ['False']}), ('pool-avg', {'kernel-size': ['2']}), ('act', {'beta': ['0.06484265692908964'], 'beta-trainable': ['True'], 'threshold': ['0.5314150132912094'], 'threshold-trainable': ['False'], 'surr-grad': ['atan'], 'reset': ['zero']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Conv2d(1, 46, kernel_size=(3, 3), stride=(2, 2), padding=valid, bias=False)
  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (3): Leaky()
  (4): Dropout(p=0.21675721744770188, inplace=False)
  (5): Flatten(start_dim=1, end_dim=-1)
  (6): Linear(in_features=1656, out_features=220, bias=False)
  (7): Leaky()
  (8): Linear(in_features=220, out_features=10, bias=True)
  (9): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/pooling.py", line 628, in forward
    self.padding, self.ceil_mode, self.count_include_pad, self.divisor_override)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.4758588514133684, inplace=False)
  (2): Dropout(p=0.21675721744770188, inplace=False)
  (3): Flatten(start_dim=1, end_dim=-1)
  (4): Linear(in_features=784, out_features=220, bias=False)
  (5): Leaky()
  (6): Linear(in_features=220, out_features=10, bias=True)
  (7): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 15: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 16
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.05843258455286948']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.05843258455286948, inplace=False)
  (2): Dropout(p=0.21675721744770188, inplace=False)
  (3): Flatten(start_dim=1, end_dim=-1)
  (4): Linear(in_features=784, out_features=220, bias=False)
  (5): Leaky()
  (6): Linear(in_features=220, out_features=10, bias=True)
  (7): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 16: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 17
[('conv', {'num-filters': ['119'], 'filter-shape': ['2'], 'stride': ['2'], 'padding': ['same'], 'bias': ['True']}), ('pool-max', {'kernel-size': ['4']}), ('act', {'beta': ['0.3804132923733776'], 'beta-trainable': ['False'], 'threshold': ['0.7173478428132765'], 'threshold-trainable': ['True'], 'surr-grad': ['fast_sigmoid'], 'reset': ['zero']}), ('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Conv2d(1, 119, kernel_size=(2, 2), stride=(1, 1), padding=same)
  (1): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
  (2): Leaky()
  (3): Dropout(p=0.4758588514133684, inplace=False)
  (4): Dropout(p=0.21675721744770188, inplace=False)
  (5): Flatten(start_dim=1, end_dim=-1)
  (6): Linear(in_features=5831, out_features=220, bias=False)
  (7): Leaky()
  (8): Linear(in_features=220, out_features=10, bias=True)
  (9): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.21675721744770188, inplace=False)
  (1): Flatten(start_dim=1, end_dim=-1)
  (2): Linear(in_features=784, out_features=220, bias=False)
  (3): Leaky()
  (4): Linear(in_features=220, out_features=10, bias=True)
  (5): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 17: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 18
[('dropout', {'rate': ['0.5']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['155'], 'bias': ['True']}), ('act', {'beta': ['0.41485247980864104'], 'beta-trainable': ['False'], 'threshold': ['1.0476428904707022'], 'threshold-trainable': ['False'], 'surr-grad': ['atan'], 'reset': ['zero']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.5, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=155, bias=True)
  (6): Leaky()
  (7): Linear(in_features=155, out_features=10, bias=True)
  (8): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.2523676184218356']}), ('conv', {'num-filters': ['44'], 'filter-shape': ['4'], 'stride': ['3'], 'padding': ['valid'], 'bias': ['False']}), ('no-op', {}), ('act', {'beta': ['0.697187649582255'], 'beta-trainable': ['False'], 'threshold': ['0.7326335687292607'], 'threshold-trainable': ['False'], 'surr-grad': ['atan'], 'reset': ['zero']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.2523676184218356, inplace=False)
  (1): Conv2d(1, 44, kernel_size=(4, 4), stride=(3, 3), padding=valid, bias=False)
  (2): Leaky()
  (3): Dropout(p=0.21675721744770188, inplace=False)
  (4): Flatten(start_dim=1, end_dim=-1)
  (5): Linear(in_features=3564, out_features=220, bias=False)
  (6): Leaky()
  (7): Linear(in_features=220, out_features=10, bias=True)
  (8): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 460, in _conv_forward
    self.padding, self.dilation, self.groups)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['187'], 'bias': ['False']}), ('act', {'beta': ['0.28781053751023045'], 'beta-trainable': ['False'], 'threshold': ['0.7268381091737788'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['zero']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=187, bias=False)
  (4): Leaky()
  (5): Linear(in_features=187, out_features=220, bias=False)
  (6): Leaky()
  (7): Linear(in_features=220, out_features=10, bias=True)
  (8): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('dropout', {'rate': ['0.4484316504198031']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Dropout(p=0.4484316504198031, inplace=False)
  (3): Flatten(start_dim=1, end_dim=-1)
  (4): Linear(in_features=784, out_features=10, bias=True)
  (5): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 18: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 19
[('dropout', {'rate': ['0.4758588514133684']}), ('conv', {'num-filters': ['127'], 'filter-shape': ['3'], 'stride': ['1'], 'padding': ['valid'], 'bias': ['False']}), ('pool-avg', {'kernel-size': ['2']}), ('act', {'beta': ['0.7264173075654474'], 'beta-trainable': ['False'], 'threshold': ['0.9290055928665458'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['zero']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['110'], 'bias': ['True']}), ('act', {'beta': ['0.21024196092228886'], 'beta-trainable': ['True'], 'threshold': ['0.7020320956073609'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['zero']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Conv2d(1, 127, kernel_size=(3, 3), stride=(1, 1), padding=valid, bias=False)
  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (3): Leaky()
  (4): Dropout(p=0.21675721744770188, inplace=False)
  (5): Flatten(start_dim=1, end_dim=-1)
  (6): Linear(in_features=21463, out_features=220, bias=False)
  (7): Leaky()
  (8): Linear(in_features=220, out_features=110, bias=True)
  (9): Leaky()
  (10): Linear(in_features=110, out_features=10, bias=True)
  (11): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.70 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('conv', {'num-filters': ['112'], 'filter-shape': ['4'], 'stride': ['1'], 'padding': ['same'], 'bias': ['False']}), ('no-op', {}), ('act', {'beta': ['0.2752961137219988'], 'beta-trainable': ['True'], 'threshold': ['1.356254099878769'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('dropout', {'rate': ['0.2982361936507545']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Conv2d(1, 112, kernel_size=(4, 4), stride=(1, 1), padding=same, bias=False)
  (1): Leaky()
  (2): Dropout(p=0.2982361936507545, inplace=False)
  (3): Dropout(p=0.21675721744770188, inplace=False)
  (4): Flatten(start_dim=1, end_dim=-1)
  (5): Linear(in_features=87808, out_features=220, bias=False)
  (6): Leaky()
  (7): Linear(in_features=220, out_features=10, bias=True)
  (8): Leaky()
)
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 617, in evaluate
    return scnn_eval.evaluate(phenotype, weights_save_path, parent_weights_path, num_epochs)
  File "/home/branquinho/snn/fast_denser/utils.py", line 376, in evaluate
    model.to(device)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 74.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 23.75 MiB free; 2.70 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('conv', {'num-filters': ['119'], 'filter-shape': ['3'], 'stride': ['2'], 'padding': ['same'], 'bias': ['False']}), ('pool-max', {'kernel-size': ['4']}), ('act', {'beta': ['0.3602768399097057'], 'beta-trainable': ['True'], 'threshold': ['1.2119011916453704'], 'threshold-trainable': ['True'], 'surr-grad': ['fast_sigmoid'], 'reset': ['zero']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Conv2d(1, 119, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)
  (1): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
  (2): Leaky()
  (3): Dropout(p=0.21675721744770188, inplace=False)
  (4): Flatten(start_dim=1, end_dim=-1)
  (5): Linear(in_features=5831, out_features=220, bias=False)
  (6): Leaky()
  (7): Linear(in_features=220, out_features=10, bias=True)
  (8): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 19: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 20
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.7000811880926436'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['153'], 'bias': ['False']}), ('act', {'beta': ['0.5205842977547843'], 'beta-trainable': ['True'], 'threshold': ['1.115716327946083'], 'threshold-trainable': ['False'], 'surr-grad': ['atan'], 'reset': ['zero']}), ('dropout', {'rate': ['0.15511490730494898']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=153, bias=False)
  (6): Leaky()
  (7): Dropout(p=0.15511490730494898, inplace=False)
  (8): Linear(in_features=153, out_features=10, bias=True)
  (9): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('dropout', {'rate': ['0.3268665396771886']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Dropout(p=0.3268665396771886, inplace=False)
  (3): Flatten(start_dim=1, end_dim=-1)
  (4): Linear(in_features=784, out_features=220, bias=False)
  (5): Leaky()
  (6): Linear(in_features=220, out_features=10, bias=True)
  (7): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 20: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 21
[('conv', {'num-filters': ['33'], 'filter-shape': ['2'], 'stride': ['2'], 'padding': ['same'], 'bias': ['False']}), ('pool-avg', {'kernel-size': ['3']}), ('act', {'beta': ['0.09884261478876644'], 'beta-trainable': ['True'], 'threshold': ['0.9493738479545202'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['zero']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Conv2d(1, 33, kernel_size=(2, 2), stride=(1, 1), padding=same, bias=False)
  (1): AvgPool2d(kernel_size=3, stride=3, padding=0)
  (2): Leaky()
  (3): Dropout(p=0.21675721744770188, inplace=False)
  (4): Flatten(start_dim=1, end_dim=-1)
  (5): Linear(in_features=2673, out_features=220, bias=False)
  (6): Leaky()
  (7): Linear(in_features=220, out_features=10, bias=True)
  (8): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 460, in _conv_forward
    self.padding, self.dilation, self.groups)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.21675721744770188, inplace=False)
  (1): Flatten(start_dim=1, end_dim=-1)
  (2): Linear(in_features=784, out_features=220, bias=False)
  (3): Leaky()
  (4): Linear(in_features=220, out_features=10, bias=True)
  (5): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('conv', {'num-filters': ['110'], 'filter-shape': ['4'], 'stride': ['3'], 'padding': ['valid'], 'bias': ['True']}), ('no-op', {}), ('act', {'beta': ['0.12178286062576871'], 'beta-trainable': ['False'], 'threshold': ['1.31268282104802'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Conv2d(1, 110, kernel_size=(4, 4), stride=(3, 3), padding=valid)
  (3): Leaky()
  (4): Flatten(start_dim=1, end_dim=-1)
  (5): Linear(in_features=8910, out_features=220, bias=False)
  (6): Leaky()
  (7): Linear(in_features=220, out_features=10, bias=True)
  (8): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 21: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 22
[('dropout', {'rate': ['0.4758588514133684']}), ('conv', {'num-filters': ['107'], 'filter-shape': ['3'], 'stride': ['1'], 'padding': ['same'], 'bias': ['True']}), ('no-op', {}), ('act', {'beta': ['0.6298301291940982'], 'beta-trainable': ['False'], 'threshold': ['1.363873572270636'], 'threshold-trainable': ['False'], 'surr-grad': ['atan'], 'reset': ['zero']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Conv2d(1, 107, kernel_size=(3, 3), stride=(1, 1), padding=same)
  (2): Leaky()
  (3): Flatten(start_dim=1, end_dim=-1)
  (4): Linear(in_features=83888, out_features=220, bias=False)
  (5): Leaky()
  (6): Linear(in_features=220, out_features=10, bias=True)
  (7): Leaky()
)
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 617, in evaluate
    return scnn_eval.evaluate(phenotype, weights_save_path, parent_weights_path, num_epochs)
  File "/home/branquinho/snn/fast_denser/utils.py", line 376, in evaluate
    model.to(device)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 23.75 MiB free; 2.70 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['244'], 'bias': ['True']}), ('act', {'beta': ['0.6198272226183867'], 'beta-trainable': ['True'], 'threshold': ['0.6438599804493064'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.21675721744770188, inplace=False)
  (1): Flatten(start_dim=1, end_dim=-1)
  (2): Linear(in_features=784, out_features=244, bias=True)
  (3): Leaky()
  (4): Linear(in_features=244, out_features=220, bias=False)
  (5): Leaky()
  (6): Linear(in_features=220, out_features=10, bias=True)
  (7): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 22: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 23
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.2436198824408038']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('dropout', {'rate': ['0.34849728684083653']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.2436198824408038, inplace=False)
  (2): Dropout(p=0.21675721744770188, inplace=False)
  (3): Flatten(start_dim=1, end_dim=-1)
  (4): Linear(in_features=784, out_features=220, bias=False)
  (5): Leaky()
  (6): Dropout(p=0.34849728684083653, inplace=False)
  (7): Linear(in_features=220, out_features=10, bias=True)
  (8): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.39141125434060103']}), ('dropout', {'rate': ['0.4758588514133684']}), ('conv', {'num-filters': ['106'], 'filter-shape': ['2'], 'stride': ['3'], 'padding': ['same'], 'bias': ['False']}), ('no-op', {}), ('act', {'beta': ['0.32376431342811174'], 'beta-trainable': ['False'], 'threshold': ['1.0984089293167467'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.39141125434060103, inplace=False)
  (1): Dropout(p=0.4758588514133684, inplace=False)
  (2): Conv2d(1, 106, kernel_size=(2, 2), stride=(1, 1), padding=same, bias=False)
  (3): Leaky()
  (4): Flatten(start_dim=1, end_dim=-1)
  (5): Linear(in_features=83104, out_features=220, bias=False)
  (6): Leaky()
  (7): Linear(in_features=220, out_features=10, bias=True)
  (8): Leaky()
)
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 617, in evaluate
    return scnn_eval.evaluate(phenotype, weights_save_path, parent_weights_path, num_epochs)
  File "/home/branquinho/snn/fast_denser/utils.py", line 376, in evaluate
    model.to(device)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 70.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 23.75 MiB free; 2.70 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.5']}), ('conv', {'num-filters': ['94'], 'filter-shape': ['3'], 'stride': ['2'], 'padding': ['valid'], 'bias': ['False']}), ('no-op', {}), ('act', {'beta': ['0.7415931514761962'], 'beta-trainable': ['False'], 'threshold': ['1.1574220096823644'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.5, inplace=False)
  (1): Conv2d(1, 94, kernel_size=(3, 3), stride=(2, 2), padding=valid, bias=False)
  (2): Leaky()
  (3): Dropout(p=0.21675721744770188, inplace=False)
  (4): Flatten(start_dim=1, end_dim=-1)
  (5): Linear(in_features=15886, out_features=220, bias=False)
  (6): Leaky()
  (7): Linear(in_features=220, out_features=10, bias=True)
  (8): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.70 GiB already allocated; 9.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 23: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 24
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('conv', {'num-filters': ['69'], 'filter-shape': ['4'], 'stride': ['1'], 'padding': ['valid'], 'bias': ['False']}), ('pool-avg', {'kernel-size': ['4']}), ('act', {'beta': ['0.12685155616775967'], 'beta-trainable': ['True'], 'threshold': ['0.9952567058789222'], 'threshold-trainable': ['True'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Conv2d(1, 69, kernel_size=(4, 4), stride=(1, 1), padding=valid, bias=False)
  (3): AvgPool2d(kernel_size=4, stride=4, padding=0)
  (4): Leaky()
  (5): Flatten(start_dim=1, end_dim=-1)
  (6): Linear(in_features=2484, out_features=220, bias=False)
  (7): Leaky()
  (8): Linear(in_features=220, out_features=10, bias=True)
  (9): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 460, in _conv_forward
    self.padding, self.dilation, self.groups)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.8568003322766427'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('dropout', {'rate': ['0.10037393801697075']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Dropout(p=0.10037393801697075, inplace=False)
  (6): Linear(in_features=220, out_features=10, bias=True)
  (7): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['172'], 'bias': ['True']}), ('act', {'beta': ['0.8946526213234282'], 'beta-trainable': ['False'], 'threshold': ['0.7978541504525896'], 'threshold-trainable': ['False'], 'surr-grad': ['atan'], 'reset': ['zero']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Dropout(p=0.21675721744770188, inplace=False)
  (3): Flatten(start_dim=1, end_dim=-1)
  (4): Linear(in_features=784, out_features=172, bias=True)
  (5): Leaky()
  (6): Linear(in_features=172, out_features=220, bias=False)
  (7): Leaky()
  (8): Linear(in_features=220, out_features=10, bias=True)
  (9): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['212'], 'bias': ['True']}), ('act', {'beta': ['0.5677648078107513'], 'beta-trainable': ['True'], 'threshold': ['1.2421299433927584'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=212, bias=True)
  (4): Leaky()
  (5): Linear(in_features=212, out_features=220, bias=False)
  (6): Leaky()
  (7): Linear(in_features=220, out_features=10, bias=True)
  (8): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 24: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 25
[('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.21675721744770188, inplace=False)
  (1): Flatten(start_dim=1, end_dim=-1)
  (2): Linear(in_features=784, out_features=220, bias=False)
  (3): Leaky()
  (4): Linear(in_features=220, out_features=10, bias=True)
  (5): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.34452329531575987']}), ('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.34452329531575987, inplace=False)
  (1): Dropout(p=0.4758588514133684, inplace=False)
  (2): Dropout(p=0.21675721744770188, inplace=False)
  (3): Flatten(start_dim=1, end_dim=-1)
  (4): Linear(in_features=784, out_features=220, bias=False)
  (5): Leaky()
  (6): Linear(in_features=220, out_features=10, bias=True)
  (7): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('dropout', {'rate': ['0.14586166960204028']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Dropout(p=0.14586166960204028, inplace=False)
  (3): Flatten(start_dim=1, end_dim=-1)
  (4): Linear(in_features=784, out_features=220, bias=False)
  (5): Leaky()
  (6): Linear(in_features=220, out_features=10, bias=True)
  (7): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 25: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 26
[('conv', {'num-filters': ['80'], 'filter-shape': ['4'], 'stride': ['2'], 'padding': ['valid'], 'bias': ['False']}), ('pool-avg', {'kernel-size': ['3']}), ('act', {'beta': ['0.19282149136719218'], 'beta-trainable': ['False'], 'threshold': ['0.5420759363067776'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Conv2d(1, 80, kernel_size=(4, 4), stride=(2, 2), padding=valid, bias=False)
  (1): AvgPool2d(kernel_size=3, stride=3, padding=0)
  (2): Leaky()
  (3): Dropout(p=0.21675721744770188, inplace=False)
  (4): Flatten(start_dim=1, end_dim=-1)
  (5): Linear(in_features=1280, out_features=220, bias=False)
  (6): Leaky()
  (7): Linear(in_features=220, out_features=10, bias=True)
  (8): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/snntorch/_neurons/leaky.py", line 160, in forward
    self.mem = _SpikeTorchConv(self.mem, input_=input_)
  File "/home/branquinho/.local/lib/python3.7/site-packages/snntorch/_neurons/neurons.py", line 465, in _SpikeTorchConv
    arg = torch.zeros_like(input_, requires_grad=True)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.12343555941225598']}), ('fc', {'num-units': ['73'], 'bias': ['False']}), ('act', {'beta': ['0.5278897609068749'], 'beta-trainable': ['False'], 'threshold': ['1.1741622531096079'], 'threshold-trainable': ['True'], 'surr-grad': ['fast_sigmoid'], 'reset': ['zero']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.12343555941225598, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=73, bias=False)
  (4): Leaky()
  (5): Linear(in_features=73, out_features=220, bias=False)
  (6): Leaky()
  (7): Linear(in_features=220, out_features=10, bias=True)
  (8): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/dropout.py", line 59, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/functional.py", line 1252, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('dropout', {'rate': ['0.09297994116261998']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Dropout(p=0.09297994116261998, inplace=False)
  (6): Linear(in_features=220, out_features=10, bias=True)
  (7): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('conv', {'num-filters': ['53'], 'filter-shape': ['4'], 'stride': ['2'], 'padding': ['valid'], 'bias': ['True']}), ('pool-max', {'kernel-size': ['2']}), ('act', {'beta': ['0.5128216454858229'], 'beta-trainable': ['False'], 'threshold': ['1.190113839404809'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']}), ('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Conv2d(1, 53, kernel_size=(4, 4), stride=(2, 2), padding=valid)
  (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (2): Leaky()
  (3): Dropout(p=0.4758588514133684, inplace=False)
  (4): Dropout(p=0.21675721744770188, inplace=False)
  (5): Flatten(start_dim=1, end_dim=-1)
  (6): Linear(in_features=1908, out_features=220, bias=False)
  (7): Leaky()
  (8): Linear(in_features=220, out_features=10, bias=True)
  (9): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/pooling.py", line 168, in forward
    return_indices=self.return_indices)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/_jit_internal.py", line 485, in fn
    return if_false(*args, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/functional.py", line 782, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 26: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 27
[('conv', {'num-filters': ['44'], 'filter-shape': ['4'], 'stride': ['1'], 'padding': ['valid'], 'bias': ['True']}), ('pool-avg', {'kernel-size': ['3']}), ('act', {'beta': ['0.25624671105207786'], 'beta-trainable': ['False'], 'threshold': ['1.2184515651167651'], 'threshold-trainable': ['True'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Conv2d(1, 44, kernel_size=(4, 4), stride=(1, 1), padding=valid)
  (1): AvgPool2d(kernel_size=3, stride=3, padding=0)
  (2): Leaky()
  (3): Dropout(p=0.21675721744770188, inplace=False)
  (4): Flatten(start_dim=1, end_dim=-1)
  (5): Linear(in_features=2816, out_features=220, bias=False)
  (6): Leaky()
  (7): Linear(in_features=220, out_features=10, bias=True)
  (8): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 460, in _conv_forward
    self.padding, self.dilation, self.groups)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['zero']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('conv', {'num-filters': ['43'], 'filter-shape': ['3'], 'stride': ['1'], 'padding': ['same'], 'bias': ['False']}), ('pool-avg', {'kernel-size': ['2']}), ('act', {'beta': ['0.4811976310590197'], 'beta-trainable': ['True'], 'threshold': ['0.7781773942097905'], 'threshold-trainable': ['True'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['True']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Conv2d(1, 43, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)
  (1): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (2): Leaky()
  (3): Dropout(p=0.21675721744770188, inplace=False)
  (4): Flatten(start_dim=1, end_dim=-1)
  (5): Linear(in_features=8428, out_features=220, bias=True)
  (6): Leaky()
  (7): Linear(in_features=220, out_features=10, bias=True)
  (8): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 27: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 28
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.34142752642618707']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.34142752642618707, inplace=False)
  (2): Dropout(p=0.21675721744770188, inplace=False)
  (3): Flatten(start_dim=1, end_dim=-1)
  (4): Linear(in_features=784, out_features=220, bias=False)
  (5): Leaky()
  (6): Linear(in_features=220, out_features=10, bias=True)
  (7): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('dropout', {'rate': ['0.4115188226319724']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Dropout(p=0.4115188226319724, inplace=False)
  (3): Flatten(start_dim=1, end_dim=-1)
  (4): Linear(in_features=784, out_features=10, bias=True)
  (5): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.5']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.5, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 28: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 29
[('dropout', {'rate': ['0.4758588514133684']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Flatten(start_dim=1, end_dim=-1)
  (2): Linear(in_features=784, out_features=220, bias=False)
  (3): Leaky()
  (4): Linear(in_features=220, out_features=10, bias=True)
  (5): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.3438229083429857']}), ('conv', {'num-filters': ['64'], 'filter-shape': ['3'], 'stride': ['1'], 'padding': ['valid'], 'bias': ['True']}), ('pool-max', {'kernel-size': ['4']}), ('act', {'beta': ['0.39571063247098726'], 'beta-trainable': ['False'], 'threshold': ['1.4910417069672124'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.3438229083429857, inplace=False)
  (1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=valid)
  (2): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
  (3): Leaky()
  (4): Dropout(p=0.21675721744770188, inplace=False)
  (5): Flatten(start_dim=1, end_dim=-1)
  (6): Linear(in_features=2304, out_features=220, bias=False)
  (7): Leaky()
  (8): Linear(in_features=220, out_features=10, bias=True)
  (9): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 539, in train_network
    spk_rec = forward_pass(model, data)
  File "/home/branquinho/snn/fast_denser/utils.py", line 471, in forward_pass
    spk_out, mem_out = net(data[step])
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 460, in _conv_forward
    self.padding, self.dilation, self.groups)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 11.78 GiB total capacity; 2.71 GiB already allocated; 3.75 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 29: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 30
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['True']}), ('act', {'beta': ['0.5297326660212921'], 'beta-trainable': ['False'], 'threshold': ['0.7938346216214669'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['zero']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=True)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=220, bias=False)
  (6): Leaky()
  (7): Linear(in_features=220, out_features=10, bias=True)
  (8): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('fc', {'num-units': ['208'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Flatten(start_dim=1, end_dim=-1)
  (2): Linear(in_features=784, out_features=208, bias=False)
  (3): Leaky()
  (4): Linear(in_features=208, out_features=10, bias=True)
  (5): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 30: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 31
[('conv', {'num-filters': ['68'], 'filter-shape': ['4'], 'stride': ['1'], 'padding': ['valid'], 'bias': ['True']}), ('no-op', {}), ('act', {'beta': ['0.23053015786512054'], 'beta-trainable': ['False'], 'threshold': ['0.9525110550559687'], 'threshold-trainable': ['True'], 'surr-grad': ['fast_sigmoid'], 'reset': ['zero']}), ('dropout', {'rate': ['0.21675721744770188']}), ('conv', {'num-filters': ['53'], 'filter-shape': ['3'], 'stride': ['1'], 'padding': ['valid'], 'bias': ['False']}), ('no-op', {}), ('act', {'beta': ['0.7792367851220644'], 'beta-trainable': ['True'], 'threshold': ['0.7475051422254064'], 'threshold-trainable': ['False'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Conv2d(1, 68, kernel_size=(4, 4), stride=(1, 1), padding=valid)
  (1): Leaky()
  (2): Dropout(p=0.21675721744770188, inplace=False)
  (3): Conv2d(68, 53, kernel_size=(3, 3), stride=(1, 1), padding=valid, bias=False)
  (4): Leaky()
  (5): Flatten(start_dim=1, end_dim=-1)
  (6): Linear(in_features=28037, out_features=220, bias=False)
  (7): Leaky()
  (8): Linear(in_features=220, out_features=220, bias=False)
  (9): Leaky()
  (10): Linear(in_features=220, out_features=10, bias=True)
  (11): Leaky()
)
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 617, in evaluate
    return scnn_eval.evaluate(phenotype, weights_save_path, parent_weights_path, num_epochs)
  File "/home/branquinho/snn/fast_denser/utils.py", line 376, in evaluate
    model.to(device)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/branquinho/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 23.75 MiB free; 2.70 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['False'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['False'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Flatten(start_dim=1, end_dim=-1)
  (2): Linear(in_features=784, out_features=220, bias=False)
  (3): Leaky()
  (4): Linear(in_features=220, out_features=220, bias=False)
  (5): Leaky()
  (6): Linear(in_features=220, out_features=10, bias=True)
  (7): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0] Best fitness of generation 31: 0.653944
[0] Best overall fitness: 0.653944
[0] Performing generation: 32
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['219'], 'bias': ['False']}), ('act', {'beta': ['0.30232066743027297'], 'beta-trainable': ['True'], 'threshold': ['0.9585233057488782'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=219, bias=False)
  (4): Leaky()
  (5): Linear(in_features=219, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
Traceback (most recent call last):
  File "/home/branquinho/snn/fast_denser/utils.py", line 403, in evaluate
    acc_hist, loss_hist, time_stats = train_network(model,trainloader,optimizer,loss_fn,num_epochs,num_steps)
  File "/home/branquinho/snn/fast_denser/utils.py", line 522, in train_network
    data = spikegen.rate(data.data, num_steps=num_steps).to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 2.69 GiB already allocated; 21.75 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[('dropout', {'rate': ['0.4758588514133684']}), ('dropout', {'rate': ['0.21675721744770188']}), ('fc', {'num-units': ['220'], 'bias': ['False']}), ('act', {'beta': ['0.658815986908692'], 'beta-trainable': ['True'], 'threshold': ['0.729705216805681'], 'threshold-trainable': ['True'], 'surr-grad': ['atan'], 'reset': ['subtract']}), ('fc', {'num-units': ['10'], 'bias': ['True']}), ('act', {'beta': ['0.9633157837008631'], 'beta-trainable': ['True'], 'threshold': ['1.456100646116651'], 'threshold-trainable': ['False'], 'surr-grad': ['fast_sigmoid'], 'reset': ['subtract']})]
Sequential(
  (0): Dropout(p=0.4758588514133684, inplace=False)
  (1): Dropout(p=0.21675721744770188, inplace=False)
  (2): Flatten(start_dim=1, end_dim=-1)
  (3): Linear(in_features=784, out_features=220, bias=False)
  (4): Leaky()
  (5): Linear(in_features=220, out_features=10, bias=True)
  (6): Leaky()
)
	Current speed:0.0 iterations per second
